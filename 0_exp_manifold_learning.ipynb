{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm, trange\n",
    "import zuko\n",
    "from zuko.flows import Distribution, NSF\n",
    "from zuko.distributions import DiagNormal, BoxUniform, Minimum\n",
    "from zuko.flows import DistributionModule, FlowModule, Unconditional\n",
    "from hnne import HNNE\n",
    "\n",
    "from utils.robot import Robot\n",
    "from utils.settings import param\n",
    "from utils.dataset import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:13<00:00, 76826.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building h-NNE hierarchy using FINCH...\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Thu May 18 16:19:03 2023 Building RP forest with 32 trees\n",
      "Thu May 18 16:19:12 2023 NN descent for 20 iterations\n",
      "\t 1  /  20\n",
      "\t 2  /  20\n",
      "\t 3  /  20\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 0: 265325 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Thu May 18 16:19:35 2023 Building RP forest with 28 trees\n",
      "Thu May 18 16:19:36 2023 NN descent for 18 iterations\n",
      "\t 1  /  18\n",
      "\t 2  /  18\n",
      "\t 3  /  18\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 1: 65931 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Thu May 18 16:19:39 2023 Building RP forest with 21 trees\n",
      "Thu May 18 16:19:39 2023 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 2: 15912 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Thu May 18 16:19:40 2023 Building RP forest with 16 trees\n",
      "Thu May 18 16:19:40 2023 NN descent for 14 iterations\n",
      "\t 1  /  14\n",
      "\t 2  /  14\n",
      "\t 3  /  14\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 3: 3783 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Thu May 18 16:19:40 2023 Building RP forest with 13 trees\n",
      "Thu May 18 16:19:40 2023 NN descent for 12 iterations\n",
      "\t 1  /  12\n",
      "\t 2  /  12\n",
      "\t 3  /  12\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 4: 920 clusters\n",
      "Level 5: 232 clusters\n",
      "Level 6: 62 clusters\n",
      "Level 7: 18 clusters\n",
      "Level 8: 4 clusters\n",
      "Projecting to 4 dimensions...\n",
      "[265325, 65931, 15912, 3783, 920, 232, 62, 18, 4]\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Thu May 18 16:19:43 2023 Building RP forest with 13 trees\n",
      "Thu May 18 16:19:43 2023 NN descent for 12 iterations\n",
      "\t 1  /  12\n",
      "\t 2  /  12\n",
      "\t 3  /  12\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Thu May 18 16:19:50 2023 Building RP forest with 16 trees\n",
      "Thu May 18 16:19:50 2023 NN descent for 14 iterations\n",
      "\t 1  /  14\n",
      "\t 2  /  14\n",
      "\t 3  /  14\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Thu May 18 16:19:50 2023 Building RP forest with 21 trees\n",
      "Thu May 18 16:19:51 2023 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Thu May 18 16:19:51 2023 Building RP forest with 28 trees\n",
      "Thu May 18 16:19:52 2023 NN descent for 18 iterations\n",
      "\t 1  /  18\n",
      "\t 2  /  18\n",
      "\t 3  /  18\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    }
   ],
   "source": [
    "panda = Robot(verbose=False)\n",
    "# data generation\n",
    "X, y = panda.random_sample_joint_config(num_samples=100_0000, return_ee=True)\n",
    "hnne = HNNE(dim=4, ann_threshold=1000)\n",
    "X_transformed = hnne.fit_transform(X=X[:100_0000], dim=4, verbose=True)\n",
    "y = np.column_stack((y, X_transformed))\n",
    "ds = create_dataset(features=X, targets=y, enable_normalize=False)\n",
    "loader = ds.create_loader(shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        # training\n",
    "        self.num_epochs = 2\n",
    "        self.num_steps_save = 2000\n",
    "        self.num_test_data = 60\n",
    "        self.num_test_samples = 40\n",
    "        self.save_path = './weights/best_manifold_learning.pth'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config()\n",
    "# Neural spline flow (NSF) with 3 sample features and 5 context features\n",
    "flow = NSF(features=7, context=7+1, transforms=12, randperm=True, activation=nn.LeakyReLU, hidden_features=[1024] * 4).to('cuda')\n",
    "flow.load_state_dict(state_dict=torch.load(config.save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_small_noise_to_batch(batch, esp: float = 1e-3, eval: bool = False):\n",
    "    x, y = batch\n",
    "    if eval:\n",
    "        std = torch.zeros((x.shape[0], 1)).to(x.device)\n",
    "        y = torch.column_stack((y, std))\n",
    "    else:\n",
    "        std = torch.rand((x.shape[0], 1)).to(x.device)\n",
    "        y = torch.column_stack((y, std))\n",
    "        noise = torch.normal(mean=torch.zeros_like(input=x), std=torch.repeat_interleave(input=std, repeats=x.shape[1], dim=1))\n",
    "        x = x + esp * noise\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 37359.08it/s]\n"
     ]
    }
   ],
   "source": [
    "path, sample_ans_q = panda.path_generate_via_stable_joint_traj()\n",
    "np.save('./data/sample_ans_q', sample_ans_q)\n",
    "np.save('./data/path', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ans_q = np.load('./data/sample_ans_q.npy')\n",
    "path = np.load('./data/path.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_jtraj(path, pidx, model=flow):\n",
    "    path_len = len(path)\n",
    "    pidx = np.tile(pidx, (path_len,1))\n",
    "    cstd = np.zeros((path_len,))\n",
    "    \n",
    "    y = np.column_stack((path, pidx, cstd))\n",
    "    y = torch.tensor(data=y, device='cuda', dtype=torch.float32)\n",
    "    \n",
    "    errs = np.zeros((len(path),))\n",
    "    log_probs = np.zeros((len(path),))\n",
    "    \n",
    "    step = 0\n",
    "    x_hat = model(y).sample((1,))\n",
    "    log_prob = model(y).log_prob(x_hat)\n",
    "    \n",
    "    x_hat = x_hat.detach().cpu().numpy()[0]\n",
    "    log_prob = -log_prob.detach().cpu().numpy()[0]\n",
    "    print(path.shape)\n",
    "    print(x_hat.shape)\n",
    "    print(log_prob.shape)\n",
    "    for q, lp, ee_pos in zip(x_hat, log_prob, path):\n",
    "        errs[step] = panda.dist_fk(q=q, ee_pos=ee_pos)\n",
    "        log_probs[step] = lp     \n",
    "        step += 1\n",
    "    print(f'step={step}')\n",
    "    df = pd.DataFrame(np.column_stack((errs, log_probs)), columns=['l2_err', 'log_prob'])\n",
    "    qs = x_hat\n",
    "    return df, qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44524488,  0.61229221,  0.21142905,  0.26101529],\n",
       "       [-0.44524488,  0.61229221,  0.21142905,  0.26101529],\n",
       "       [-0.44524489,  0.6122922 ,  0.21142904,  0.26101529]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pidx = hnne.transform(X=sample_ans_q[0:3])\n",
    "pidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100, 7)\n",
      "(100,)\n",
      "step=100\n",
      "           l2_err    log_prob\n",
      "count  100.000000  100.000000\n",
      "mean     0.017932   -5.861188\n",
      "std      0.010550    2.194074\n",
      "min      0.003041   -9.723755\n",
      "25%      0.010885   -7.426585\n",
      "50%      0.017146   -6.232446\n",
      "75%      0.022153   -4.845385\n",
      "max      0.063643    0.473040\n",
      "(100, 3)\n",
      "(100, 7)\n",
      "(100,)\n",
      "step=100\n",
      "           l2_err    log_prob\n",
      "count  100.000000  100.000000\n",
      "mean     0.018972   -5.751236\n",
      "std      0.017647    2.021458\n",
      "min      0.003151   -9.228773\n",
      "25%      0.010400   -7.288369\n",
      "50%      0.015109   -5.968640\n",
      "75%      0.020470   -4.544196\n",
      "max      0.123945   -0.395426\n",
      "(100, 3)\n",
      "(100, 7)\n",
      "(100,)\n",
      "step=100\n",
      "           l2_err    log_prob\n",
      "count  100.000000  100.000000\n",
      "mean     0.022680   -5.307285\n",
      "std      0.021689    2.384039\n",
      "min      0.004120   -9.228888\n",
      "25%      0.010919   -7.129104\n",
      "50%      0.017539   -5.697484\n",
      "75%      0.025518   -3.623688\n",
      "max      0.164878    2.780489\n"
     ]
    }
   ],
   "source": [
    "for i, px in enumerate(pidx):\n",
    "    df, qs = sample_jtraj(path, px, flow)\n",
    "    print(df.describe())\n",
    "    np.save(f'./data/exp_qs_{i}', arr=qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4]),)\n",
      "[0.06364301]\n",
      "1.793220472269379\n",
      "(array([54, 79, 90, 98]),)\n",
      "[0.12394481 0.07852604 0.07414823 0.09467775]\n",
      "1.8972022784952\n",
      "(array([ 2,  3,  9, 72, 79, 83]),)\n",
      "[0.07673373 0.05092229 0.1648779  0.08106042 0.06482196 0.10785701]\n",
      "2.2680039664091587\n"
     ]
    }
   ],
   "source": [
    "panda = Robot(verbose=False)\n",
    "\n",
    "path = np.load('./data/path.npy')\n",
    "err = np.zeros((100,))\n",
    "\n",
    "for i in range(3):\n",
    "    step = 0\n",
    "    qs = np.load(file=f'./data/exp_qs_{i}.npy')\n",
    "    for i in range(100):\n",
    "        err[i] = panda.dist_fk(q=qs[i], ee_pos=path[i])\n",
    "    outliner = np.where(err > 0.05)\n",
    "    print(outliner)\n",
    "    print(err[outliner])\n",
    "    print(np.sum(err))\n",
    "    # panda.plot_qs(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
