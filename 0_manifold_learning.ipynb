{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm, trange\n",
    "import zuko\n",
    "from zuko.flows import Distribution, NSF\n",
    "from zuko.distributions import DiagNormal, BoxUniform, Minimum\n",
    "from zuko.flows import DistributionModule, FlowModule, Unconditional\n",
    "from hnne import HNNE\n",
    "\n",
    "from utils.utils import load_numpy\n",
    "from utils.robot import Robot\n",
    "from utils.settings import param\n",
    "from utils.dataset import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # data\n",
    "        self.x_data_path = './data/feature.npy' # joint configuration\n",
    "        self.y_data_path = './data/target.npy' # end-effector position\n",
    "        \n",
    "        # model parameter\n",
    "        self.device = 'cuda'\n",
    "        self.num_features = 7\n",
    "        self.num_conditions = 3 + 4 + 1 # position + posture + noise = 3-dim + 4-dim + 1-dim \n",
    "        self.num_transforms = 12\n",
    "        self.subnet_shape = [1024] * 4\n",
    "        self.activation = nn.LeakyReLU\n",
    "        \n",
    "        \n",
    "        # training\n",
    "        self.lr = 4e-5\n",
    "        self.lr_decay = 3e-2\n",
    "        self.noise_esp = 1e-3\n",
    "        self.num_epochs = 2\n",
    "        self.num_steps_save = 2000\n",
    "        self.num_test_data = 60\n",
    "        self.num_test_samples = 40\n",
    "        self.save_path = './weights/NSF.pth'\n",
    "        \n",
    "        # log\n",
    "        self.err_his_path = './log/err_his.npy'\n",
    "        self.train_loss_his_path = './log/train_loss_his.npy'\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "panda = Robot(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "X = load_numpy(file_path=config.x_data_path)\n",
    "y = load_numpy(file_path=config.y_data_path)\n",
    "\n",
    "if len(X) == 0:\n",
    "    X, y = panda.random_sample_joint_config(num_samples=100_0000, return_ee=True)\n",
    "    np.save(file=config.x_data_path, arr=X)\n",
    "    np.save(file=config.y_data_path, arr=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dimension reduction model\n",
    "hnne = HNNE(dim=4, ann_threshold=1000)\n",
    "X_transformed = hnne.fit_transform(X=X[:100_0000], dim=4, verbose=True)\n",
    "y = np.column_stack((y, X_transformed))\n",
    "ds = create_dataset(features=X, targets=y, enable_normalize=False)\n",
    "loader = ds.create_loader(shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Generative model, NSF\n",
    "# Neural spline flow (NSF) with 3 sample features and 5 context features\n",
    "flow = NSF(features=config.num_features, \n",
    "           context=config.num_conditions, \n",
    "           transforms=config.num_transforms, \n",
    "           randperm=True, \n",
    "           activation=config.activation, \n",
    "           hidden_features=config.subnet_shape).to(config.device)\n",
    "flow.load_state_dict(state_dict=torch.load(config.save_path))\n",
    "\n",
    "# Train to maximize the log-likelihood\n",
    "optimizer = AdamW(flow.parameters(), lr=config.lr, weight_decay=config.lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_small_noise_to_batch(batch, esp: float = config.noise_esp, eval: bool = False):\n",
    "    x, y = batch\n",
    "    if eval:\n",
    "        std = torch.zeros((x.shape[0], 1)).to(x.device)\n",
    "        y = torch.column_stack((y, std))\n",
    "    else:\n",
    "        std = torch.rand((x.shape[0], 1)).to(x.device)\n",
    "        y = torch.column_stack((y, std))\n",
    "        noise = torch.normal(mean=torch.zeros_like(input=x), std=torch.repeat_interleave(input=std, repeats=x.shape[1], dim=1))\n",
    "        x = x + esp * noise\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_l2_err(config, step=None, model=flow):\n",
    "    num_data, num_samples = config.num_test_data, config.num_test_samples\n",
    "    batch = next(iter(loader))\n",
    "    x, y = add_small_noise_to_batch(batch, eval=True)\n",
    "    assert num_data < len(x)\n",
    "\n",
    "    errs = np.zeros((num_data*num_samples,))\n",
    "    log_probs = np.zeros((num_data*num_samples,))\n",
    "    rand = np.random.randint(low=0, high=len(x), size=num_data)\n",
    "    \n",
    "    step = 0\n",
    "    for nd in rand:\n",
    "        x_hat = model(y[nd]).sample((num_samples,))\n",
    "        log_prob = model(y[nd]).log_prob(x_hat)\n",
    "        \n",
    "        x_hat = x_hat.detach().cpu().numpy()\n",
    "        log_prob = -log_prob.detach().cpu().numpy()\n",
    "        ee_pos = y[nd].detach().cpu().numpy()\n",
    "        # ee_pos = ee_pos * (ds.targets_max - ds.targets_min) + ds.targets_min\n",
    "        ee_pos = ee_pos[:3]\n",
    "        \n",
    "        for q, lp in zip(x_hat, log_prob):\n",
    "            errs[step] = panda.dist_fk(q=q, ee_pos=ee_pos)\n",
    "            log_probs[step] = lp     \n",
    "            step += 1\n",
    "    print(f'step={step}')\n",
    "    df = pd.DataFrame(np.column_stack((errs, log_probs)), columns=['l2_err', 'log_prob'])\n",
    "    return df, errs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch):\n",
    "    x, y = add_small_noise_to_batch(batch)\n",
    "        \n",
    "    loss = -flow(y).log_prob(x)  # -log p(x | y)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "err_his = load_numpy(file_path=config.err_his_path)\n",
    "loss_his = load_numpy(file_path=config.train_loss_his_path)\n",
    "for ep in range(config.num_epochs):\n",
    "    t = tqdm(loader)\n",
    "    for batch in t:\n",
    "        loss = train_step(model=flow, batch=batch)\n",
    "        \n",
    "        loss_his = np.concatenate((loss_his, [loss]))\n",
    "        bar = {\n",
    "            \"loss\": f\"{np.round(loss, 3)}/{np.round(loss_his.mean(), 3)}\",\n",
    "            \"ep\": ep,\n",
    "        }\n",
    "        t.set_postfix(bar, refresh=True)\n",
    "\n",
    "        step += 1\n",
    "        if step % config.num_steps_save == 0:\n",
    "            torch.save(flow.state_dict(), config.save_path)\n",
    "            np.save(config.train_loss_his_path, loss_his)\n",
    "            df, err = test_l2_err(config, step=step)\n",
    "            print(df.describe())\n",
    "            err_his = np.concatenate((err_his, [err]))\n",
    "            np.save(config.err_his_path, err_his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, err = test_l2_err(config)\n",
    "ax1 = df.plot.scatter(x='log_prob', y='l2_err')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflow = FlowModule(\n",
    "    transforms=flow.transforms, \n",
    "    base= Unconditional(\n",
    "            BoxUniform,\n",
    "            -torch.ones((7,))*.5,\n",
    "            torch.ones((7,))*.5,\n",
    "            buffer=True,\n",
    "        ))\n",
    "    \n",
    "nflow.to('cuda')\n",
    "df, err = test_l2_err(num_data=num_test_data, num_samples=num_test_samples, model=nflow)\n",
    "ax1 = df.plot.scatter(x='log_prob', y='l2_err')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pose(num_data, num_samples, model=flow):\n",
    "    batch = next(iter(loader))\n",
    "    x, y = add_small_noise_to_batch(batch, eval=True)\n",
    "    assert num_data < len(x)\n",
    "    \n",
    "    x_hats = np.array([])\n",
    "    pidxs = np.array([])\n",
    "    errs = np.array([])\n",
    "    log_probs = np.array([])\n",
    "    rand = np.random.randint(low=0, high=len(x), size=num_data)\n",
    "    \n",
    "    for nd in rand:\n",
    "        x_hat = model(y[nd]).sample((num_samples,))\n",
    "        log_prob = model(y[nd]).log_prob(x_hat)\n",
    "        \n",
    "        x_hat = x_hat.detach().cpu().numpy()\n",
    "        log_prob = -log_prob.detach().cpu().numpy()\n",
    "        target = y[nd].detach().cpu().numpy()\n",
    "        # ee_pos = ee_pos * (ds.targets_max - ds.targets_min) + ds.targets_min\n",
    "        ee_pos = target[:3]\n",
    "        \n",
    "        for q in x_hat:\n",
    "            err = panda.dist_fk(q=q, ee_pos=ee_pos)\n",
    "            errs = np.concatenate((errs, [err]))\n",
    "        x_hats = np.concatenate((x_hats, x_hat.reshape(-1)))\n",
    "        pidx = target[3:-1]\n",
    "        pidx = np.tile(pidx, (num_samples, 1))\n",
    "\n",
    "        pidxs = np.concatenate((pidxs, pidx.reshape(-1)))\n",
    "        log_probs = np.concatenate((log_probs, log_prob))\n",
    "\n",
    "    x_hats = x_hats.reshape((-1, panda.dof))\n",
    "    pidxs = pidxs.reshape((len(x_hats), -1))\n",
    "    return x_hats, pidxs, errs, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hats, pidxs, errs, log_porbs = show_pose(num_data=5, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/x_hats', arr=x_hats)\n",
    "np.save('./data/pidxs', pidxs)\n",
    "np.save('./data/errs', errs)\n",
    "np.save('./data/log_porbs', log_porbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hats = np.load('./data/x_hats.npy')\n",
    "pidxs = np.load('./data/pidxs.npy')\n",
    "errs = np.load('./data/errs.npy')\n",
    "log_porbs = np.load('./data/log_porbs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside_same_pidx(x_hats, pidxs):\n",
    "    pre_pidx = None\n",
    "    qs = np.array([])\n",
    "    for q, pidx in zip(x_hats, pidxs):\n",
    "        if pre_pidx is None or np.array_equal(pre_pidx, pidx):\n",
    "            qs = np.concatenate((qs, q))\n",
    "        else:\n",
    "            break\n",
    "        pre_pidx = pidx\n",
    "    qs = qs.reshape((-1, panda.dof))\n",
    "    for q in qs:\n",
    "        panda.plot(q, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_same_pidx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(x_hats):\n",
    "    for i, q in enumerate(x_hats):\n",
    "        panda.plot(q, q)\n",
    "        print(f'step={i}, pidx={pidxs[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, sample_ans_q = panda.path_generate_via_stable_joint_traj()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
