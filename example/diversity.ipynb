{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import torch\n",
    "from tqdm import trange\n",
    "from paik.solver import Solver\n",
    "from paik.settings import (\n",
    "    DEFAULT_NSF,\n",
    "    DEFULT_SOLVER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "WORKDIR = \"/home/luca/paik\"\n",
    "\n",
    "record_dir = f\"{WORKDIR}/record/{datetime.today().strftime('%Y_%m_%d')}\"\n",
    "os.makedirs(record_dir, exist_ok=True)\n",
    "\n",
    "solver_param = DEFULT_SOLVER\n",
    "solver_param.workdir = WORKDIR\n",
    "solver = Solver(solver_param=solver_param)\n",
    "\n",
    "num_seeds = 2000\n",
    "num_sols = num_seeds\n",
    "num_poses = 1000\n",
    "base_stds = np.arange(0.1, 1.5, 0.1)  # start, stop, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_ik_sols(target_pose, num_seeds):\n",
    "    seeds, _ = solver._robot.sample_joint_angles_and_poses(\n",
    "        n=num_seeds, return_torch=False\n",
    "    )\n",
    "    numer_ik = np.empty((num_seeds, solver.n))\n",
    "    for i in range(num_seeds):\n",
    "        numer_ik[i] = solver.robot.inverse_kinematics_klampt(\n",
    "            pose=target_pose, seed=seeds[i]\n",
    "        )\n",
    "    return numer_ik\n",
    "\n",
    "\n",
    "_, P = solver._robot.sample_joint_angles_and_poses(n=num_poses, return_torch=False)\n",
    "\n",
    "J_ground_truth = np.empty((num_poses, num_sols, solver.n))\n",
    "for i in trange(num_poses):\n",
    "    J_ground_truth[i] = get_numerical_ik_sols(P[i], num_seeds)\n",
    "\n",
    "# Save to repeat the same experiment on NODEIK\n",
    "np.save(f\"{record_dir}/numerical_ik_sols.npy\", J_ground_truth)\n",
    "np.save(f\"{record_dir}/poses.npy\", P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmd import mmd_evaluate_multiple_poses\n",
    "\n",
    "l2_mean = np.empty((len(base_stds)))\n",
    "ang_mean = np.empty((len(base_stds)))\n",
    "mmd_mean = np.empty((len(base_stds)))\n",
    "J_hat_paik = np.empty((len(base_stds), num_poses, num_sols, solver.n))\n",
    "\n",
    "for i, std in enumerate(base_stds):\n",
    "    solver.base_std = std\n",
    "    P_expand_dim = (\n",
    "        np.expand_dims(P, axis=1).repeat(num_sols, axis=1).reshape(-1, P.shape[-1])\n",
    "    )\n",
    "\n",
    "    F = solver.F[\n",
    "        solver.P_knn.kneighbors(\n",
    "            np.atleast_2d(P), n_neighbors=num_sols, return_distance=False\n",
    "        ).flatten()\n",
    "    ]\n",
    "    J_hat = solver.solve_batch(P_expand_dim, F, 1)\n",
    "    l2, ang = solver.evaluate_pose_error_J3d_P2d(J_hat, P_expand_dim, return_all=True)\n",
    "    J_hat = J_hat.reshape(num_poses, num_sols, -1)\n",
    "    J_hat_paik[i] = J_hat\n",
    "    l2_mean[i] = l2.mean()\n",
    "    ang_mean[i] = ang.mean()\n",
    "    mmd_mean[i] = mmd_evaluate_multiple_poses(\n",
    "        J_hat, J_ground_truth, num_poses=num_poses\n",
    "    )\n",
    "    assert not np.isnan(mmd_mean[i])\n",
    "\n",
    "np.save(f\"{record_dir}/J_hat_paik.npy\", J_hat_paik)\n",
    "df_paik = pd.DataFrame(\n",
    "    {\"l2\": l2_mean, \"ang\": ang_mean, \"mmd\": mmd_mean, \"base_std\": base_stds}\n",
    ")\n",
    "df_paik.to_pickle(f\"{record_dir}/paik_posture_mmd_std.pkl\")\n",
    "df_paik.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikflow.utils import set_seed\n",
    "from ikflow.model_loading import get_ik_solver\n",
    "\n",
    "set_seed()\n",
    "# Build IKFlowSolver and set weights\n",
    "ik_solver, _ = get_ik_solver(\"panda__full__lp191_5.25m\")\n",
    "l2_flow = np.empty((len(base_stds)))\n",
    "ang_flow = np.empty((len(base_stds)))\n",
    "mmd_flow = np.empty((len(base_stds)))\n",
    "J_hat_ikflow = np.empty((len(base_stds), num_poses, num_sols, solver.n))\n",
    "\n",
    "for i, std in enumerate(base_stds):\n",
    "    J_flow = np.array(\n",
    "        [ik_solver.solve(p, n=num_sols, latent_scale=std).cpu().numpy() for p in P]\n",
    "    )  # (num_sols, num_poses, n)\n",
    "    J_hat_ikflow[i] = J_flow\n",
    "    l2, ang = solver.evaluate_pose_error_J3d_P2d(\n",
    "        J_flow.transpose(1, 0, 2), P, return_all=True\n",
    "    )\n",
    "    l2_flow[i] = l2.mean()\n",
    "    ang_flow[i] = ang.mean()\n",
    "    mmd_flow[i] = mmd_evaluate_multiple_poses(\n",
    "        J_flow, J_ground_truth, num_poses=num_poses\n",
    "    )\n",
    "\n",
    "np.save(f\"{record_dir}/J_hat_ikflow.npy\", J_hat_ikflow)\n",
    "df_flow = pd.DataFrame(\n",
    "    {\"l2\": l2_flow, \"ang\": ang_flow, \"mmd\": mmd_flow, \"base_std\": base_stds}\n",
    ")\n",
    "df_flow.to_pickle(f\"{record_dir}/ikflow_posture_mmd_std.pkl\")\n",
    "df_flow.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mmd posture diversity and present\n",
    "Note that before run the following code, you need to run\n",
    "- conda activate nodeik\n",
    "- python nodeik_experiments.py\n",
    "\n",
    "to obtain `df_nodeik` data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "WORKDIR = \"/home/luca/paik\"\n",
    "\n",
    "date = datetime.today().strftime(\"%Y_%m_%d\")\n",
    "date = \"2024_02_24\"\n",
    "record_dir = f\"{WORKDIR}/record/{date}\"\n",
    "df_paik = pd.read_pickle(f\"{record_dir}/paik_posture_mmd_std.pkl\")\n",
    "df_ikflow = pd.read_pickle(f\"{record_dir}/ikflow_posture_mmd_std.pkl\")\n",
    "df_nodeik = pd.read_pickle(f\"{record_dir}/nodeik_posture_mmd_std.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paik.rename(columns={\"std\": \"base_std\"}, inplace=True)\n",
    "df_ikflow.rename(columns={\"std\": \"base_std\"}, inplace=True)\n",
    "df_nodeik.rename(columns={\"std\": \"base_std\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"l2_paik\": df_paik.l2.values * 1000,\n",
    "        \"ang_paik\": df_paik.ang.values,\n",
    "        \"mmd_paik\": df_paik.mmd.values,\n",
    "        \"l2_ikflow\": df_ikflow.l2.values * 1000,\n",
    "        \"ang_ikflow\": df_ikflow.ang.values,\n",
    "        \"mmd_ikflow\": df_ikflow.mmd.values,\n",
    "        \"l2_nodeik\": df_nodeik.l2.values * 1000,\n",
    "        \"ang_nodeik\": df_nodeik.ang.values,\n",
    "        \"mmd_nodeik\": df_nodeik.mmd.values,\n",
    "        \"base_std\": df_paik.base_std.values,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.to_pickle(f\"{record_dir}/three_methods_posture_mmd_std.pkl\")\n",
    "\n",
    "df_l2 = pd.DataFrame(\n",
    "    {\n",
    "        \"paik\": df_paik.l2.values * 1000,\n",
    "        \"IKFlow\": df_ikflow.l2.values * 1000,\n",
    "        \"NODEIK\": df_nodeik.l2.values * 1000,\n",
    "        \"base std\": df_paik.base_std.values,\n",
    "    }\n",
    ")\n",
    "\n",
    "df_mmd = pd.DataFrame(\n",
    "    {\n",
    "        \"paik\": df_paik.mmd.values,\n",
    "        \"IKFlow\": df_ikflow.mmd.values,\n",
    "        \"NODEIK\": df_nodeik.mmd.values,\n",
    "        \"base std\": df_paik.base_std.values,\n",
    "    }\n",
    ")\n",
    "\n",
    "fontsize = 24\n",
    "ax1 = df_l2.plot(x=\"base std\", grid=True, fontsize=fontsize)\n",
    "ax1.set_ylabel(\"L2 Error (mm)\", fontsize=fontsize)\n",
    "ax1.set_xlabel(\"Base std\", fontsize=fontsize)\n",
    "ax1.set_title(\"Position Error\", fontsize=fontsize)\n",
    "ax1.legend(fontsize=fontsize)\n",
    "\n",
    "ax1 = df_mmd.plot(x=\"base std\", grid=True, fontsize=fontsize)\n",
    "ax1.set_ylabel(\"MMD Score\", fontsize=fontsize)\n",
    "ax1.set_xlabel(\"Base std\", fontsize=fontsize)\n",
    "ax1.set_title(\"MMD Score\", fontsize=fontsize)\n",
    "ax1.legend(fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load J_hat's, J, and P for further mmd research\n",
    "\n",
    "Apply inverse multi-quadric kernel as rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "J_hat_paik = np.load(f\"{record_dir}/J_hat_paik.npy\")\n",
    "J_hat_ikflow = np.load(f\"{record_dir}/J_hat_ikflow.npy\")\n",
    "J_hat_nodeik = np.load(f\"{record_dir}/J_hat_nodeik.npy\")\n",
    "J_ground_truth = np.load(f\"{record_dir}/numerical_ik_sols.npy\")\n",
    "\n",
    "J_hat_paik.shape, J_hat_ikflow.shape, J_hat_nodeik.shape, J_ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from mmd import mmd_evaluate_multiple_poses\n",
    "\n",
    "num_base_stds, num_poses, num_sols, num_dofs = J_hat_paik.shape\n",
    "mmd_paik, mmd_ikflow, mmd_nodeik = (\n",
    "    np.empty((num_base_stds)),\n",
    "    np.empty((num_base_stds)),\n",
    "    np.empty((num_base_stds)),\n",
    ")\n",
    "use_inverse_multi_quadric = True\n",
    "\n",
    "\n",
    "for i in (pbar := trange(num_base_stds)):\n",
    "    mmd_paik[i] = mmd_evaluate_multiple_poses(\n",
    "        J_hat_paik[i],\n",
    "        J_ground_truth,\n",
    "        num_poses=num_poses,\n",
    "        use_inverse_multi_quadric=use_inverse_multi_quadric,\n",
    "    )\n",
    "    mmd_ikflow[i] = mmd_evaluate_multiple_poses(\n",
    "        J_hat_ikflow[i],\n",
    "        J_ground_truth,\n",
    "        num_poses=num_poses,\n",
    "        use_inverse_multi_quadric=use_inverse_multi_quadric,\n",
    "    )\n",
    "    mmd_nodeik[i] = mmd_evaluate_multiple_poses(\n",
    "        J_hat_nodeik[i],\n",
    "        J_ground_truth,\n",
    "        num_poses=num_poses,\n",
    "        use_inverse_multi_quadric=use_inverse_multi_quadric,\n",
    "    )\n",
    "    pbar.set_postfix(\n",
    "        {\n",
    "            \"mmd_paik\": mmd_paik[i],\n",
    "            \"mmd_ikflow\": mmd_ikflow[i],\n",
    "            \"mmd_nodeik\": mmd_nodeik[i],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_mmd = pd.DataFrame(\n",
    "    {\n",
    "        \"mmd_paik\": mmd_paik,\n",
    "        \"mmd_ikflow\": mmd_ikflow,\n",
    "        \"mmd_nodeik\": mmd_nodeik,\n",
    "        \"base_std\": df.base_std.values,\n",
    "    }\n",
    ")\n",
    "df_mmd.plot(\n",
    "    x=\"base_std\",\n",
    "    y=[\"mmd_paik\", \"mmd_ikflow\", \"mmd_nodeik\"],\n",
    "    title=\"mmd vs. Base Std\",\n",
    "    grid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mmd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_X, num_Y = 100, 101\n",
    "num_features = 7\n",
    "num_samples = num_X + num_Y\n",
    "\n",
    "X, Y = torch.randn(num_X, num_features) * 3, torch.randn(num_Y, num_features) * (-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = torch.vstack([X, Y])\n",
    "XY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = torch.cat([X, Y], dim=0)\n",
    "total0 = total.unsqueeze(0).expand(\n",
    "    int(total.size(0)), int(total.size(0)), int(total.size(1))\n",
    ")\n",
    "total1 = total.unsqueeze(1).expand(\n",
    "    int(total.size(0)), int(total.size(0)), int(total.size(1))\n",
    ")\n",
    "L2_distance_total = ((total0 - total1) ** 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_distance = torch.cdist(XY, XY) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_distance_total.shape, L2_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the difference between the L2_distance and L2_distance_total\n",
    "(L2_distance_total - L2_distance).abs().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy, xy = torch.mm(X, X.t()), torch.mm(Y, Y.t()), torch.mm(X, Y.t())\n",
    "\n",
    "rx = xx.diag().unsqueeze(0).expand_as(xx)\n",
    "ry = yy.diag().unsqueeze(0).expand_as(yy)\n",
    "\n",
    "dist_xx = torch.clamp(rx.t() + rx - 2.0 * xx, 0, torch.inf)\n",
    "# dist_yy = torch.clamp(ry.t() + ry - 2.0 * yy, 0, torch.inf)\n",
    "# dist_xy = torch.clamp(rx.t() + ry - 2.0 * xy, 0, torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = torch.cdist(X, X) ** 2\n",
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.randn(2, 3)\n",
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
