{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ikflow/config.py | Using device: 'cuda:0'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe0984e1050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Optional\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common.evaluate import evaluate_pose_error_J3d_P2d\n",
    "from paik.solver import NSF, PAIK, Solver, get_solver\n",
    "from ikp import get_robot, numerical_inverse_kinematics_batch, compute_mmd, gaussian_kernel, inverse_multiquadric_kernel\n",
    "\n",
    "import torch\n",
    "\n",
    "# set the same random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "from numpy import ndarray\n",
    "from tqdm import tqdm, trange\n",
    "import itertools\n",
    "from tqdm.contrib import itertools as tqdm_itertools\n",
    "\n",
    "from paik.file import load_pickle, save_pickle\n",
    "from latent_space_sampler import Retriever\n",
    "\n",
    "\n",
    "def solver_batch(solver, P, num_sols, std=0.001, retriever: Optional[Retriever] = None, J_ref=None, radius=0.0, num_clusters=30, use_samples=int(5e6), verbose=False, retr_type='cluster'):\n",
    "    # shape: (num_sols, num_poses, m)\n",
    "    P_num_sols = np.expand_dims(P, axis=0).repeat(num_sols, axis=0)\n",
    "    # shape: (num_sols*num_poses, n)\n",
    "    P_num_sols = P_num_sols.reshape(-1, P.shape[-1])\n",
    "    \n",
    "    J_ref_num_sols = None\n",
    "    if J_ref is not None:\n",
    "        J_ref_num_sols = np.expand_dims(J_ref, axis=0).repeat(num_sols, axis=0)\n",
    "        J_ref_num_sols = J_ref_num_sols.reshape(-1, J_ref.shape[-1])\n",
    "\n",
    "    if isinstance(solver, PAIK):\n",
    "        solver.base_std = std\n",
    "        F = solver.get_reference_partition_label(P=P, J=J_ref, num_sols=num_sols)\n",
    "        # shape: (1, num_sols*num_poses, n)\n",
    "        J_hat = solver.generate_ik_solutions(P=P_num_sols, F=F, verbose=verbose)\n",
    "    elif isinstance(solver, NSF):\n",
    "        if retriever is None:\n",
    "            solver.base_std = std\n",
    "            J_hat = solver.generate_ik_solutions(P=P, num_sols=num_sols)\n",
    "        else:\n",
    "            if retr_type == 'cluster':\n",
    "                latents = retriever.cluster_retriever(seeds=J_ref, num_poses=P.shape[0], num_sols=num_sols, max_samples=use_samples, radius=radius, n_clusters=num_clusters)\n",
    "            elif retr_type == 'random':\n",
    "                latents = retriever.random_retriever(seeds=J_ref, num_poses=P.shape[0], max_samples=use_samples, num_sols=num_sols, radius=radius)\n",
    "            elif retr_type == 'numerical':\n",
    "                latents = retriever.numerical_retriever(poses=P, seeds=J_ref, num_sols=num_sols, radius=radius)\n",
    "            J_hat = solver.generate_ik_solutions(P=P_num_sols, latents=latents, verbose=verbose)\n",
    "    else:\n",
    "        J_hat = np.empty((num_sols, P.shape[0], solver.robot.n_dofs))\n",
    "        P_torch = torch.tensor(P, dtype=torch.float32).to('cuda')\n",
    "        for i, p in enumerate(P_torch):\n",
    "            solutions = solver.generate_ik_solutions(\n",
    "                p,\n",
    "                num_sols,\n",
    "                latent_distribution='gaussian',\n",
    "                latent_scale=std,\n",
    "                clamp_to_joint_limits=False,\n",
    "            )\n",
    "            J_hat[:, i] = solutions.detach().cpu().numpy()\n",
    "    # return shape: (num_sols, num_poses, n)\n",
    "    return J_hat.reshape(num_sols, P.shape[0], -1)\n",
    "\n",
    "\n",
    "def random_ikp(robot, P: np.ndarray, solve_fn_batch: Any, num_poses: int, num_sols: int, J_hat_num: Optional[np.ndarray] = None):\n",
    "    begin = time()\n",
    "    # shape: (num_poses, num_sols, num_dofs or n)\n",
    "    J_hat = solve_fn_batch(P=P, num_sols=num_sols)\n",
    "    assert J_hat.shape == (\n",
    "        num_sols, num_poses, robot.n_dofs), f\"J_hat shape {J_hat.shape} is not correct\"\n",
    "\n",
    "    l2, ang = evaluate_pose_error_J3d_P2d(\n",
    "        #init(num_sols, num_poses, num_dofs or n)\n",
    "        robot, J_hat, P, return_all=True\n",
    "    )\n",
    "    \n",
    "    num_sols_time_ms = round((time() - begin) / len(P), 3) * 1000\n",
    "    \n",
    "    ret_results = {}\n",
    "    l2_mean = np.nanmean(l2)\n",
    "    ang_mean = np.nanmean(ang)\n",
    "    \n",
    "    ret_results[f'{num_poses}_{num_sols}'] = {\n",
    "        \"l2_mm\": l2_mean * 1000,\n",
    "        \"ang_deg\": np.rad2deg(ang_mean),\n",
    "        \"num_sols_time_ms\": num_sols_time_ms\n",
    "    }\n",
    "    \n",
    "    if J_hat_num is None:\n",
    "        mmd_guassian = np.nan\n",
    "        mmd_imq = np.nan\n",
    "    else:\n",
    "        mmd_guassian_list = np.empty((num_poses))\n",
    "        mmd_imq_list = np.empty((num_poses))\n",
    "        for i in range(num_poses):\n",
    "            mmd_guassian_list[i] = compute_mmd(J_hat[:, i], J_hat_num[:, i], kernel=gaussian_kernel)\n",
    "            mmd_imq_list[i] = compute_mmd(J_hat[:, i], J_hat_num[:, i], kernel=inverse_multiquadric_kernel)\n",
    "        mmd_guassian = mmd_guassian_list.mean()\n",
    "        mmd_imq = mmd_imq_list.mean()\n",
    "        \n",
    "    ret_results[f'{num_poses}_{num_sols}']['mmd_guassian'] = mmd_guassian\n",
    "    ret_results[f'{num_poses}_{num_sols}']['mmd_imq'] = mmd_imq\n",
    "\n",
    "    return J_hat, ret_results\n",
    "\n",
    "def nested_dict_to_2d_dict(nested_dict: dict):\n",
    "    ret_dict = {}\n",
    "    for key, value in nested_dict.items():\n",
    "        if isinstance(value, dict):\n",
    "            for k, v in value.items():\n",
    "                ret_dict[f\"{key}_{k}\"] = v\n",
    "        else:\n",
    "            ret_dict[key] = value\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "def random_ikp_with_mmd(record_dir, robot_name, num_poses, num_sols, paik_std_list, radius_list, num_clusters_list):\n",
    "    robot = get_robot(robot_name)\n",
    "    nsf = get_solver(arch_name=\"nsf\", robot=robot, load=True, work_dir='/home/luca/paik')\n",
    "    retriever = Retriever(nsf)\n",
    "    max_samples = int(5e6)\n",
    "    retriever.init([max_samples], num_clusters_list)\n",
    "    paik = get_solver(arch_name=\"paik\", robot=robot, load=True, work_dir='/home/luca/paik')\n",
    "    \n",
    "    file_path = f\"{record_dir}/random_ikp_with_mmd_{robot_name}_{num_poses}_{num_sols}.pkl\"\n",
    "    \n",
    "    results = {}\n",
    "    # if os.path.exists(file_path):\n",
    "    #     results = load_pickle(file_path)\n",
    "    #     ret_results = nested_dict_to_2d_dict(results)\n",
    "    #     df = pd.DataFrame(ret_results).T\n",
    "    #     # round to 4 decimal places\n",
    "    #     df = df.round(4)\n",
    "    #     print(df)\n",
    "    #     print(f\"Results are loaded from {file_path}\")\n",
    "    # else:\n",
    "    #     print(f\"Results are not found in {file_path}\")\n",
    "        \n",
    "    if 'P' in results:\n",
    "        P = results['P']\n",
    "    else:\n",
    "        _, P = nsf.robot.sample_joint_angles_and_poses(n=num_poses)\n",
    "        \n",
    "    print(f\"Start numerical IK...\")\n",
    "    # num's variable: num_poses, num_sols\n",
    "    num_solver_batch = partial(numerical_inverse_kinematics_batch, solver=nsf)    \n",
    "    J_hat_num, results['num'] = random_ikp(robot, P, num_solver_batch, num_poses=num_poses, num_sols=num_sols)\n",
    "    save_pickle(file_path, results)    \n",
    "    print(f\"Results numerical IK are saved in {file_path}\")\n",
    "    \n",
    "    print(f\"Start paik...\")\n",
    "    # paik's variable: num_poses, num_sols, std, \n",
    "    for std in tqdm(paik_std_list):\n",
    "        paik_solver_batch = partial(solver_batch, solver=paik, std=std)\n",
    "        name = f'paik_{std}_gaussian'\n",
    "        if name not in results:\n",
    "            _, results[name] = random_ikp(robot, P, paik_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results) \n",
    "    print(f\"Results paik are saved in {file_path}\")\n",
    "    \n",
    "    print(f\"Start nsf w/o retreiver...\")\n",
    "    # nsf's variable: std\n",
    "    for std in tqdm(paik_std_list):\n",
    "        nsf_solver_batch = partial(solver_batch, solver=nsf, std=std, retriever=None)\n",
    "        name = f'nsf_gaussian_{std}'\n",
    "        if name not in results:\n",
    "            _, results[name] = random_ikp(robot, P, nsf_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results)\n",
    "\n",
    "    print(f\"Start nsf with cluster retriever...\")    \n",
    "    # nsf's variable: num_poses, num_sols, max_samples, radius, num_clusters\n",
    "    use_samples = max_samples\n",
    "    for radius, num_clusters in tqdm_itertools.product(radius_list, num_clusters_list):\n",
    "        nsf_solver_batch = partial(solver_batch, solver=nsf, radius=radius, num_clusters=num_clusters, retriever=retriever, use_samples=use_samples, retr_type='cluster')\n",
    "        name = f'nsf_cluster_{radius}_{num_clusters}'\n",
    "        if name not in results:\n",
    "            _, results[name] = random_ikp(robot, P, nsf_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results)\n",
    "    print(f\"Results nsf with cluster retriever are saved in {file_path}\")\n",
    "    \n",
    "    print(f\"Start nsf with random retriever...\")\n",
    "    # nsf's variable: num_poses, num_sols, max_samples, radius\n",
    "    use_samples = min(max_samples, num_clusters)\n",
    "    use_samples = max(use_samples, num_sols)\n",
    "    for radius in tqdm(radius_list):\n",
    "        nsf_solver_batch = partial(solver_batch, solver=nsf, radius=radius, retriever=retriever, use_samples=use_samples, retr_type='random')\n",
    "        name = f'nsf_random_{radius}'\n",
    "        if name not in results:\n",
    "            _, results[name] = random_ikp(robot, P, nsf_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results)\n",
    "            \n",
    "    print(f\"Start nsf with numerical retriever...\")\n",
    "    # nsf's variable: num_poses, num_sols, max_samples, radius\n",
    "    for radius in radius_list:\n",
    "        nsf_solver_batch = partial(solver_batch, solver=nsf, radius=radius, retriever=retriever, retr_type='numerical', J_ref=None)\n",
    "        name = f'nsf_numerical_{radius}'\n",
    "        if name not in results:\n",
    "            _, results[name] = random_ikp(robot, P, nsf_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results)\n",
    "    \n",
    "    ret_results = nested_dict_to_2d_dict(results)\n",
    "\n",
    "    df = pd.DataFrame(ret_results).T\n",
    "    # round to 4 decimal places\n",
    "    df = df.round(4)\n",
    "    print(df)\n",
    "    file_path = f\"{record_dir}/random_ikp_with_mmd_evaluation_results_{robot_name}_{num_poses}_{num_sols}.csv\"\n",
    "    df.to_csv(file_path)\n",
    "    print(f\"Results are saved in {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to evaluate panda...\n",
      "WorldModel::LoadRobot: /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "joint mimic: no multiplier, using default value of 1 \n",
      "joint mimic: no offset, using default value of 0 \n",
      "URDFParser: Link size: 17\n",
      "URDFParser: Joint size: 12\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link0.dae (59388 verts, 20478 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link1.dae (37309 verts, 12516 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link2.dae (37892 verts, 12716 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link3.dae (42512 verts, 14233 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link4.dae (43520 verts, 14620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link5.dae (54770 verts, 18327 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link6.dae (64086 verts, 21620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link7.dae (35829 verts, 12077 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/hand.dae (20896 verts, 7078 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "URDFParser: Done loading robot file /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "Initialized robot collision data structures in time 0.395625\n",
      "[Warning] Error(s) in loading state_dict for Flow:\n",
      "\tsize mismatch for base._0: copying a param with shape torch.Size([1, 7]) from checkpoint, the shape in current model is torch.Size([7]).. Please check the model path /home/luca/paik/weights/panda/0115-0234/model.pth.\n",
      "[WARNING] /home/luca/paik/weights/panda/0115-0234/J_knn.pth: file not exist and return None.. Load training data instead.\n",
      "[SUCCESS] P_knn load from /home/luca/paik/weights/panda/P_knn-5000000-7-7-1.pth.\n",
      "[SUCCESS] J_knn load from /home/luca/paik/weights/panda/J_knn-5000000-7-7-1.pth.\n",
      "[INFO] Load latent variable from /home/luca/paik/weights/panda/Z.npy.\n",
      "Start to initialize cluster info...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006300926208496094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c912789c2f5a4454b38bfc27ce4de36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to initialize numerical retriever...\n",
      "[SUCCESS] load from /home/luca/paik/weights/panda/0904-1939\n",
      "[SUCCESS] load best date 0904-1939 with l2 0.00297 from /home/luca/paik/weights/panda/best_date_paik.csv.\n",
      "Start numerical IK...\n",
      "Results numerical IK are saved in /mnt/d/pads/Documents/paik_store/record/2024_11_12/random_ikp_with_mmd_panda_100_100.pkl\n",
      "Start nsf w/o retreiver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.18it/s]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start nsf with cluster retriever...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007058620452880859,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 6,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7a4385c1fe42b6ba2cc41e260cba46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to cluster retriever with max_samples: 5000000, num_poses: 100, num_sols: 100, radius: 0.001, n_clusters: 70\n",
      "Start to cluster retriever with max_samples: 5000000, num_poses: 100, num_sols: 100, radius: 0.1, n_clusters: 70\n",
      "Start to cluster retriever with max_samples: 5000000, num_poses: 100, num_sols: 100, radius: 0.25, n_clusters: 70\n",
      "Start to cluster retriever with max_samples: 5000000, num_poses: 100, num_sols: 100, radius: 0.5, n_clusters: 70\n",
      "Start to cluster retriever with max_samples: 5000000, num_poses: 100, num_sols: 100, radius: 0.7, n_clusters: 70\n",
      "Start to cluster retriever with max_samples: 5000000, num_poses: 100, num_sols: 100, radius: 0.9, n_clusters: 70\n",
      "Results nsf with cluster retriever are saved in /mnt/d/pads/Documents/paik_store/record/2024_11_12/random_ikp_with_mmd_panda_100_100.pkl\n",
      "Start nsf with random retriever...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to random retriever with max_samples: 100, num_poses: 100, num_sols: 100, radius: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to random retriever with max_samples: 100, num_poses: 100, num_sols: 100, radius: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:03,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to random retriever with max_samples: 100, num_poses: 100, num_sols: 100, radius: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to random retriever with max_samples: 100, num_poses: 100, num_sols: 100, radius: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to random retriever with max_samples: 100, num_poses: 100, num_sols: 100, radius: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:04<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to random retriever with max_samples: 100, num_poses: 100, num_sols: 100, radius: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start nsf with numerical retriever...\n",
      "Start to numerical retriever...\n",
      "Start to numerical retriever...\n",
      "Start to numerical retriever...\n",
      "Start to numerical retriever...\n",
      "Start to numerical retriever...\n",
      "Start to numerical retriever...\n",
      "                                l2_mm  ang_deg  num_sols_time_ms  \\\n",
      "num_100_100                    0.4187   0.0517              49.0   \n",
      "nsf_gaussian_0.001_100_100     3.0865   3.1889              11.0   \n",
      "nsf_gaussian_0.1_100_100       2.8854   1.8070               9.0   \n",
      "nsf_gaussian_0.25_100_100      3.2234   1.7870               9.0   \n",
      "nsf_gaussian_0.5_100_100       3.6623   1.8971               9.0   \n",
      "nsf_gaussian_0.7_100_100       4.2836   2.1465               9.0   \n",
      "nsf_gaussian_0.9_100_100       5.5797   2.7152               9.0   \n",
      "nsf_cluster_0.001_70_100_100   3.4817   1.7853               9.0   \n",
      "nsf_cluster_0.1_70_100_100     3.5516   1.8551               9.0   \n",
      "nsf_cluster_0.25_70_100_100    3.4773   1.8048               9.0   \n",
      "nsf_cluster_0.5_70_100_100     4.1261   2.0331               9.0   \n",
      "nsf_cluster_0.7_70_100_100     5.0015   2.4898               9.0   \n",
      "nsf_cluster_0.9_70_100_100     7.1468   3.4678               9.0   \n",
      "nsf_random_0.001_100_100       3.9019   1.9565               9.0   \n",
      "nsf_random_0.1_100_100         3.9387   1.9831               9.0   \n",
      "nsf_random_0.25_100_100        4.0953   2.0045               9.0   \n",
      "nsf_random_0.5_100_100         4.7281   2.2596               9.0   \n",
      "nsf_random_0.7_100_100         6.0911   2.8934               9.0   \n",
      "nsf_random_0.9_100_100        10.2617   4.1722               9.0   \n",
      "nsf_numerical_0.001_100_100    0.4292   0.0619              15.0   \n",
      "nsf_numerical_0.1_100_100      2.4367   1.1418              16.0   \n",
      "nsf_numerical_0.25_100_100     3.0618   1.5821              18.0   \n",
      "nsf_numerical_0.5_100_100      4.2665   1.9291              16.0   \n",
      "nsf_numerical_0.7_100_100      5.8862   3.0184              16.0   \n",
      "nsf_numerical_0.9_100_100     10.1345   3.9646              15.0   \n",
      "\n",
      "                              mmd_guassian  mmd_imq  \n",
      "num_100_100                            NaN      NaN  \n",
      "nsf_gaussian_0.001_100_100          0.8828   0.6503  \n",
      "nsf_gaussian_0.1_100_100            0.4181   0.3007  \n",
      "nsf_gaussian_0.25_100_100           0.1595   0.1200  \n",
      "nsf_gaussian_0.5_100_100            0.0663   0.0513  \n",
      "nsf_gaussian_0.7_100_100            0.0557   0.0437  \n",
      "nsf_gaussian_0.9_100_100            0.0642   0.0508  \n",
      "nsf_cluster_0.001_70_100_100        0.0813   0.0632  \n",
      "nsf_cluster_0.1_70_100_100          0.0722   0.0562  \n",
      "nsf_cluster_0.25_70_100_100         0.0663   0.0524  \n",
      "nsf_cluster_0.5_70_100_100          0.0599   0.0474  \n",
      "nsf_cluster_0.7_70_100_100          0.0597   0.0469  \n",
      "nsf_cluster_0.9_70_100_100          0.0692   0.0544  \n",
      "nsf_random_0.001_100_100            0.0690   0.0547  \n",
      "nsf_random_0.1_100_100              0.0645   0.0509  \n",
      "nsf_random_0.25_100_100             0.0583   0.0455  \n",
      "nsf_random_0.5_100_100              0.0601   0.0474  \n",
      "nsf_random_0.7_100_100              0.0639   0.0500  \n",
      "nsf_random_0.9_100_100              0.0714   0.0561  \n",
      "nsf_numerical_0.001_100_100         0.8861   0.7000  \n",
      "nsf_numerical_0.1_100_100           0.5575   0.4371  \n",
      "nsf_numerical_0.25_100_100          0.3946   0.3188  \n",
      "nsf_numerical_0.5_100_100           0.2340   0.1934  \n",
      "nsf_numerical_0.7_100_100           0.1412   0.1195  \n",
      "nsf_numerical_0.9_100_100           0.1610   0.1353  \n",
      "Results are saved in /mnt/d/pads/Documents/paik_store/record/2024_11_12/random_ikp_with_mmd_evaluation_results_panda_100_100.csv\n"
     ]
    }
   ],
   "source": [
    "from common.config import Config_IKP\n",
    "config = Config_IKP()\n",
    "\n",
    "config.workdir = '/mnt/d/pads/Documents/paik_store'\n",
    "\n",
    "kwarg = {\n",
    "    'record_dir': config.record_dir,\n",
    "    'robot_name': 'panda',\n",
    "    'num_poses': 100, # 300, 500, 1000\n",
    "    'num_sols': 100,  # 300, 500, 1000\n",
    "    'paik_std_list': [0.001, 0.1, 0.25, 0.5, 0.7, 0.9], # 0.001, 0.1, 0.25, 0.5, 0.7\n",
    "    'radius_list': [0.001, 0.1, 0.25, 0.5, 0.7, 0.9], # 0, 0.1, 0.3, 0.5, 0.7, 0.9\n",
    "    'num_clusters_list': [70] # 13, 16, 19, 25, 30, 40\n",
    "}\n",
    "\n",
    "robot_names = [\"panda\"] # \"panda\", \"fetch\", \"fetch_arm\", \"atlas_arm\", \"atlas_waist_arm\", \"baxter_arm\"\n",
    "\n",
    "for robot_name in robot_names:\n",
    "    print(f\"Start to evaluate {robot_name}...\")\n",
    "    kwarg['robot_name'] = robot_name\n",
    "    random_ikp_with_mmd(**kwarg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(f'{config.record_dir}/random_ikp_with_mmd_evaluation_results_panda_1000_1000.csv', index_col=0)\n",
    "mi = df.index.str.split('_', expand=True)\n",
    "df_mi = df.set_index(mi)\n",
    "# set index names\n",
    "df_mi.index.names = ['solver', 'max_samples', 'radius', 'num_clusters', 'num_poses', 'num_sols']\n",
    "df_mi.reset_index(inplace=True)\n",
    "\n",
    "# swap values in the columns of max_samples and num_poses for solver num\n",
    "df_mi.loc[df_mi.solver == 'num', ['max_samples', 'num_poses']] = df_mi.loc[df_mi.solver == 'num', ['num_poses', 'max_samples']].values\n",
    "# swap values in the columns of radius and num_sols for solver num\n",
    "df_mi.loc[df_mi.solver == 'num', ['radius', 'num_sols']] = df_mi.loc[df_mi.solver == 'num', ['num_sols', 'radius']].values\n",
    "\n",
    "# set new columns as float \n",
    "df_mi[['max_samples', 'radius', 'num_clusters', 'num_poses', 'num_sols']] = df_mi[['max_samples', 'radius', 'num_clusters', 'num_poses', 'num_sols']].astype(float)\n",
    "df_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter nsf\n",
    "df_nsf = df_mi[df_mi.solver == 'nsf']\n",
    "# nsf has variables: max_samples, radius, num_clusters\n",
    "# fix the other variables, e.g. num_poses, num_sols.\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_nsf_linechart(df, hue, x_label, y_labels=['l2_mm', 'mmd_imq']):\n",
    "    df_cp = df.copy()\n",
    "    df_cp = df_cp.sort_values(x_label)\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 12))\n",
    "    for i, y_label in enumerate(y_labels):\n",
    "        sns.lineplot(data=df_cp, x=x_label, y=y_label, hue=hue, marker='o', ax=axs[i])\n",
    "        y_label = y_label.replace('_', ' ').upper()\n",
    "        axs[i].set_title(f'NSF {y_label} vs {x_label.replace(\"_\", \" \").title()}')\n",
    "        axs[i].set_xlabel(f'{x_label.replace(\"_\", \" \").title()}')\n",
    "        axs[i].set_ylabel(y_label)\n",
    "        axs[i].grid()\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "# plot the linechart where x-axis is max_samples, y-axis is mmd_imq\n",
    "# and each line is a different num_clusters. \n",
    "# Fix radius=0, num_poses=1000, num_sols=1000\n",
    "df_cp = df_nsf.copy()\n",
    "# select the rows where nnum_poses=1000, num_sols=1000, radius=0\n",
    "df_cp = df_cp[(df_cp.num_poses == 1000) & (df_cp.num_sols == 1000) & (df_cp.radius == 0)]\n",
    "plot_nsf_linechart(df_cp, hue='num_clusters', x_label='max_samples')\n",
    "\n",
    "# plot the linechart where x-axis is radius, y-axis is mmd_imq\n",
    "# and each line is a different num_clusters. \n",
    "# Fix max_samples=5000000, num_poses=1000, num_sols=1000.\n",
    "df_cp = df_nsf.copy()\n",
    "# select the rows where nnum_poses=1000, num_sols=1000, max_samples=5000000\n",
    "df_cp = df_cp[(df_cp.num_poses == 1000) & (df_cp.num_sols == 1000) & (df_cp.max_samples == 5000000)]\n",
    "plot_nsf_linechart(df_cp, hue='num_clusters', x_label='radius')\n",
    "\n",
    "# plot the linechart where x-axis is max_samples, y-axis is mmd_imq\n",
    "# and each line is a different radius.\n",
    "# Fix num_clusters=25, num_poses=1000, num_sols=1000.\n",
    "df_cp = df_nsf.copy()\n",
    "# select the rows where nnum_poses=1000, num_sols=1000, num_clusters=25\n",
    "df_cp = df_cp[(df_cp.num_poses == 1000) & (df_cp.num_sols == 1000) & (df_cp.num_clusters == 25)]\n",
    "plot_nsf_linechart(df_cp, hue='radius', x_label='max_samples')\n",
    "\n",
    "# plot the linechart where x-axis is num_poses, y-axis is mmd_imq\n",
    "# and each line is a different num_sols.\n",
    "# Fix max_samples=5000000, radius=0.5, num_clusters=25.\n",
    "df_cp = df_nsf.copy()\n",
    "# select the rows where max_samples=5000000, radius=0.5, num_clusters=25\n",
    "df_cp = df_cp[(df_cp.max_samples == 5000000) & (df_cp.radius == 0.5) & (df_cp.num_clusters == 25)]\n",
    "plot_nsf_linechart(df_cp, hue='num_sols', x_label='num_poses')\n",
    "\n",
    "# plot two sub-plot linechart where x-axis are max_samples, one y-axis is l2_mm and one is mmd_imq\n",
    "# and each line is a different num_clusters. \n",
    "# Fix radius=0, num_poses=1000, num_sols=1000.\n",
    "df_cp = df_nsf.copy()\n",
    "# select the rows where nnum_poses=1000, num_sols=1000, radius=0\n",
    "df_cp = df_cp[(df_cp.num_poses == 1000) & (df_cp.num_sols == 1000) & (df_cp.radius == 0)]\n",
    "plot_nsf_linechart(df_cp, hue='num_clusters', x_label='max_samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi.loc['paik']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flatdict import FlatterDict\n",
    "\n",
    "nested_dict = {'a': 1, 'c': {'a': 2, 'b': {'x': 3, 'y': 4, 'z': 5}}, 'd': [6, 7, 8]}\n",
    "flat_dict = FlatterDict(nested_dict, delimiter='_')\n",
    "print(dict(flat_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show method == random\n",
    "df[df[\"method\"] == \"random\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "\n",
    "robot_name = 'panda'\n",
    "\n",
    "max_samples_list = [10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "radius_list = [0.0, 0.01, 0.1, 0.5, 1.0, 2]\n",
    "j_ref_list = [None]\n",
    "use_cluster_list = [False, True]\n",
    "n_clusters_list = [5, 10, 20, 30, 50, 100, 200]\n",
    "\n",
    "# Combine as an iterator\n",
    "combinations = itertools.product(max_samples_list, radius_list, j_ref_list, use_cluster_list, n_clusters_list)\n",
    "\n",
    "for com in combinations:\n",
    "    \n",
    "    MAX_SAMPLES, RADIUS, J_REF, USE_CLUSTER, N_CLUSTERS = com\n",
    "    print_retriever()\n",
    "    \n",
    "    if not USE_CLUSTER and N_CLUSTERS > n_clusters_list[0]:\n",
    "        continue\n",
    "    \n",
    "    if USE_CLUSTER and MAX_SAMPLES < N_CLUSTERS * 1000:\n",
    "        continue\n",
    "    \n",
    "    record_dir = f'/home/luca/paik/record/retriever/'\n",
    "    \n",
    "    if USE_CLUSTER:\n",
    "        record_dir += 'cluster'\n",
    "    else:\n",
    "        record_dir += 'random'\n",
    "    \n",
    "    record_dir += f'_sam{MAX_SAMPLES}_r{RADIUS}_clstr{N_CLUSTERS}'\n",
    "    \n",
    "    os.makedirs(record_dir, exist_ok=True)\n",
    "    test_random_ikp_with_mmd(robot_name, \"diag_normal\", 150, 150, [0.01], record_dir, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results from the record directory\n",
    "combinations = itertools.product(max_samples_list, radius_list, j_ref_list, use_cluster_list, n_clusters_list)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for com in combinations:\n",
    "    \n",
    "    MAX_SAMPLES, RADIUS, J_REF, USE_CLUSTER, N_CLUSTERS = com\n",
    "    \n",
    "    record_dir = f'/home/luca/paik/record/retriever/'\n",
    "    \n",
    "    if USE_CLUSTER:\n",
    "        record_dir += 'cluster'\n",
    "    else:\n",
    "        record_dir += 'random'\n",
    "    \n",
    "    record_dir += f'_sam{MAX_SAMPLES}_r{RADIUS}_clstr{N_CLUSTERS}'\n",
    "\n",
    "    if not os.path.exists(record_dir):\n",
    "        continue\n",
    "    \n",
    "    df_file = pd.read_csv(f\"{record_dir}/ikp_{robot_name}_150_150_0.01_nsf_diag_normal.csv\")\n",
    "    # convert to pd series with mean of df columns as keys\n",
    "    # add max_samples, radius, j_ref, use_cluster, n_clusters as keys\n",
    "    series = df_file.mean(numeric_only=True)\n",
    "    series[\"max_samples\"] = MAX_SAMPLES\n",
    "    series[\"radius\"] = RADIUS\n",
    "    series[\"j_ref\"] = False if J_REF is None else True\n",
    "    series[\"method\"] = \"cluster\" if USE_CLUSTER else \"random\"\n",
    "    series[\"n_clusters\"] = N_CLUSTERS\n",
    "\n",
    "    df_list.append(series)\n",
    "\n",
    "df = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show method == random\n",
    "df[df[\"method\"] == \"random\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster's variables: max_samples, radius, n_clusters\n",
    "\n",
    "# lineplots for cluster method with radius = 0.0.\n",
    "# x_axis is different max_samples \n",
    "# y_axis is mmd_imq\n",
    "# lines are different number of clusters\n",
    "df_cluster = df[(df[\"method\"] == \"cluster\") & (df[\"radius\"] == 0.0)]\n",
    "df_cluster = df_cluster.sort_values(by=\"n_clusters\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_cluster, x=\"max_samples\", y=\"mmd_imq\", hue=\"n_clusters\", marker=\"o\")\n",
    "# set x_ticks as max_samples_list\n",
    "plt.xticks(max_samples_list)\n",
    "plt.title(\"MMD_IMQ with different number of clusters\")\n",
    "plt.show()\n",
    "\n",
    "# n_clsuter domainates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster's variables: max_samples, radius, n_clusters\n",
    "\n",
    "# lineplots for cluster method with max_samples = 50000.\n",
    "# x_axis is different raius \n",
    "# y_axis is mmd_imq\n",
    "# lines are different number of clusters\n",
    "df_cluster = df[(df[\"method\"] == \"cluster\") & (df[\"max_samples\"] == 100000)]\n",
    "df_cluster = df_cluster.sort_values(by=\"radius\")\n",
    "\n",
    "# print out the row of the min mmd_imq\n",
    "print(df_cluster[df_cluster[\"mmd_imq\"] == df_cluster[\"mmd_imq\"].min()].T)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_cluster, x=\"radius\", y=\"mmd_imq\", hue=\"n_clusters\", marker=\"o\")\n",
    "# set x_ticks as radius_list\n",
    "plt.xticks(radius_list)\n",
    "plt.title(\"Cluster's MMD_IMQ with different radius\")\n",
    "plt.show()\n",
    "\n",
    "# radius has a balance near 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random's variables: max_samples, radius \n",
    "\n",
    "# lineplots for random method. \n",
    "# x_axis is different radius\n",
    "# y_axis is mmd_imq\n",
    "# lines are different max_samples\n",
    "\n",
    "df_random = df[df[\"method\"] == \"random\"]\n",
    "df_random = df_random.sort_values(by=\"max_samples\")\n",
    "\n",
    "print(df_random[df_random[\"mmd_imq\"] == df_random[\"mmd_imq\"].min()].T)\n",
    "\n",
    "df_random_first_5 = df_random[df_random[\"max_samples\"] <= 1000]\n",
    "df_random_rest = df_random[df_random[\"max_samples\"] > 1000]\n",
    "\n",
    "# plot the first 5 max_samples as a sub-plot and the rest as a sub-plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 12))\n",
    "sns.lineplot(data=df_random_first_5, x=\"radius\", y=\"mmd_imq\", hue=\"max_samples\", marker=\"o\", ax=axes[0])\n",
    "sns.lineplot(data=df_random_rest, x=\"radius\", y=\"mmd_imq\", hue=\"max_samples\", marker=\"o\", ax=axes[1])\n",
    "plt.xticks(radius_list)\n",
    "plt.title(\"MMD_IMQ with different radius\")\n",
    "plt.show()\n",
    "\n",
    "# radius has a balance near 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
