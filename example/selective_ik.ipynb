{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7effad6d6870>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Optional\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common.evaluate import evaluate_pose_error_J3d_P2d\n",
    "from paik.solver import NSF, PAIK, Solver, get_solver\n",
    "from ikp import get_robot, numerical_inverse_kinematics_batch, compute_mmd, gaussian_kernel, inverse_multiquadric_kernel\n",
    "\n",
    "import torch\n",
    "from functools import partial\n",
    "import os\n",
    "import itertools\n",
    "from tqdm.contrib import itertools as tqdm_itertools\n",
    "\n",
    "from paik.file import load_pickle, save_pickle\n",
    "from latent_space_sampler import Retriever\n",
    "\n",
    "\n",
    "# set the same random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_batch(solver, P, num_sols, std=0.001, retriever: Optional[Retriever] = None, J_ref=None, radius=0.0, num_clusters=30, num_seeds_per_pose=10, use_samples=int(5e6), verbose=False, retr_type='cluster'):\n",
    "    # shape: (num_sols, num_poses, m)\n",
    "    P_num_sols = np.expand_dims(P, axis=0).repeat(num_sols, axis=0)\n",
    "    # shape: (num_sols*num_poses, n)\n",
    "    P_num_sols = P_num_sols.reshape(-1, P.shape[-1])\n",
    "    \n",
    "    J_ref_num_sols = None\n",
    "    if J_ref is not None:\n",
    "        J_ref_num_sols = np.expand_dims(J_ref, axis=0).repeat(num_sols, axis=0)\n",
    "        J_ref_num_sols = J_ref_num_sols.reshape(-1, J_ref.shape[-1])\n",
    "\n",
    "    if isinstance(solver, PAIK):\n",
    "        solver.base_std = std\n",
    "        F = solver.get_reference_partition_label(P=P, J=J_ref, num_sols=num_sols)\n",
    "        # shape: (1, num_sols*num_poses, n)\n",
    "        J_hat = solver.generate_ik_solutions(P=P_num_sols, F=F, verbose=verbose)\n",
    "    elif isinstance(solver, NSF):\n",
    "        if retriever is None:\n",
    "            solver.base_std = std\n",
    "            J_hat = solver.generate_ik_solutions(P=P, num_sols=num_sols)\n",
    "        else:\n",
    "            if retr_type == 'cluster':\n",
    "                latents = retriever.cluster_retriever(seeds=J_ref, num_poses=P.shape[0], num_sols=num_sols, max_samples=use_samples, radius=radius, n_clusters=num_clusters)\n",
    "            elif retr_type == 'random':\n",
    "                latents = retriever.random_retriever(seeds=J_ref, num_poses=P.shape[0], max_samples=use_samples, num_sols=num_sols, radius=radius)\n",
    "            elif retr_type == 'numerical':\n",
    "                latents = retriever.numerical_retriever(poses=P, seeds=J_ref, num_sols=num_sols, num_seeds_per_pose=num_seeds_per_pose, radius=radius)\n",
    "            J_hat = solver.generate_ik_solutions(P=P_num_sols, latents=latents, verbose=verbose)\n",
    "    else:\n",
    "        J_hat = np.empty((num_sols, P.shape[0], solver.robot.n_dofs))\n",
    "        P_torch = torch.tensor(P, dtype=torch.float32).to('cuda')\n",
    "        for i, p in enumerate(P_torch):\n",
    "            solutions = solver.generate_ik_solutions(\n",
    "                p,\n",
    "                num_sols,\n",
    "                latent_distribution='gaussian',\n",
    "                latent_scale=std,\n",
    "                clamp_to_joint_limits=False,\n",
    "            )\n",
    "            J_hat[:, i] = solutions.detach().cpu().numpy()\n",
    "    # return shape: (num_sols, num_poses, n)\n",
    "    return J_hat.reshape(num_sols, P.shape[0], -1)\n",
    "\n",
    "\n",
    "def random_ikp(robot, poses: np.ndarray, solve_fn_batch: Any, num_poses: int, num_sols: int, J_hat_num: Optional[np.ndarray] = None):\n",
    "    begin = time()\n",
    "    # shape: (num_poses, num_sols, num_dofs or n)\n",
    "    J_hat = solve_fn_batch(P=poses, num_sols=num_sols)\n",
    "    assert J_hat.shape == (\n",
    "        num_sols, num_poses, robot.n_dofs), f\"J_hat shape {J_hat.shape} is not correct\"\n",
    "\n",
    "    l2, ang = evaluate_pose_error_J3d_P2d(\n",
    "        #init(num_sols, num_poses, num_dofs or n)\n",
    "        robot, J_hat, poses, return_all=True\n",
    "    )\n",
    "    \n",
    "    num_sols_time_ms = round((time() - begin) / len(poses), 3) * 1000\n",
    "    \n",
    "    ret_results = {}\n",
    "    l2_mean = np.nanmean(l2)\n",
    "    ang_mean = np.nanmean(ang)\n",
    "    \n",
    "    ret_results[f'{num_poses}_{num_sols}'] = {\n",
    "        \"l2_mm\": l2_mean * 1000,\n",
    "        \"ang_deg\": np.rad2deg(ang_mean),\n",
    "        \"num_sols_time_ms\": num_sols_time_ms\n",
    "    }\n",
    "    \n",
    "    if J_hat_num is None:\n",
    "        mmd_guassian = np.nan\n",
    "        mmd_imq = np.nan\n",
    "    else:\n",
    "        mmd_guassian_list = np.empty((num_poses))\n",
    "        mmd_imq_list = np.empty((num_poses))\n",
    "        for i in range(num_poses):\n",
    "            mmd_guassian_list[i] = compute_mmd(J_hat[:, i], J_hat_num[:, i], kernel=gaussian_kernel)\n",
    "            mmd_imq_list[i] = compute_mmd(J_hat[:, i], J_hat_num[:, i], kernel=inverse_multiquadric_kernel)\n",
    "        mmd_guassian = mmd_guassian_list.mean()\n",
    "        mmd_imq = mmd_imq_list.mean()\n",
    "        \n",
    "    ret_results[f'{num_poses}_{num_sols}']['mmd_guassian'] = mmd_guassian\n",
    "    ret_results[f'{num_poses}_{num_sols}']['mmd_imq'] = mmd_imq\n",
    "    \n",
    "    ret_results['ik_sols'] = J_hat\n",
    "\n",
    "    return ret_results\n",
    "\n",
    "def plot_3d_scatter(array, file_path):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(array[:, -1], array[:, -2], array[:, -3])\n",
    "    ax.set_xlabel('Last 1 Dimension')\n",
    "    ax.set_ylabel('Last 2 Dimension')\n",
    "    ax.set_zlabel('Last 3 Dimension')\n",
    "    plt.savefig(file_path)\n",
    "    plt.show()\n",
    "    \n",
    "def parse_ik_sols(results: dict):\n",
    "    cp = results.copy()\n",
    "    ik_sols = {}\n",
    "    for k, v in cp.items():\n",
    "        if 'ik_sols' in v:\n",
    "            ik_sols[k] = v['ik_sols']\n",
    "    return ik_sols\n",
    "    \n",
    "    \n",
    "def plot_random_3d_joints_scatter(keys, ik_sols_dict: dict, c: dict, marker: dict, label: dict, seeds: np.ndarray, file_path: str, joint_nums=[-1, -2, -3]):\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': '3d'})\n",
    "    \n",
    "    x, y, z = joint_nums\n",
    "    \n",
    "    j = 0\n",
    "    colors = plt.cm.tab20.colors\n",
    "    markers = ['o', 's', 'd', '^', 'v', '<', '>', 'p', 'P', '*', 'h', 'H', '+', 'x', 'X', '|', '_', '1', '2', '3', '4']\n",
    "    \n",
    "    ax.scatter(seeds[:, x], seeds[:, y], seeds[:, z], c='brown', marker='p', label='Seeds', s=100)\n",
    "    for i in keys:\n",
    "        Ji = ik_sols_dict[i].reshape(-1, ik_sols_dict[i].shape[-1])\n",
    "        \n",
    "        # if c[i], marker[i], label[i] (dict) is not exist, use a default color, marker, label\n",
    "        if i not in c:\n",
    "            # color is a tuple of RGB (0-1)\n",
    "            c[i] = np.atleast_2d(colors[j])\n",
    "            j += 1\n",
    "\n",
    "        if i not in marker:\n",
    "            marker[i] = markers[j]\n",
    "            j += 1\n",
    "\n",
    "        if i not in label:\n",
    "            label[i] = i.upper()\n",
    "                        \n",
    "        if i == 'numerical':\n",
    "            # alpha is used to make the NUM solution more transparent\n",
    "            ax.scatter(Ji[:, x], Ji[:, y], Ji[:, z], c='gray', marker='x', label=label[i], alpha=0.6, s=50)\n",
    "        else:\n",
    "            ax.scatter(Ji[:, x], Ji[:, y], Ji[:, z], c=c[i], marker=marker[i], label=label[i], s=70)\n",
    "    \n",
    "    ax.set_xlabel(f'Joint {x}')\n",
    "    ax.set_ylabel(f'Joint {y}')\n",
    "    ax.set_zlabel(f'Joint {z}')\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.show()    \n",
    "    fig.savefig(file_path)\n",
    "\n",
    "\n",
    "def selective_ik(record_dir, robot_name, num_poses, num_sols, paik_std_list, radius_list, num_clusters_list, num_seeds_per_pose_list):\n",
    "    \n",
    "    robot = get_robot(robot_name)\n",
    "    nsf = get_solver(arch_name=\"nsf\", robot=robot, load=True, work_dir='/home/luca/paik')\n",
    "    retriever = Retriever(nsf)\n",
    "    max_samples = int(5e6)\n",
    "    retriever.init([max_samples], num_clusters_list)\n",
    "    paik = get_solver(arch_name=\"paik\", robot=robot, load=True, work_dir='/home/luca/paik')\n",
    "    \n",
    "    func_name = f\"selective_ik_{robot_name}_{num_sols}\"\n",
    "    file_path = f\"{record_dir}/{func_name}.pkl\"\n",
    "\n",
    "    results = {}\n",
    "    # if os.path.exists(file_path):\n",
    "    #     results = load_pickle(file_path)\n",
    "        \n",
    "    # Generate one random pose\n",
    "    if 'pose' in results:\n",
    "        J_ref = results['J_ref']\n",
    "        poses = results['poses']\n",
    "    else:\n",
    "        _, poses = nsf.robot.sample_joint_angles_and_poses(n=num_poses)\n",
    "        results['poses'] = poses\n",
    "        save_pickle(file_path, results)\n",
    "\n",
    "    print(f\"Start numerical IK...\")\n",
    "    num_solver_batch = partial(numerical_inverse_kinematics_batch, solver=nsf)    \n",
    "    results['num'] = random_ikp(robot, poses, num_solver_batch, num_poses=num_poses, num_sols=num_sols)\n",
    "    save_pickle(file_path, results)    \n",
    "    print(f\"Results numerical IK are saved in {file_path}\")\n",
    "    \n",
    "    J_hat_num = results['num']['ik_sols']\n",
    "    J_ref = J_hat_num[0]\n",
    "    \n",
    "    \n",
    "    print(f\"Start paik...\")\n",
    "    # paik's variable: num_poses, num_sols, std, \n",
    "    for std in tqdm(paik_std_list):\n",
    "        paik_solver_batch = partial(solver_batch, solver=paik, std=std, J_ref=J_ref)\n",
    "        name = f'paik_gaussian_{std}'\n",
    "        if name not in results:\n",
    "            results[name] = random_ikp(robot, poses, paik_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results) \n",
    "    print(f\"Results paik are saved in {file_path}\")\n",
    "    \n",
    "    \n",
    "    print(f\"Start paik...\")\n",
    "    # paik's variable: num_poses, num_sols, std, \n",
    "    for std in tqdm(paik_std_list):\n",
    "        paik_solver_batch = partial(solver_batch, solver=paik, std=std, J_ref=J_ref)\n",
    "        name = f'paik_gaussian_{std}'\n",
    "        if name not in results:\n",
    "            results[name] = random_ikp(robot, poses, paik_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results) \n",
    "    print(f\"Results paik are saved in {file_path}\")\n",
    "\n",
    "    # print(f\"Start nsf w/o retreiver...\")\n",
    "    # # nsf's variable: std\n",
    "    # for std in tqdm(paik_std_list):\n",
    "    #     nsf_solver_batch = partial(solver_batch, solver=nsf, std=std, retriever=None, J_ref=J_ref)\n",
    "    #     name = f'nsf_gaussian_{std}'\n",
    "    #     if name not in results:\n",
    "    #         results[name] = random_ikp(robot, poses, nsf_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "    #         save_pickle(file_path, results)\n",
    "\n",
    "    print(f\"Start nsf with cluster retriever...\")    \n",
    "    # nsf's variable: num_poses, num_sols, max_samples, radius, num_clusters\n",
    "    use_samples = max_samples\n",
    "    for radius, num_clusters in tqdm_itertools.product(radius_list, num_clusters_list):\n",
    "        nsf_solver_batch = partial(solver_batch, solver=nsf, radius=radius, num_clusters=num_clusters, retriever=retriever, use_samples=use_samples, retr_type='cluster', J_ref=J_ref)\n",
    "        name = f'nsf_cluster_{radius}_{num_clusters}'\n",
    "        if name not in results:\n",
    "            results[name] = random_ikp(robot, poses, nsf_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results)\n",
    "    print(f\"Results nsf with cluster retriever are saved in {file_path}\")\n",
    "    \n",
    "    print(f\"Start nsf with random retriever...\")\n",
    "    # nsf's variable: num_poses, num_sols, max_samples, radius\n",
    "    for radius, num_clusters in tqdm_itertools.product(radius_list, num_clusters_list):\n",
    "        use_samples = min(max_samples, num_clusters)\n",
    "        nsf_solver_batch = partial(solver_batch, solver=nsf, radius=radius, retriever=retriever, use_samples=use_samples, retr_type='random', J_ref=J_ref)\n",
    "        name = f'nsf_random_{radius}_{use_samples}'\n",
    "        if name not in results:\n",
    "            results[name] = random_ikp(robot, poses, nsf_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results)\n",
    "            \n",
    "    print(f\"Start nsf with numerical retriever...\")\n",
    "    # nsf's variable: num_poses, num_sols, max_samples, radius, num_seeds_per_pose\n",
    "    for radius, num_seeds_per_pose in tqdm_itertools.product(radius_list, num_seeds_per_pose_list):\n",
    "        nsf_solver_batch = partial(solver_batch, solver=nsf, radius=radius, retriever=retriever, num_seeds_per_pose=num_seeds_per_pose, retr_type='numerical', J_ref=J_ref)\n",
    "        name = f'nsf_numerical_{radius}_{num_seeds_per_pose}'\n",
    "        if name not in results:\n",
    "            results[name] = random_ikp(robot, poses, nsf_solver_batch, num_poses=num_poses, num_sols=num_sols, J_hat_num=J_hat_num)\n",
    "            save_pickle(file_path, results)\n",
    "            \n",
    "    # for k, v in results.items():\n",
    "    #     if 'ik_sols' in v:\n",
    "    #         ik_sols = v['ik_sols']\n",
    "    #         file_path = f\"{record_dir}/{func_name}_{k}.png\"\n",
    "    #         plot_3d_scatter(ik_sols.reshape(-1, ik_sols.shape[-1]), file_path)\n",
    "    \n",
    "    # drop pose in results\n",
    "    results.pop('poses')\n",
    "    # drop joint_config_ref in results\n",
    "    results.pop('joint_config_ref')\n",
    "\n",
    "    ik_sols = parse_ik_sols(results)\n",
    "    keys_list = [(key, 'numerical') for key in ik_sols.keys() if key != 'num']\n",
    "    file_path_list = [f\"{record_dir}/{func_name}_{key}.png\" for key in ik_sols.keys() if key != 'num']\n",
    "    for keys, file_path in zip(keys_list, file_path_list):\n",
    "        plot_random_3d_joints_scatter(keys, ik_sols, {}, {}, {}, joint_config_ref, file_path)\n",
    "    \n",
    "\n",
    "    # stat_results w/o pose, ik_sols \n",
    "    stat_results = {}\n",
    "    for k, v in results.items():\n",
    "        v.pop('ik_sols')\n",
    "        stat_results[k] = v        \n",
    "    \n",
    "    df = pd.DataFrame(stat_results).T\n",
    "    # round to 4 decimal places\n",
    "    df = df.round(4)\n",
    "    print(df)\n",
    "    file_path = f\"{record_dir}/selective_ik_evaluation_results_{robot_name}_{num_sols}.csv\"\n",
    "    df.to_csv(file_path)\n",
    "    print(f\"Results are saved in {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to evaluate panda...\n",
      "WorldModel::LoadRobot: /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "joint mimic: no multiplier, using default value of 1 \n",
      "joint mimic: no offset, using default value of 0 \n",
      "URDFParser: Link size: 17\n",
      "URDFParser: Joint size: 12\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link0.dae (59388 verts, 20478 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link1.dae (37309 verts, 12516 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link2.dae (37892 verts, 12716 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link3.dae (42512 verts, 14233 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link4.dae (43520 verts, 14620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link5.dae (54770 verts, 18327 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link6.dae (64086 verts, 21620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link7.dae (35829 verts, 12077 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/hand.dae (20896 verts, 7078 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "URDFParser: Done loading robot file /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "[Warning] Error(s) in loading state_dict for Flow:\n",
      "\tsize mismatch for base._0: copying a param with shape torch.Size([1, 7]) from checkpoint, the shape in current model is torch.Size([7]).. Please check the model path /home/luca/paik/weights/panda/0115-0234/model.pth.\n",
      "[WARNING] /home/luca/paik/weights/panda/0115-0234/J_knn.pth: file not exist and return None.. Load training data instead.\n",
      "[SUCCESS] P_knn load from /home/luca/paik/weights/panda/P_knn-5000000-7-7-1.pth.\n",
      "[SUCCESS] J_knn load from /home/luca/paik/weights/panda/J_knn-5000000-7-7-1.pth.\n",
      "[INFO] Load latent variable from /home/luca/paik/weights/panda/Z.npy.\n",
      "Start to initialize cluster info...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006299257278442383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a15d2ac1df7460893917a60a2e62281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to initialize numerical retriever...\n",
      "[SUCCESS] load from /home/luca/paik/weights/panda/0904-1939\n",
      "[SUCCESS] load best date 0904-1939 with l2 0.00297 from /home/luca/paik/weights/panda/best_date_paik.csv.\n",
      "Start numerical IK...\n",
      "Results numerical IK are saved in /mnt/d/pads/Documents/paik_store/record/2024_11_13/selective_ik_panda_100.pkl\n",
      "Start paik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results paik are saved in /mnt/d/pads/Documents/paik_store/record/2024_11_13/selective_ik_panda_100.pkl\n",
      "Start paik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 19737.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results paik are saved in /mnt/d/pads/Documents/paik_store/record/2024_11_13/selective_ik_panda_100.pkl\n",
      "Start nsf with cluster retriever...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007135868072509766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfecef520da54d0bbc3bf40594e7c0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results nsf with cluster retriever are saved in /mnt/d/pads/Documents/paik_store/record/2024_11_13/selective_ik_panda_100.pkl\n",
      "Start nsf with random retriever...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006497621536254883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e42402f2ff64467959b7aa1f915863f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to random retriever...\n",
      "Start to random retriever...\n",
      "Start nsf with numerical retriever...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0063474178314208984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74059906f954c9c93b25143e5205015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "numerical_retriever() got an unexpected keyword argument 'num_seeds_per_pose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart to evaluate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrobot_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m kwarg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobot_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m robot_name\n\u001b[0;32m---> 22\u001b[0m \u001b[43mselective_ik\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwarg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 240\u001b[0m, in \u001b[0;36mselective_ik\u001b[0;34m(record_dir, robot_name, num_poses, num_sols, paik_std_list, radius_list, num_clusters_list, num_seeds_per_pose_list)\u001b[0m\n\u001b[1;32m    238\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsf_numerical_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mradius\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_seeds_per_pose\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m--> 240\u001b[0m         results[name] \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_ikp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrobot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsf_solver_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_poses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_poses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_sols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_sols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ_hat_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mJ_hat_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m         save_pickle(file_path, results)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# for k, v in results.items():\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m#     if 'ik_sols' in v:\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m#         ik_sols = v['ik_sols']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# drop pose in results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 48\u001b[0m, in \u001b[0;36mrandom_ikp\u001b[0;34m(robot, poses, solve_fn_batch, num_poses, num_sols, J_hat_num)\u001b[0m\n\u001b[1;32m     46\u001b[0m begin \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# shape: (num_poses, num_sols, num_dofs or n)\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m J_hat \u001b[38;5;241m=\u001b[39m \u001b[43msolve_fn_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_sols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_sols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m J_hat\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m     50\u001b[0m     num_sols, num_poses, robot\u001b[38;5;241m.\u001b[39mn_dofs), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJ_hat shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mJ_hat\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not correct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m l2, ang \u001b[38;5;241m=\u001b[39m evaluate_pose_error_J3d_P2d(\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m#init(num_sols, num_poses, num_dofs or n)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     robot, J_hat, poses, return_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     55\u001b[0m )\n",
      "Cell \u001b[0;32mIn[19], line 27\u001b[0m, in \u001b[0;36msolver_batch\u001b[0;34m(solver, P, num_sols, std, retriever, J_ref, radius, num_clusters, num_seeds_per_pose, use_samples, verbose, retr_type)\u001b[0m\n\u001b[1;32m     25\u001b[0m             latents \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39mrandom_retriever(seeds\u001b[38;5;241m=\u001b[39mJ_ref, num_poses\u001b[38;5;241m=\u001b[39mP\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], max_samples\u001b[38;5;241m=\u001b[39muse_samples, num_sols\u001b[38;5;241m=\u001b[39mnum_sols, radius\u001b[38;5;241m=\u001b[39mradius)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m retr_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m             latents \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumerical_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mJ_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_sols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_sols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_seeds_per_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_seeds_per_pose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m         J_hat \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mgenerate_ik_solutions(P\u001b[38;5;241m=\u001b[39mP_num_sols, latents\u001b[38;5;241m=\u001b[39mlatents, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: numerical_retriever() got an unexpected keyword argument 'num_seeds_per_pose'"
     ]
    }
   ],
   "source": [
    "from common.config import Config_IKP\n",
    "config = Config_IKP()\n",
    "\n",
    "config.workdir = '/mnt/d/pads/Documents/paik_store'\n",
    "\n",
    "kwarg = {\n",
    "    'record_dir': config.record_dir,\n",
    "    'robot_name': 'panda',\n",
    "    'num_poses': 1,\n",
    "    'num_sols': 100,  # 300, 500, 1000\n",
    "    'paik_std_list': [0.001, 0.1], # 0.001, 0.1, 0.25, 0.5, 0.7\n",
    "    'radius_list': [0.001, 0.1], # 0, 0.1, 0.3, 0.5, 0.7, 0.9\n",
    "    'num_seeds_per_pose_list': [10], # 10, 20, 30, 40, 50\n",
    "    'num_clusters_list': [30] # 13, 16, 19, 25, 30, 40\n",
    "}\n",
    "\n",
    "robot_names = [\"panda\"] # \"panda\", \"fetch\", \"fetch_arm\", \"atlas_arm\", \"atlas_waist_arm\", \"baxter_arm\"\n",
    "\n",
    "for robot_name in robot_names:\n",
    "    print(f\"Start to evaluate {robot_name}...\")\n",
    "    kwarg['robot_name'] = robot_name\n",
    "    selective_ik(**kwarg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorldModel::LoadRobot: /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "joint mimic: no multiplier, using default value of 1 \n",
      "joint mimic: no offset, using default value of 0 \n",
      "URDFParser: Link size: 17\n",
      "URDFParser: Joint size: 12\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link0.dae (59388 verts, 20478 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link1.dae (37309 verts, 12516 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link2.dae (37892 verts, 12716 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link3.dae (42512 verts, 14233 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link4.dae (43520 verts, 14620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link5.dae (54770 verts, 18327 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link6.dae (64086 verts, 21620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link7.dae (35829 verts, 12077 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/hand.dae (20896 verts, 7078 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "URDFParser: Done loading robot file /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "Initialized robot collision data structures in time 0.408395\n",
      "[Warning] Error(s) in loading state_dict for Flow:\n",
      "\tsize mismatch for base._0: copying a param with shape torch.Size([1, 7]) from checkpoint, the shape in current model is torch.Size([7]).. Please check the model path /home/luca/paik/weights/panda/0115-0234/model.pth.\n",
      "[WARNING] /home/luca/paik/weights/panda/0115-0234/J_knn.pth: file not exist and return None.. Load training data instead.\n",
      "[SUCCESS] P_knn load from /home/luca/paik/weights/panda/P_knn-5000000-7-7-1.pth.\n",
      "[SUCCESS] J_knn load from /home/luca/paik/weights/panda/J_knn-5000000-7-7-1.pth.\n",
      "[INFO] Load latent variable from /home/luca/paik/weights/panda/Z.npy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.08it/s]\n"
     ]
    }
   ],
   "source": [
    "nsf = get_solver(arch_name=\"nsf\", robot=get_robot('panda'), load=True, work_dir='/home/luca/paik')\n",
    "_, pose = nsf.robot.sample_joint_angles_and_poses(n=1)\n",
    "num_sols = 100\n",
    "ik_sols_num = numerical_inverse_kinematics_batch(solver=nsf, P=pose, num_sols=num_sols)\n",
    "Z = nsf.generate_z_from_ik_solutions(pose, ik_sols_num.reshape(num_sols, nsf.robot.n_dofs))\n",
    "ik_sols_nsf = nsf.generate_ik_solutions(P=pose, num_sols=num_sols, latents=Z, verbose=True)\n",
    "l2, ang = evaluate_pose_error_J3d_P2d(robot=nsf.robot, J=ik_sols_nsf.reshape(num_sols, 1, nsf.robot.n_dofs), P=pose, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.006941903072011681, 1.0502243409556615)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.mean(), np.rad2deg(ang.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
