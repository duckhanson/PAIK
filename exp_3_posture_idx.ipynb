{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from jrl.robots import Panda\n",
                "from jrl.evaluation import pose_errors_cm_deg\n",
                "import torch\n",
                "\n",
                "def assert_poses_almost_equal(poses_1, poses_2):\n",
                "    pos_errors_cm, rot_errors_deg = pose_errors_cm_deg(poses_1, poses_2)\n",
                "    assert (pos_errors_cm.max().item() < 0.01) and (rot_errors_deg.max().item() < 0.1)\n",
                "\n",
                "robot = Panda()\n",
                "joint_angles, poses = robot.sample_joint_angles_and_poses(n=5, return_torch=True) # sample 5 random joint angles and matching poses\n",
                "\n",
                "# Run forward-kinematics\n",
                "poses_fk = robot.forward_kinematics_batch(joint_angles) \n",
                "assert_poses_almost_equal(poses, poses_fk)\n",
                "\n",
                "# Run inverse-kinematics\n",
                "ik_sols = joint_angles + 0.1 * torch.randn_like(joint_angles) \n",
                "for i in range(5):\n",
                "    ik_sols = robot.inverse_kinematics_single_step_levenburg_marquardt(poses, ik_sols)\n",
                "assert_poses_almost_equal(poses, robot.forward_kinematics_batch(ik_sols))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.robot import get_robot\n",
                "robot = get_robot()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from klampt.model import trajectory\n",
                "milestones = [[0,0,0],[0.02,0,0],[1,0,0],[2,0,1],[2.2,0,1.5],[3,0,1],[4,0,-0.3]]\n",
                "traj = trajectory.Trajectory(milestones=milestones)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "endPoints = np.random.rand(2, 3)\n",
                "traj = trajectory.Trajectory(milestones=endPoints)\n",
                "endPoints"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.settings import config as cfg\n",
                "\n",
                "numSteps = 20\n",
                "P_path = np.empty((numSteps, cfg.m))\n",
                "\n",
                "for i in range(numSteps):\n",
                "    iStep = i/numSteps\n",
                "    point = traj.eval(iStep)\n",
                "    print(f\"{iStep}: {point}\")\n",
                "    P_path[i] = point\n",
                "\n",
                "P_path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.robot import sample_P_path\n",
                "from utils.utils import load_numpy\n",
                "\n",
                "traj_dir = sample_P_path(num_steps=20)\n",
                "load_numpy(traj_dir + 'ee_traj.npy')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mu = torch.zeros(size=(cfg.n,))\n",
                "NUM_DATA = 100\n",
                "NUM_SAMPLES = 1000"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test(robot=panda, P_ts=P_ts[:NUM_DATA], F=F, solver=flow, knn=knn, K=NUM_SAMPLES, print_report=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WorldModel::LoadRobot: /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
                        "joint mimic: no multiplier, using default value of 1 \n",
                        "joint mimic: no offset, using default value of 0 \n",
                        "URDFParser: Link size: 17\n",
                        "URDFParser: Joint size: 12\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link0.dae (59388 verts, 20478 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link1.dae (37309 verts, 12516 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link2.dae (37892 verts, 12716 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link3.dae (42512 verts, 14233 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link4.dae (43520 verts, 14620 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link5.dae (54770 verts, 18327 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link6.dae (64086 verts, 21620 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link7.dae (35829 verts, 12077 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/hand.dae (20896 verts, 7078 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
                        "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
                        "URDFParser: Done loading robot file /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
                        "Initialized robot collision data structures in time 0.406655\n",
                        "F load successfully from /home/luca/ikpflow/data/panda/train/F-2500000-7-3-4.npy\n",
                        "knn load successfully from /home/luca/ikpflow/data/panda/train/knn-2500000-7-3-4-normFalse.pickle\n",
                        "Load err from /home/luca/ikpflow/weights/panda/nsf.pth, assuming you use different architecture.\n"
                    ]
                }
            ],
            "source": [
                "from jrl.robots import Panda\n",
                "from utils.settings import config as cfg\n",
                "from utils.model import get_knn, get_flow_model\n",
                "from utils.utils import load_all_data\n",
                "robot = Panda()\n",
                "J_tr, P_tr, P_ts, F = load_all_data(robot)\n",
                "knn = get_knn(P_tr=P_tr)\n",
                "\n",
                "# Build Generative model, NSF\n",
                "config = {\n",
                "        'subnet_width': 1400,\n",
                "        'subnet_num_layers': 3,\n",
                "        'num_transforms': 9,\n",
                "        'lr': 2.1e-4,\n",
                "        'lr_weight_decay': 2.7e-2,\n",
                "        'decay_step_size': 4e4,\n",
                "        'gamma': 5e-2,\n",
                "        'batch_size': 128,\n",
                "        'num_epochs': 10,\n",
                "    }\n",
                "# Neural spline flow (NSF) with 3 sample features and 5 context features\n",
                "solver, _, _ = get_flow_model(\n",
                "        enable_load_model=cfg.use_pretrained,\n",
                "        num_transforms=config[\"num_transforms\"],\n",
                "        subnet_width=config[\"subnet_width\"],\n",
                "        subnet_num_layers=config[\"subnet_num_layers\"],\n",
                "        lr=config[\"lr\"],\n",
                "        lr_weight_decay=config[\"lr_weight_decay\"],\n",
                "        decay_step_size=config[\"decay_step_size\"],\n",
                "        gamma=config[\"gamma\"],\n",
                "        device='cuda')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Load err from /home/luca/ikpflow/weights/panda/nsf.pth, assuming you use different architecture.\n"
                    ]
                }
            ],
            "source": [
                "from utils.model import get_knn, get_flow_model\n",
                "flow = get_flow_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from zuko.nn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.utils import data_preprocess_for_inference\n",
                "solver = get_flow_model()\n",
                "K = 10\n",
                "position_errors = np.zeros(shape=(len(P_ts), K))\n",
                "orientation_errors = np.zeros(shape=(len(P_ts), K))\n",
                "\n",
                "\n",
                "# Data Preprocessing\n",
                "C = data_preprocess_for_inference(P=P_ts, F=F, knn=knn)\n",
                "\n",
                "\n",
                "time_begin = time.time()\n",
                "# Begin inference\n",
                "with torch.inference_mode():\n",
                "    J_hat = solver(C).sample((K,))\n",
                "    J_hat = J_hat.detach().cpu().numpy()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from jrl.robots import Panda\n",
                "from jrl.evaluation import pose_errors_cm_deg\n",
                "import torch\n",
                "\n",
                "def assert_poses_almost_equal(poses_1, poses_2):\n",
                "    pos_errors_cm, rot_errors_deg = pose_errors_cm_deg(poses_1, poses_2)\n",
                "    assert (pos_errors_cm.max().item() < 0.01) and (rot_errors_deg.max().item() < 0.1)\n",
                "\n",
                "robot = Panda()\n",
                "joint_angles, poses = robot.sample_joint_angles_and_poses(n=5, return_torch=True) # sample 5 random joint angles and matching poses\n",
                "\n",
                "# Run forward-kinematics\n",
                "poses_fk = robot.forward_kinematics_batch(joint_angles) \n",
                "assert_poses_almost_equal(poses, poses_fk)\n",
                "\n",
                "# Run inverse-kinematics\n",
                "ik_sols = joint_angles + 0.1 * torch.randn_like(joint_angles) \n",
                "for i in range(5):\n",
                "    ik_sols = robot.inverse_kinematics_single_step_levenburg_marquardt(poses, ik_sols)\n",
                "assert_poses_almost_equal(poses, robot.forward_kinematics_batch(ik_sols))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "joint_angles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.DataFrame(data=data, columns=[f'jt_{i}' for i in range(7)] + ['ml'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.boxplot(by='ml', figsize=(10, 10), layout=(5, 2), fontsize=10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_trans = load_numpy(file_path=config.x_trans_train_path)\n",
                "data = np.column_stack((x_trans, label))\n",
                "df_trans = pd.DataFrame(data=data, columns=[i for i in range(4)] + ['ml'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_trans.boxplot(by='ml', figsize=(10, 10), layout=(5, 2), fontsize=10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in range(4):\n",
                "    print(df_trans.groupby('ml')[i].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in range(7):\n",
                "    print(df.groupby('ml')[f'jt_{i}'].describe())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
