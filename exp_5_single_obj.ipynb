{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.py: Using device 'cuda:0'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import zuko\n",
    "from zuko.flows import GMM\n",
    "\n",
    "from pymoo.algorithms.soo.nonconvex.brkga import BRKGA\n",
    "from pymoo.core.callback import CallbackCollection, Callback\n",
    "from pymoo.core.problem import ElementwiseProblem, Problem\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.problems.functional import FunctionalProblem, func_return_none\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "from jkinpylib.evaluation import evaluate_solutions\n",
    "\n",
    "from ikflow.utils import set_seed\n",
    "from ikflow.model_loading import get_ik_solver\n",
    "\n",
    "from utils.settings import config\n",
    "from utils.utils import *\n",
    "from utils.model import *\n",
    "from utils.robot import Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemWrapper(ElementwiseProblem):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 iksols,\n",
    "                 target_poses,\n",
    "                 **kwargs):\n",
    "        self.target_poses = target_poses\n",
    "        self.all_sols = iksols\n",
    "        self.all_l2_errs = self.calc_all_l2_errs()\n",
    "        xl = np.zeros((iksols.shape[0]))\n",
    "        xu = np.full_like(xl, fill_value=len(iksols)-1)\n",
    "        super().__init__(n_var=len(xl),\n",
    "                         n_obj=1,\n",
    "                         n_ieq_constr=0,\n",
    "                         n_eq_constr=0,\n",
    "                         xl=xl,\n",
    "                         xu=xu,\n",
    "                         **kwargs)\n",
    "    \n",
    "    def calc_all_l2_errs(self):\n",
    "        all_l2_errs = np.ones((self.all_sols.shape[0], self.all_sols.shape[1]))\n",
    "        for i in range(self.all_sols.shape[1]):\n",
    "            qtraj = self.all_sols[:, i, :]\n",
    "            l2_errs, _, _, _ = evaluate_solutions(\n",
    "                ik_solver.robot, \n",
    "                torch.tensor(self.target_poses), \n",
    "                torch.tensor(qtraj))\n",
    "            all_l2_errs[:, i] = l2_errs\n",
    "        return all_l2_errs\n",
    "    \n",
    "    def ang_jump(self, qs):\n",
    "        errs = calc_ang_errs(qs)\n",
    "        return errs.mean()\n",
    "    \n",
    "    def pheno(self, design):\n",
    "        return np.floor(design).astype(int)\n",
    "        \n",
    "    def iksols(self, pheno):\n",
    "        qs = np.zeros((self.all_sols.shape[0], self.all_sols.shape[2]))\n",
    "        for ri, i in enumerate(pheno):\n",
    "            qs[ri] = self.all_sols[ri, i]\n",
    "        return qs\n",
    "\n",
    "    def l2_errs(self, pheno):\n",
    "        l2_errs = 0\n",
    "        for ri, i in enumerate(pheno):\n",
    "            l2_errs += self.all_l2_errs[ri, i]\n",
    "        return l2_errs / len(pheno)\n",
    "\n",
    "    def _evaluate(self, design, out, *args, **kwargs):\n",
    "        pheno = self.pheno(design)\n",
    "        iksols = self.iksols(pheno=pheno)\n",
    "        ang_errs = self.ang_jump(qs=iksols)\n",
    "        l2_errs = self.l2_errs(pheno=pheno)\n",
    "        out[\"F\"] = ang_errs\n",
    "        out[\"ang_errs\"] = ang_errs\n",
    "        out[\"l2_errs\"] = l2_errs\n",
    "        out[\"pheno\"] = pheno\n",
    "        out[\"hash\"] = hash(str(pheno))\n",
    "\n",
    "class MyElementwiseDuplicateElimination(ElementwiseDuplicateElimination):\n",
    "\n",
    "    def is_equal(self, a, b):\n",
    "        return a.get(\"hash\") == b.get(\"hash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_poses(robot): \n",
    "    traj_dir = sample_ee_traj(robot=robot, load_time='')\n",
    "    ee_traj = load_numpy(file_path=traj_dir + 'ee_traj.npy')\n",
    "    quaternions = np.zeros((len(ee_traj), 4))\n",
    "    quaternions[:, 0] = np.random.randn() * 2e-2 + 1\n",
    "    target_poses = np.column_stack((ee_traj, quaternions))\n",
    "    return traj_dir, target_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_seed() - random int:  44\n",
      "ndim_tot=7\n",
      "dim_cond=8\n",
      "WorldModel::LoadRobot: /tmp/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "joint mimic: no multiplier, using default value of 1 \n",
      "joint mimic: no offset, using default value of 0 \n",
      "URDFParser: Link size: 17\n",
      "URDFParser: Joint size: 12\n",
      "URDFParser: Done loading robot file /tmp/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n"
     ]
    }
   ],
   "source": [
    "file_names = ['ang_errs_avg', 'ang_errs_min', 'F_avg', 'F_min', 'ikflow_ang', 'ikflow_l2', 'l2_errs_avg', 'l2_errs_min', 'n_evals']\n",
    "exp_5_fig_dir = config.traj_dir + f'figs/exp_5_{datetime.now().strftime(\"%m%d%H%M\")}/'\n",
    "if not os.path.exists(path=exp_5_fig_dir):\n",
    "    os.makedirs(exp_5_fig_dir)\n",
    "set_seed()\n",
    "num_trails = 3\n",
    "num_generation = 100\n",
    "num_ikflow_trails = num_generation\n",
    "num_solutions = 500\n",
    "# Build IKFlowSolver and set weights\n",
    "ik_solver, hyper_parameters = get_ik_solver(\"panda__full__lp191_5.25m\")\n",
    "robot = ik_solver.robot\n",
    "panda = Robot(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir /home/luca/ikpflow/data/panda/trajectory/0710020345\n",
      "/home/luca/ikpflow/data/panda/trajectory/0710020345/ load successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:03,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011765626942888236\n",
      "542.6455801275969\n",
      "mkdir /home/luca/ikpflow/data/panda/trajectory/0710020347\n",
      "/home/luca/ikpflow/data/panda/trajectory/0710020347/ load successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17057971116658358\n",
      "517.6033977220058\n",
      "mkdir /home/luca/ikpflow/data/panda/trajectory/0710020349\n",
      "/home/luca/ikpflow/data/panda/trajectory/0710020349/ load successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023163149303705128\n",
      "538.8440417764186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for n_trail in trange(num_trails):\n",
    "    traj_dir, target_poses = get_target_poses(robot=panda)\n",
    "    exp_dir = traj_dir + f'exp_5_single_obj/'\n",
    "    data = {fn: [] for fn in file_names}\n",
    "    \n",
    "    # -> unrefined solutions\n",
    "    l2_errs = np.zeros((num_ikflow_trails,))\n",
    "    ang_errs = np.zeros((num_ikflow_trails,))\n",
    "    for ikflow_i in range(num_ikflow_trails):\n",
    "        solutions, l2_err, _, _, _, _ = ik_solver.solve_n_poses(\n",
    "            target_poses, \n",
    "            refine_solutions=False, \n",
    "            return_detailed=True)\n",
    "\n",
    "        iksols = solutions.detach().cpu().numpy()\n",
    "        df = qtraj_evaluation(robot=panda, qs=iksols, l2_errs=l2_err)\n",
    "        l2_errs[ikflow_i], ang_errs[ikflow_i] = df.mean().values\n",
    "    data['ikflow_l2'] = l2_errs\n",
    "    data['ikflow_ang'] = ang_errs    \n",
    "    print(np.mean(l2_errs))\n",
    "    print(np.mean(ang_errs))\n",
    "    \n",
    "    # # Generate iksols\n",
    "    # iksols = np.zeros((len(target_poses), num_solutions, panda.dof))\n",
    "\n",
    "    # for i, target_pose in enumerate(target_poses):\n",
    "    #     solutions = ik_solver.solve(\n",
    "    #         target_pose, \n",
    "    #         num_solutions, \n",
    "    #         refine_solutions=False, \n",
    "    #         return_detailed=False)\n",
    "    #     iksols[i] = solutions.detach().cpu().numpy()\n",
    "        \n",
    "    # problem = ProblemWrapper(\n",
    "    #     iksols=iksols, \n",
    "    #     target_poses=target_poses)\n",
    "\n",
    "    # algorithm = BRKGA(\n",
    "    #     n_elites=200,\n",
    "    #     n_offsprings=700,\n",
    "    #     n_mutants=300,\n",
    "    #     bias=0.7)\n",
    "\n",
    "    # res = minimize(\n",
    "    #     problem,\n",
    "    #     algorithm,\n",
    "    #     (\"n_gen\", num_generation),\n",
    "    #     seed=1,\n",
    "    #     verbose=False,\n",
    "    #     save_history=True,\n",
    "    #     eliminate_duplicates=MyElementwiseDuplicateElimination())\n",
    "    \n",
    "    # hist = res.history\n",
    "\n",
    "    \n",
    "    # for algo in hist:\n",
    "    #     data['n_evals'].append(algo.evaluator.n_eval)\n",
    "        \n",
    "    #     opt = algo.opt\n",
    "    #     data['l2_errs_min'].append(opt.get(\"l2_errs\").min())\n",
    "    #     data['l2_errs_avg'].append(algo.pop.get(\"l2_errs\").mean())\n",
    "        \n",
    "    #     data['ang_errs_min'].append(opt.get(\"ang_errs\").min())\n",
    "    #     data['ang_errs_avg'].append(algo.pop.get(\"ang_errs\").mean())\n",
    "        \n",
    "    #     data['F_min'].append(algo.pop.get(\"F\").min())\n",
    "    #     data['F_avg'].append(algo.pop.get(\"F\").mean())\n",
    "        \n",
    "    # for key, val in data.items():\n",
    "    #     # replace this line by `hist_cv` if you like to analyze the least feasible optimal solution and not the population\n",
    "    #     save_numpy(file_path=exp_dir + f'{key}.npy', arr=np.array(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_traj_dirs(num_trails=num_trails):\n",
    "    fns = np.array(os.listdir(path=config.traj_dir))\n",
    "    fns.sort()\n",
    "    abs_traj_dir = os.path.abspath(config.traj_dir) + '/'\n",
    "    fns = np.array([abs_traj_dir + fn + '/' for fn in fns])\n",
    "    return fns[-num_trails-1:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse(traj_dir):\n",
    "    exp_dir = traj_dir + 'exp_5_single_obj/'\n",
    "    file_paths = [exp_dir + fn + '.npy' for fn in file_names]\n",
    "    \n",
    "    data = {}\n",
    "    for i, fn in enumerate(file_names):\n",
    "        data[fn] = load_numpy(file_path=file_paths[i])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(data, y_axis, exp_dir, x_axis=None, title=\"Convergence\"):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    fig_dir = exp_dir + 'figs/'\n",
    "    if not os.path.exists(path=fig_dir):\n",
    "        os.mkdir(path=fig_dir)\n",
    "    if x_axis is None:\n",
    "        plt.plot(data[y_axis], color='black', lw=0.7)\n",
    "        fig_path = fig_dir + y_axis + '.png'\n",
    "    else:\n",
    "        plt.plot(data[x_axis], data[y_axis],  color='black', lw=0.7)\n",
    "        plt.scatter(data[x_axis], data[y_axis],  facecolor=\"none\", edgecolor='black', marker=\"p\")\n",
    "        plt.xlabel(x_axis)\n",
    "        fig_path = fig_dir + x_axis + '_' + y_axis + '.png'\n",
    "        \n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel(y_axis)\n",
    "    \n",
    "    plt.savefig(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_trail_data(num_trails, num_generation):\n",
    "    traj_dirs = load_traj_dirs(num_trails)\n",
    "    name_list = ['ang_errs_avg', 'ang_errs_min', 'F_avg', 'F_min', 'ikflow_ang', 'ikflow_l2', 'l2_errs_avg', 'l2_errs_min', 'n_evals']\n",
    "    \n",
    "    trails_data = {name: np.array([]) for name in name_list}\n",
    "    trails_data['n_trails'] = np.array([])\n",
    "    trails_data['n_gen'] = np.array([])\n",
    "    \n",
    "    n_trail = 0\n",
    "    for td in tqdm(traj_dirs):\n",
    "        data = load_and_parse(traj_dir=td)\n",
    "        trails_data['n_trails'] = np.concatenate((trails_data['n_trails'], np.ones((num_generation))*n_trail))\n",
    "        trails_data['n_gen'] = np.concatenate((trails_data['n_gen'], list(range(num_generation))))\n",
    "        for name in name_list:\n",
    "            trails_data[name] = np.concatenate((trails_data[name], data[name]))\n",
    "        n_trail += 1\n",
    "        \n",
    "    df = pd.DataFrame(data=trails_data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_vis(num_trails, num_generation):\n",
    "    vis_pair = [\n",
    "        ('n_evals', 'ang_errs_min', 'Number of Evaluations', 'Joint Jumps (degrees)', 'Joint Jumps of IKB (min)'),\n",
    "        ('n_evals', 'ang_errs_avg', 'Number of Evaluations', 'Joint Jumps (degrees)', 'Joint Jumps of IKB (avg)'),\n",
    "        ('n_evals', 'F_min', 'Number of Evaluations', 'F_min', 'F_min'),\n",
    "        ('n_evals', 'F_avg', 'Number of Evaluations', 'F_avg', 'F_avg'),\n",
    "        ('n_evals', 'l2_errs_min', 'Number of Evaluations', 'L2 Position Error (m)', 'L2 Position Error of IKB (min)'),\n",
    "        ('n_evals', 'l2_errs_avg', 'Number of Evaluations', 'L2 Position Error (m)', 'L2 Position Error of IKB (avg)'),\n",
    "        ('n_gen', 'ikflow_ang', 'Number of Generations', 'Joint Jumps (degrees)', 'Joint Jumps of IKFlow'),\n",
    "        ('n_gen', 'ikflow_l2', 'Number of Generations', 'L2 Position Error (m)', 'L2 Position Error of IKFlow')\n",
    "    ]\n",
    "    \n",
    "    column_renameing = {\n",
    "        y: t for _, y, _, _, t in vis_pair\n",
    "    }\n",
    "    \n",
    "    errbar = [('sd'), ('se')]\n",
    "\n",
    "    trails_data = combine_trail_data(num_trails=num_trails, num_generation=num_generation)\n",
    "    \n",
    "    trails_data.rename(columns=column_renameing, inplace=True)\n",
    "    sns.set(font_scale=1.15)  # crazy big\n",
    "    for x, y, xa, ya, t in vis_pair:\n",
    "        for eb in errbar:\n",
    "            ax = sns.relplot(data=trails_data, x=x, y=t, kind=\"line\").set(title=t, xlabel=xa, ylabel=ya)\n",
    "            # ax.set_xticklabels(step=1)\n",
    "            # ax.set_xlabels()\n",
    "            ax.savefig(f'{exp_5_fig_dir}{t}_{eb}.png')\n",
    "    \n",
    "\n",
    "load_and_vis(num_trails=100, num_generation=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/13404468/t-test-in-pandas (o)\n",
    "    # Ttest_indResult(statistic=-370.76733198053574, pvalue=0.0)\n",
    "    # since the pvalue of this experiment is 0.0 which is lower than the threshold 0.05. That is, our method is significantly improve the smoothness of solutions from diverse learning-based IK method for the path-following tasks. \n",
    "# success rates\n",
    "\n",
    "# standard error (o)\n",
    "# https://seaborn.pydata.org/tutorial/error_bars.html error_bar methods\n",
    "\n",
    "# mean best fitness values (o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_data = combine_trail_data(num_trails=num_trails, num_generation=num_generation)\n",
    "trails_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_ttest(num_trails=num_trails, num_generation=num_generation):\n",
    "    trails_data = combine_trail_data(num_trails=num_trails, num_generation=num_generation)\n",
    "    \n",
    "    com_pair = [\n",
    "        ('ang_errs_avg', 'ikflow_ang'),\n",
    "        ('ang_errs_min', 'ikflow_ang'),\n",
    "        ('l2_errs_avg', 'ikflow_l2'),\n",
    "        ('l2_errs_min', 'ikflow_l2'),\n",
    "    ]\n",
    "    # trails_data.query('n_evals==100200')['ang_errs_min'].describe()\n",
    "    for x, y in com_pair:\n",
    "        stat, pval = ttest_ind(trails_data.query('n_evals==100200')[x], trails_data.query('n_gen==99')[y], equal_var=False)\n",
    "        print(f\"t-test on ours({x}) and ikflow({y}) with stat = {stat}, p-value = {pval}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_threshold = 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_data.query('n_evals==100200 and ang_errs_min <= 280')['ang_errs_min'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_data.query('ikflow_ang <= 280')['ikflow_ang'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_ttest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_dfdescribe(num_trails=num_trails, num_generation=num_generation):\n",
    "    vis_pair = [\n",
    "        ('n_evals', 'ang_errs_min'),\n",
    "        ('n_evals', 'ang_errs_avg'),\n",
    "        ('n_evals', 'F_min'),\n",
    "        ('n_evals', 'F_avg'),\n",
    "        ('n_evals', 'l2_errs_min'),\n",
    "        ('n_evals', 'l2_errs_avg'),\n",
    "        ('n_gen', 'ikflow_ang'),\n",
    "        ('n_gen', 'ikflow_l2')\n",
    "    ]\n",
    "    errbar = [('sd'), ('se'), ('ci')]\n",
    "\n",
    "    trails_data = combine_trail_data(num_trails=num_trails, num_generation=num_generation)\n",
    "    for x, y in vis_pair:\n",
    "        print(trails_data)\n",
    "    \n",
    "\n",
    "load_and_vis(num_trails=num_trails, num_generation=num_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_data = combine_trail_data(num_trails=num_trails, num_generation=num_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_data.groupby(['n_gen'])['ikflow_ang'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_data.query('n_evals==100200')['ang_errs_min'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_dir, target_poses = get_target_poses(robot=panda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> unrefined solutions\n",
    "solutions, l2_err, _, _, _, _ = ik_solver.solve_n_poses(\n",
    "    target_poses, \n",
    "    refine_solutions=False, \n",
    "    return_detailed=True)\n",
    "\n",
    "iksols = solutions.detach().cpu().numpy()\n",
    "panda.plot(qs=iksols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate iksols\n",
    "iksols = np.zeros((len(target_poses), num_solutions, panda.dof))\n",
    "\n",
    "for i, target_pose in enumerate(target_poses):\n",
    "    solutions = ik_solver.solve(\n",
    "        target_pose, \n",
    "        num_solutions, \n",
    "        refine_solutions=False, \n",
    "        return_detailed=False)\n",
    "    iksols[i] = solutions.detach().cpu().numpy()\n",
    "    \n",
    "problem = ProblemWrapper(\n",
    "    iksols=iksols, \n",
    "    target_poses=target_poses)\n",
    "\n",
    "algorithm = BRKGA(\n",
    "    n_elites=200,\n",
    "    n_offsprings=700,\n",
    "    n_mutants=300,\n",
    "    bias=0.7)\n",
    "\n",
    "res = minimize(\n",
    "    problem,\n",
    "    algorithm,\n",
    "    (\"n_gen\", 50),\n",
    "    seed=1,\n",
    "    verbose=False,\n",
    "    save_history=True,\n",
    "    eliminate_duplicates=MyElementwiseDuplicateElimination())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = res.problem.iksols(res.problem.pheno(res.X))\n",
    "panda.plot(qs=qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
