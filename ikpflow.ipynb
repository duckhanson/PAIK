{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from os import path \n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm, trange\n",
    "import zuko\n",
    "from zuko.flows import Distribution, NSF\n",
    "from zuko.distributions import DiagNormal, BoxUniform, Minimum\n",
    "from zuko.flows import DistributionModule, FlowModule, Unconditional\n",
    "from hnne import HNNE\n",
    "\n",
    "from utils.settings import config\n",
    "from utils.utils import *\n",
    "from utils.model import *\n",
    "from utils.robot import Robot\n",
    "from utils.dataset import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = Robot(verbose=False)\n",
    "# data generation\n",
    "X, y = load_data(robot=panda, num_samples=250_0000)\n",
    "# build dimension reduction model\n",
    "hnne, ds, loader = get_hnne_model(X, y)\n",
    "# Build Generative model, NSF\n",
    "# Neural spline flow (NSF) with 3 sample features and 5 context features\n",
    "flow, optimizer = get_flow_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch):\n",
    "    x, y = add_small_noise_to_batch(batch)\n",
    "        \n",
    "    loss = -flow(y).log_prob(x)  # -log p(x | y)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "err_his = load_numpy(file_path=config.err_his_path)\n",
    "loss_his = load_numpy(file_path=config.train_loss_his_path)\n",
    "for ep in range(config.num_epochs):\n",
    "    t = tqdm(loader)\n",
    "    for batch in t:\n",
    "        loss = train_step(model=flow, batch=batch)\n",
    "        \n",
    "        loss_his = np.concatenate((loss_his, [loss]))\n",
    "        bar = {\n",
    "            \"loss\": f\"{np.round(loss, 3)}/{np.round(loss_his.mean(), 3)}\",\n",
    "            \"ep\": ep,\n",
    "        }\n",
    "        t.set_postfix(bar, refresh=True)\n",
    "\n",
    "        step += 1\n",
    "        if step % config.num_steps_save == 0:\n",
    "            torch.save(flow.state_dict(), config.save_path)\n",
    "            save_numpy(config.train_loss_his_path, loss_his)\n",
    "            df, err = test_l2_err(config, step=step)\n",
    "            print(df.describe())\n",
    "            err_his = np.concatenate((err_his, [err]))\n",
    "            save_numpy(config.err_his_path, err_his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, err = test_l2_err(config, robot=panda, loader=loader, model=flow)\n",
    "ax1 = df.plot.scatter(x='log_prob', y='l2_err')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflow = get_nflow_model(flow=flow)\n",
    "df, err = test_l2_err(config, robot=panda, loader=loader, model=nflow)\n",
    "ax1 = df.plot.scatter(x='log_prob', y='l2_err')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_show_pose_data(config, num_data, num_samples, model=flow):\n",
    "    batch = next(iter(loader))\n",
    "    x, y = add_small_noise_to_batch(batch, eval=True)\n",
    "    assert num_data < len(x)\n",
    "    \n",
    "    x_hats = np.array([])\n",
    "    pidxs = np.array([])\n",
    "    errs = np.array([])\n",
    "    log_probs = np.array([])\n",
    "    rand = np.random.randint(low=0, high=len(x), size=num_data)\n",
    "    \n",
    "    for nd in rand:\n",
    "        x_hat = model(y[nd]).sample((num_samples,))\n",
    "        log_prob = model(y[nd]).log_prob(x_hat)\n",
    "        \n",
    "        x_hat = x_hat.detach().cpu().numpy()\n",
    "        log_prob = -log_prob.detach().cpu().numpy()\n",
    "        target = y[nd].detach().cpu().numpy()\n",
    "        # ee_pos = ee_pos * (ds.targets_max - ds.targets_min) + ds.targets_min\n",
    "        ee_pos = target[:3]\n",
    "        \n",
    "        for q in x_hat:\n",
    "            err = panda.dist_fk(q=q, ee_pos=ee_pos)\n",
    "            errs = np.concatenate((errs, [err]))\n",
    "        x_hats = np.concatenate((x_hats, x_hat.reshape(-1)))\n",
    "        pidx = target[3:-1]\n",
    "        pidx = np.tile(pidx, (num_samples, 1))\n",
    "\n",
    "        pidxs = np.concatenate((pidxs, pidx.reshape(-1)))\n",
    "        log_probs = np.concatenate((log_probs, log_prob))\n",
    "\n",
    "    x_hats = x_hats.reshape((-1, panda.dof))\n",
    "    pidxs = pidxs.reshape((len(x_hats), -1))\n",
    "    \n",
    "\n",
    "    save_numpy(config.show_pose_features_path, x_hats)\n",
    "    save_numpy(config.show_pose_pidxs_path, pidxs)\n",
    "    save_numpy(config.show_pose_errs_path, errs)\n",
    "    save_numpy(config.show_pose_log_probs_path, log_probs)\n",
    "    \n",
    "    print('Save pose successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_show_pose_data(config, num_data=5, num_samples=10, model=nflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside_same_pidx():\n",
    "    x_hats = load_numpy(file_path=config.show_pose_features_path)\n",
    "    pidxs = load_numpy(file_path=config.show_pose_pidxs_path)\n",
    "    \n",
    "    if len(x_hats) == 0:\n",
    "        raise ValueError(\"lack show pose data\") \n",
    "    \n",
    "    pre_pidx = None\n",
    "    qs = np.array([])\n",
    "    for q, pidx in zip(x_hats, pidxs):\n",
    "        if pre_pidx is None or np.array_equal(pre_pidx, pidx):\n",
    "            qs = np.concatenate((qs, q))\n",
    "        else:\n",
    "            break\n",
    "        pre_pidx = pidx\n",
    "    qs = qs.reshape((-1, panda.dof))\n",
    "    for q in qs:\n",
    "        panda.plot(q, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_same_pidx()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
