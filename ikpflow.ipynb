{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from os import path \n",
    "import wandb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm, trange\n",
    "import zuko\n",
    "from zuko.flows import Distribution, NSF\n",
    "from zuko.distributions import DiagNormal, BoxUniform, Minimum\n",
    "from zuko.flows import DistributionModule, FlowModule, Unconditional\n",
    "from hnne import HNNE\n",
    "\n",
    "from utils.settings import config\n",
    "from utils.utils import *\n",
    "from utils.model import *\n",
    "from utils.robot import Robot\n",
    "from utils.dataset import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building h-NNE hierarchy using FINCH...\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Sat May 20 02:27:29 2023 Building RP forest with 32 trees\n",
      "Sat May 20 02:27:46 2023 NN descent for 21 iterations\n",
      "\t 1  /  21\n",
      "\t 2  /  21\n",
      "\t 3  /  21\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 0: 667390 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Sat May 20 02:28:29 2023 Building RP forest with 32 trees\n",
      "Sat May 20 02:28:32 2023 NN descent for 19 iterations\n",
      "\t 1  /  19\n",
      "\t 2  /  19\n",
      "\t 3  /  19\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 1: 167858 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Sat May 20 02:28:39 2023 Building RP forest with 25 trees\n",
      "Sat May 20 02:28:40 2023 NN descent for 17 iterations\n",
      "\t 1  /  17\n",
      "\t 2  /  17\n",
      "\t 3  /  17\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 2: 41187 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Sat May 20 02:28:43 2023 Building RP forest with 19 trees\n",
      "Sat May 20 02:28:43 2023 NN descent for 15 iterations\n",
      "\t 1  /  15\n",
      "\t 2  /  15\n",
      "\t 3  /  15\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 3: 9961 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Sat May 20 02:28:44 2023 Building RP forest with 15 trees\n",
      "Sat May 20 02:28:44 2023 NN descent for 13 iterations\n",
      "\t 1  /  13\n",
      "\t 2  /  13\n",
      "\t 3  /  13\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 4: 2414 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Sat May 20 02:28:45 2023 Building RP forest with 12 trees\n",
      "Sat May 20 02:28:45 2023 NN descent for 11 iterations\n",
      "\t 1  /  11\n",
      "\t 2  /  11\n",
      "\t 3  /  11\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 5: 585 clusters\n",
      "Level 6: 148 clusters\n",
      "Level 7: 35 clusters\n",
      "Level 8: 12 clusters\n",
      "Level 9: 3 clusters\n",
      "Projecting to 4 dimensions...\n",
      "[667390, 167858, 41187, 9961, 2414, 585, 148, 35, 12, 3]\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Sat May 20 02:28:58 2023 Building RP forest with 12 trees\n",
      "Sat May 20 02:28:58 2023 NN descent for 11 iterations\n",
      "\t 1  /  11\n",
      "\t 2  /  11\n",
      "\t 3  /  11\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Sat May 20 02:29:03 2023 Building RP forest with 15 trees\n",
      "Sat May 20 02:29:03 2023 NN descent for 13 iterations\n",
      "\t 1  /  13\n",
      "\t 2  /  13\n",
      "\t 3  /  13\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Sat May 20 02:29:04 2023 Building RP forest with 19 trees\n",
      "Sat May 20 02:29:04 2023 NN descent for 15 iterations\n",
      "\t 1  /  15\n",
      "\t 2  /  15\n",
      "\t 3  /  15\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Sat May 20 02:29:04 2023 Building RP forest with 25 trees\n",
      "Sat May 20 02:29:05 2023 NN descent for 17 iterations\n",
      "\t 1  /  17\n",
      "\t 2  /  17\n",
      "\t 3  /  17\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Sat May 20 02:29:07 2023 Building RP forest with 32 trees\n",
      "Sat May 20 02:29:09 2023 NN descent for 19 iterations\n",
      "\t 1  /  19\n",
      "\t 2  /  19\n",
      "\t 3  /  19\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Load err, assuming you use different architecture.\n"
     ]
    }
   ],
   "source": [
    "panda = Robot(verbose=False)\n",
    "# data generation\n",
    "X, y = load_data(robot=panda, num_samples=250_0000)\n",
    "# build dimension reduction model\n",
    "hnne, ds, loader = get_hnne_model(X, y)\n",
    "# Build Generative model, NSF\n",
    "# Neural spline flow (NSF) with 3 sample features and 5 context features\n",
    "flow, optimizer = get_flow_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch):\n",
    "    x, y = add_small_noise_to_batch(batch)\n",
    "        \n",
    "    loss = -flow(y).log_prob(x)  # -log p(x | y)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mducklyu0301\u001b[0m (\u001b[33mluca_nthu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/luca/ikpflow/wandb/run-20230520_022922-hke7q8zy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/luca_nthu/ikpflow/runs/hke7q8zy' target=\"_blank\">swept-totem-4</a></strong> to <a href='https://wandb.ai/luca_nthu/ikpflow' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/luca_nthu/ikpflow' target=\"_blank\">https://wandb.ai/luca_nthu/ikpflow</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/luca_nthu/ikpflow/runs/hke7q8zy' target=\"_blank\">https://wandb.ai/luca_nthu/ikpflow/runs/hke7q8zy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/luca_nthu/ikpflow/runs/hke7q8zy?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1ceb55d8b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"ikpflow\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 5999/9765 [08:25<04:57, 12.65it/s, loss=-28.7]    "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "l2_label = ['mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "\n",
    "for ep in range(config.num_epochs):\n",
    "    t = tqdm(loader)\n",
    "    for batch in t:\n",
    "        loss = train_step(model=flow, batch=batch)\n",
    "        \n",
    "        bar = {\"loss\": f\"{np.round(loss, 3)}\"}\n",
    "        t.set_postfix(bar, refresh=True)\n",
    "        \n",
    "        # log metrics to wandb\n",
    "        wandb.log({\"loss\": np.round(loss, 3)})\n",
    "\n",
    "        step += 1\n",
    "        if step % config.num_steps_save == 0:\n",
    "            torch.save(flow.state_dict(), config.save_path)\n",
    "            df, err = test_l2_err(config, robot=panda, loader=loader, model=flow, step=step)\n",
    "            l2_val = df.describe().values[1:, 0]\n",
    "            l2_info = {}\n",
    "            for l, v in zip(l2_label, l2_val):\n",
    "                l2_info[l] = v\n",
    "            wandb.log(l2_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflow = get_nflow_model(flow=flow)\n",
    "df, err = test_l2_err(config, robot=panda, loader=loader, model=nflow)\n",
    "ax1 = df.plot.scatter(x='log_prob', y='l2_err')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_show_pose_data(config, num_data, num_samples, model=flow):\n",
    "    batch = next(iter(loader))\n",
    "    x, y = add_small_noise_to_batch(batch, eval=True)\n",
    "    assert num_data < len(x)\n",
    "    \n",
    "    x_hats = np.array([])\n",
    "    pidxs = np.array([])\n",
    "    errs = np.array([])\n",
    "    log_probs = np.array([])\n",
    "    rand = np.random.randint(low=0, high=len(x), size=num_data)\n",
    "    \n",
    "    for nd in rand:\n",
    "        x_hat = model(y[nd]).sample((num_samples,))\n",
    "        log_prob = model(y[nd]).log_prob(x_hat)\n",
    "        \n",
    "        x_hat = x_hat.detach().cpu().numpy()\n",
    "        log_prob = -log_prob.detach().cpu().numpy()\n",
    "        target = y[nd].detach().cpu().numpy()\n",
    "        # ee_pos = ee_pos * (ds.targets_max - ds.targets_min) + ds.targets_min\n",
    "        ee_pos = target[:3]\n",
    "        \n",
    "        for q in x_hat:\n",
    "            err = panda.dist_fk(q=q, ee_pos=ee_pos)\n",
    "            errs = np.concatenate((errs, [err]))\n",
    "        x_hats = np.concatenate((x_hats, x_hat.reshape(-1)))\n",
    "        pidx = target[3:-1]\n",
    "        pidx = np.tile(pidx, (num_samples, 1))\n",
    "\n",
    "        pidxs = np.concatenate((pidxs, pidx.reshape(-1)))\n",
    "        log_probs = np.concatenate((log_probs, log_prob))\n",
    "\n",
    "    x_hats = x_hats.reshape((-1, panda.dof))\n",
    "    pidxs = pidxs.reshape((len(x_hats), -1))\n",
    "    \n",
    "\n",
    "    save_numpy(config.show_pose_features_path, x_hats)\n",
    "    save_numpy(config.show_pose_pidxs_path, pidxs)\n",
    "    save_numpy(config.show_pose_errs_path, errs)\n",
    "    save_numpy(config.show_pose_log_probs_path, log_probs)\n",
    "    \n",
    "    print('Save pose successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_show_pose_data(config, num_data=5, num_samples=10, model=nflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside_same_pidx():\n",
    "    x_hats = load_numpy(file_path=config.show_pose_features_path)\n",
    "    pidxs = load_numpy(file_path=config.show_pose_pidxs_path)\n",
    "    \n",
    "    if len(x_hats) == 0:\n",
    "        raise ValueError(\"lack show pose data\") \n",
    "    \n",
    "    pre_pidx = None\n",
    "    qs = np.array([])\n",
    "    for q, pidx in zip(x_hats, pidxs):\n",
    "        if pre_pidx is None or np.array_equal(pre_pidx, pidx):\n",
    "            qs = np.concatenate((qs, q))\n",
    "        else:\n",
    "            break\n",
    "        pre_pidx = pidx\n",
    "    qs = qs.reshape((-1, panda.dof))\n",
    "    for q in qs:\n",
    "        panda.plot(q, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_same_pidx()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
