{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import time\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from paik.solver import Solver\n",
    "from paik.settings import (\n",
    "    PANDA_NSF,\n",
    "    PANDA_PAIK,\n",
    "    FETCH_PAIK,\n",
    "    FETCH_ARM_PAIK,\n",
    "    IIWA7_PAIK,\n",
    "    ATLAS_ARM_PAIK,\n",
    "    ATLAS_WAIST_ARM_PAIK,\n",
    "    BAXTER_ARM_PAIK,\n",
    "    PR2_PAIK\n",
    ")\n",
    "import os\n",
    "from paik.file import save_pickle, load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = BAXTER_ARM_PAIK\n",
    "param.use_dimension_reduction = False\n",
    "solver = Solver(solver_param=param, load_date=\"\", work_dir=\"/home/luca/paik\")\n",
    "solver.random_ikp(num_poses=100, num_sols=100)\n",
    "# solver.generate_ik_solutions(P, F, std, latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hnne import HNNE\n",
    "J = solver.J\n",
    "num_data = 10_0000\n",
    "\n",
    "hnne = HNNE()\n",
    "Fr = hnne.fit_transform(X=J[:num_data], dim=solver.r, verbose=True)\n",
    "\n",
    "print(f\"[INFO] use_dimension_reduction is False, use clustering.\")\n",
    "partitions = hnne.hierarchy_parameters.partitions\n",
    "num_clusters = hnne.hierarchy_parameters.partition_sizes\n",
    "closest_idx_to_num_clusters_20 = np.argmin(\n",
    "    np.abs(np.array(num_clusters) - 20)\n",
    ")\n",
    "Fp = partitions[:, closest_idx_to_num_clusters_20].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fp = Fp.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "num_total_data = num_data * 2\n",
    "J = J[:num_total_data]\n",
    "# query nearest neighbors for the rest of J\n",
    "if len(F) != len(J):\n",
    "    knn = NearestNeighbors(n_neighbors=1).fit(J[:num_data])\n",
    "    F = np.row_stack(\n",
    "        (\n",
    "            F,\n",
    "            F[\n",
    "                knn.kneighbors(\n",
    "                    J[num_data:], n_neighbors=1, return_distance=False\n",
    "                ).flatten()  # type: ignore\n",
    "            ],\n",
    "        )\n",
    "    )  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finch import FINCH\n",
    "J = solver.J\n",
    "\n",
    "num_data = min(solver.param.max_num_data_hnne, len(J))\n",
    "\n",
    "print(f\"[INFO] Use FINCH to cluster the posture features.\")\n",
    "cluster_labels_all_partitions, num_clusters, required_clusters = FINCH(\n",
    "    J[:num_data]\n",
    ")\n",
    "closest_idx_to_num_clusters_20 = np.argmin(\n",
    "    np.abs(np.array(num_clusters) - 20)\n",
    ")\n",
    "F = cluster_labels_all_partitions[:, closest_idx_to_num_clusters_20]\n",
    "\n",
    "df = pd.DataFrame(F)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hnne import HNNE\n",
    "J = solver.J\n",
    "num_data = min(solver.param.max_num_data_hnne, len(J))\n",
    "\n",
    "hnne = HNNE(dim=solver.r)\n",
    "projection = hnne.fit_transform(J[:num_data], verbose=True)\n",
    "\n",
    "partitions = hnne.hierarchy_parameters.partitions\n",
    "partition_sizes = hnne.hierarchy_parameters.partition_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(projection)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions[:, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_idx_to_num_clusters_20 = np.argmin(np.abs(np.array(num_clust) - 20))\n",
    "closest_idx_to_num_clusters_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillate_latent(solver, latent, num_steps=100, step_size=0.1):\n",
    "    _, P = solver._robot.sample_joint_angles_and_poses(\n",
    "                n=1, return_torch=False\n",
    "            )\n",
    "    F = solver.select_reference_posture(P, \"knn\")\n",
    "    print(P.shape, F.shape)\n",
    "    J_hat = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "    assert J_hat.shape == (1, 1, solver.n) # (num_sols, num_poses, n)\n",
    "    J_hat = np.repeat(np.zeros_like(J_hat), num_steps*2, axis=0) # (num_steps*2, 1, n)\n",
    "    \n",
    "    curr_i = 0\n",
    "    for i in range(num_steps):\n",
    "        latent[0] += step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "        curr_i += 1\n",
    "        \n",
    "    for i in range(num_steps):\n",
    "        latent[0] -= step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "        curr_i += 1\n",
    "        \n",
    "    return J_hat.reshape(-1, solver.n)\n",
    "oscillate_latent(solver, np.zeros((7)), num_steps=100, step_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillate_feature(solver, num_steps=100, step_size=0.1):\n",
    "    _, P = solver._robot.sample_joint_angles_and_poses(\n",
    "                n=1, return_torch=False\n",
    "            )\n",
    "    F = solver.select_reference_posture(P, \"knn\")\n",
    "    J_hat = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "    assert J_hat.shape == (1, 1, solver.n) # (num_sols, num_poses, n)\n",
    "    J_hat = np.repeat(np.zeros_like(J_hat), num_steps*2, axis=0) # (num_steps*2, 1, n)\n",
    "    \n",
    "    curr_i = 0\n",
    "    for i in range(num_steps):\n",
    "        F += step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "        curr_i += 1\n",
    "        \n",
    "    for i in range(num_steps):\n",
    "        F -= step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "        curr_i += 1\n",
    "        \n",
    "    return J_hat.reshape(-1, solver.n)\n",
    "\n",
    "oscillate_feature(solver, num_steps=100, step_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "def simple_path_planning(solver, P: np.ndarray, num_sols: int):\n",
    "    base_std = 0.1\n",
    "    assert len(P.shape) == 2\n",
    "    num_poses = P.shape[0]\n",
    "    \n",
    "    F = solver.select_reference_posture(P[0], \"knn\", num_sols=num_sols)\n",
    "    assert F.shape == (num_sols, solver.r)\n",
    "    P_tr = np.repeat(np.expand_dims(P[0], axis=0), num_sols, axis=0).reshape(-1, P.shape[-1])\n",
    "    assert P_tr.shape == (num_sols, solver.n)\n",
    "    J_fr = solver.generate_ik_solutions(P_tr, F, num_sols=1, std=base_std, latent=np.zeros((solver.n)))\n",
    "    assert J_fr.shape == (1, num_sols, solver.n)\n",
    "    J_fr = J_fr.reshape(num_sols, solver.n)\n",
    "    \n",
    "    if solver._use_nsf_only:\n",
    "        # feature from the first pose\n",
    "        F = solver.select_reference_posture(P[np.random.randint(0, num_poses)], \"knn\")\n",
    "        F = np.repeat(F, P.shape[0], axis=0)\n",
    "        J_hat = solver.generate_ik_solutions(P, F, num_sols=num_sols, std=base_std, latent=np.zeros((solver.n)))\n",
    "    else:\n",
    "        num_neighbors = 10\n",
    "        assert num_sols % num_neighbors == 0\n",
    "        F = solver.select_reference_posture(P, \"knn\", num_sols=num_neighbors)\n",
    "        assert F.shape == (num_neighbors*num_poses, solver.r)\n",
    "        F_tr = F.reshape(num_neighbors, num_poses, solver.r)\n",
    "        F_tr = np.repeat(np.expand_dims(F_tr, axis=0), num_sols//num_neighbors, axis=0).reshape(-1, solver.r)\n",
    "        assert F_tr.shape == (num_sols*num_poses, solver.r)\n",
    "        P_tr = np.repeat(np.expand_dims(P, axis=0), num_sols, axis=0).reshape(-1, P.shape[-1])\n",
    "        assert P_tr.shape == (num_sols*num_poses, solver.n)\n",
    "        J_hat = solver.generate_ik_solutions(P_tr, F_tr, num_sols=1, std=base_std, latent=np.zeros((solver.n)))\n",
    "        assert J_hat.shape == (1, num_sols*num_poses, solver.n)\n",
    "        J_hat = J_hat.reshape(num_sols, num_poses, solver.n)        \n",
    "    \n",
    "    # based on the generated solutions, we can now plan a path\n",
    "    # we will use the nearest neighbor to the solutions of the previous pose\n",
    "    # to determine the solution for the next pose\n",
    "    # we will use the first solution as the initial solution\n",
    "    def get_nearest_neighbor(next_q_set, curr_q):\n",
    "        neigh = NearestNeighbors(n_neighbors=1)\n",
    "        neigh.fit(next_q_set)\n",
    "        return neigh.kneighbors([curr_q], return_distance=False).flatten()\n",
    "    \n",
    "    \n",
    "    smooth_trajectory = np.zeros_like(J_hat[0])\n",
    "    \n",
    "    # random initialization\n",
    "    smooth_trajectory[0] = J_fr[np.random.randint(0, num_sols), 0]\n",
    "    \n",
    "    for i in range(1, num_poses):\n",
    "        idx = get_nearest_neighbor(J_hat[:, i], smooth_trajectory[i-1])\n",
    "        smooth_trajectory[i] = J_hat[idx, i]\n",
    "\n",
    "    # compute maximum joint changes for the smooth trajectory\n",
    "    max_joint_changes = np.max(np.abs(np.diff(smooth_trajectory, axis=0)))\n",
    "\n",
    "    return smooth_trajectory.reshape(1, num_poses, solver.n), max_joint_changes\n",
    "\n",
    "def plan_multiple_trajectories(solver, P, num_trajectories: int, num_samples_per_pose: int):\n",
    "    num_poses = P.shape[0]\n",
    "    trajectories = np.zeros((num_trajectories, num_poses, solver.n))\n",
    "    max_joint_changes = np.zeros(num_trajectories)\n",
    "    \n",
    "    for i in range(num_trajectories):\n",
    "        trajectories[i], max_joint_changes[i] = simple_path_planning(solver, P, num_sols=num_samples_per_pose)\n",
    "    df = pd.DataFrame(max_joint_changes, columns=[\"max_joint_changes\"])\n",
    "    print(df.describe())\n",
    "    \n",
    "    return trajectories, max_joint_changes\n",
    "    \n",
    "\n",
    "poses_function = lambda counter: np.array(\n",
    "        [0.4 * np.sin(counter / 50), 0.6, 0.75, 0.7071068, -0.7071068, 0.0, 0.0]\n",
    "    )\n",
    "\n",
    "num_poses = 10\n",
    "num_trajectories = 10\n",
    "num_samples_per_pose = 2000\n",
    "P = np.array([poses_function(i) for i in range(num_poses)])\n",
    "\n",
    "# solver = Solver(solver_param=PANDA_PAIK, load_date=\"0705-0305\", work_dir=\"/home/luca/paik\")\n",
    "trajectories, max_joint_changes = plan_multiple_trajectories(solver, P, num_trajectories=num_trajectories, num_samples_per_pose=num_samples_per_pose)\n",
    "print(trajectories.shape, max_joint_changes.shape)\n",
    "\n",
    "nsf = Solver(solver_param=PANDA_NSF, load_date=\"0115-0234\", work_dir=\"/home/luca/paik\")\n",
    "trajectories, max_joint_changes = plan_multiple_trajectories(nsf, P, num_trajectories=num_trajectories, num_samples_per_pose=num_samples_per_pose)\n",
    "print(trajectories.shape, max_joint_changes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zuko.distributions import DiagNormal\n",
    "from zuko.flows import Flow, Unconditional\n",
    "\n",
    "num_sols = 10\n",
    "c_rand = torch.ones((1, 9), device=solver._device)\n",
    "latent = torch.tensor([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], device=solver._device)\n",
    "\n",
    "model = Flow(transforms=solver._solver.transforms,  # type: ignore\n",
    "    base=Unconditional(\n",
    "        DiagNormal,\n",
    "        torch.zeros((solver._robot.n_dofs,), device=solver._device) + latent,\n",
    "        torch.zeros((solver._robot.n_dofs,),\n",
    "                    device=solver._device) * 0,\n",
    "        buffer=True,\n",
    "    ),  # type: ignore\n",
    ")\n",
    "model(c_rand).sample((num_sols,))\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(solver_param=PANDA_PAIK, load_date=\"0703-0717\", work_dir=\"/home/luca/paik\")\n",
    "solver.random_ikp(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(solver_param=PANDA_NSF, load_date=\"0115-0234\", work_dir=\"/home/luca/paik\")\n",
    "solver.random_ikp(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from paik.file import save_pickle, load_pickle\n",
    "\n",
    "def save_by_date(date: str):\n",
    "    with open(os.path.join('./', f\"{date}.pth\"), \"w\") as f:\n",
    "        f.write(date)\n",
    "    \n",
    "def remove_by_date(date: str):\n",
    "    os.remove(os.path.join('./', f\"{date}.pth\"))\n",
    "\n",
    "def save_if_best(date: str, l2: float):\n",
    "    best_date_path = os.path.join('./', \"top3_date.pth\")\n",
    "    if not os.path.exists(best_date_path):\n",
    "        save_pickle(best_date_path, {\"date\": [\"\", \"\", \"\"], \"l2\": [1000, 1000, 1000]})\n",
    "    top3_date = load_pickle(best_date_path)\n",
    "    save_idx = -1\n",
    "    # # if the top3 date has the current date, then check if the current model is better, if so, replace it\n",
    "    if date in top3_date[\"date\"]:\n",
    "        if l2 < top3_date[\"l2\"][top3_date[\"date\"].index(date)]:\n",
    "            save_idx = top3_date[\"date\"].index(date)\n",
    "    elif l2 < max(top3_date[\"l2\"]):\n",
    "        save_idx = top3_date[\"l2\"].index(max(top3_date[\"l2\"]))\n",
    "    \n",
    "    if save_idx == -1:\n",
    "        print(f\"[INFO] current model is not better than the top3 model in {best_date_path}\")\n",
    "    else:\n",
    "        if top3_date[\"date\"][save_idx] != \"\" and top3_date[\"date\"][save_idx] != date:\n",
    "            remove_by_date(top3_date[\"date\"][save_idx])\n",
    "        top3_date[\"date\"][save_idx] = date\n",
    "        top3_date[\"l2\"][save_idx] = l2\n",
    "        save_pickle(best_date_path, top3_date)\n",
    "        save_by_date(date)\n",
    "        print(f\"[SUCCESS] save the date {date} with l2 {l2:.5f} in {best_date_path}\")\n",
    "    print(f\"[INFO] top3 dates: {top3_date['date']}, top3 l2: {top3_date['l2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 1 sequnece\n",
    "save_if_best(\"0702-1911\", 0.10001)\n",
    "save_if_best(\"0702-1914\", 0.40004)\n",
    "save_if_best(\"0702-1914\", 0.30004)\n",
    "save_if_best(\"0702-1914\", 0.30006)\n",
    "save_if_best(\"0702-1913\", 0.30003)\n",
    "save_if_best(\"0702-1912\", 0.20002)\n",
    "\n",
    "save_if_best(\"0702-1915\", 0.00005)\n",
    "save_if_best(\"0702-1916\", 0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heads up: Setting joint limits to [-pi, pi] for continuous joint 'r_wheel_joint'\n",
      "Heads up: Setting joint limits to [-pi, pi] for continuous joint 'l_wheel_joint'\n",
      "Heads up: Setting joint limits to [-pi, pi] for continuous joint 'upperarm_roll_joint'\n",
      "Heads up: Setting joint limits to [-pi, pi] for continuous joint 'forearm_roll_joint'\n",
      "Heads up: Setting joint limits to [-pi, pi] for continuous joint 'wrist_roll_joint'\n",
      "WorldModel::LoadRobot: /home/luca/.cache/jrl/temp_urdfs/fetch_formatted_link_filepaths_absolute.urdf\n",
      "joint limit: no lower, defaults to 0joint limit: no upper, , defaults to 0joint limit: no lower, defaults to 0joint limit: no upper, , defaults to 0URDFParser: joint dynamics: no friction, defaults to 0\n",
      "URDFParser: joint dynamics: no friction, defaults to 0\n",
      "URDFParser: joint dynamics: no friction, defaults to 0\n",
      "joint limit: no lower, defaults to 0joint limit: no upper, , defaults to 0URDFParser: joint dynamics: no friction, defaults to 0\n",
      "URDFParser: joint dynamics: no friction, defaults to 0\n",
      "joint limit: no lower, defaults to 0joint limit: no upper, , defaults to 0URDFParser: joint dynamics: no friction, defaults to 0\n",
      "URDFParser: joint dynamics: no friction, defaults to 0\n",
      "joint limit: no lower, defaults to 0joint limit: no upper, , defaults to 0URDFParser: joint dynamics: no friction, defaults to 0\n",
      "URDFParser: joint dynamics: no friction, defaults to 0\n",
      "URDFParser: joint dynamics: no friction, defaults to 0\n",
      "URDFParser: Link size: 30\n",
      "URDFParser: Joint size: 25\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/base_link_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/base_link.dae (85809 verts, 29989 tris)\n",
      "ManagedGeometry: loaded /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/base_link.dae in time 0.322419s\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/estop_link.STL (14687 verts, 7736 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/l_wheel_link.STL (3512 verts, 2086 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/laser_link.STL (15160 verts, 7116 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/r_wheel_link.STL (3512 verts, 2086 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/torso_fixed_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/torso_fixed_link.dae (158 verts, 116 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/torso_lift_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/torso_lift_link.dae (56345 verts, 21480 tris)\n",
      "ManagedGeometry: loaded /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/torso_lift_link.dae in time 0.227871s\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/bellows_link.STL (2608 verts, 1436 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/head_pan_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/head_pan_link.dae (9431 verts, 3692 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/head_tilt_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/head_tilt_link.dae (7589 verts, 2884 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/shoulder_pan_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/shoulder_pan_link.dae (32955 verts, 12853 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/shoulder_lift_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/shoulder_lift_link.dae (30857 verts, 11962 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/upperarm_roll_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/upperarm_roll_link.dae (9596 verts, 4252 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/elbow_flex_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/elbow_flex_link.dae (8074 verts, 3498 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/forearm_roll_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/forearm_roll_link.dae (14194 verts, 6118 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/wrist_flex_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/wrist_flex_link.dae (5210 verts, 2462 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/wrist_roll_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/wrist_roll_link.dae (5950 verts, 3040 tris)\n",
      "AssimpMaterialToAppearance: couldn't load image /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/gripper_uv.png\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/gripper_link.dae (12947 verts, 4680 tris)\n",
      "URDFParser: Done loading robot file /home/luca/.cache/jrl/temp_urdfs/fetch_formatted_link_filepaths_absolute.urdf\n",
      "Initialized robot collision data structures in time 0.431618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/base_link_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/torso_fixed_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/torso_lift_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/head_pan_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/head_tilt_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/shoulder_pan_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/shoulder_lift_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/upperarm_roll_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/elbow_flex_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/forearm_roll_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/wrist_flex_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/wrist_roll_uv.png\n",
      "ImportImage: Unknown file extension \"png\" on image import file /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/fetch/meshes/gripper_uv.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] load from /home/luca/paik/weights/fetch_arm/0824-0018\n",
      "[SUCCESS] load best date 0824-0018 with l2 0.00511 from /home/luca/paik/weights/fetch_arm/best_date_paik.csv.\n"
     ]
    }
   ],
   "source": [
    "from paik.solver import get_solver\n",
    "\n",
    "paik = get_solver(arch_name=\"paik\", robot_name=\"fetch_arm\", load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  l2            ang\n",
      "count  100000.000000  100000.000000\n",
      "mean        0.005236       1.236307\n",
      "std         0.009893       2.926348\n",
      "min         0.000063       0.051247\n",
      "25%         0.002488       0.565602\n",
      "50%         0.003819       0.846091\n",
      "75%         0.005764       1.263843\n",
      "max         0.606291     178.027080\n",
      "  l2 (mm)    ang (deg)    inference_time (ms)\n",
      "---------  -----------  ---------------------\n",
      "     5.24         1.24                      8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0052355981148584155, 0.021577625761553268, 0.008)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paik.random_ikp(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = get_robot(solver_param.robot_name, solver_param.dir_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.n_dofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()  # an empty figure with no Axes\n",
    "fig, ax = plt.subplots()  # a figure with a single Axes\n",
    "\n",
    "width = 1\n",
    "ticks =np.linspace(0, width, 11)\n",
    "\n",
    "ax.set_xlabel(\"$\\\\theta_{1}$\")\n",
    "ax.set_ylabel(\"$\\\\theta_{2}$\")\n",
    "\n",
    "plt.xticks(ticks, labels=[i for i in range(len(ticks))])\n",
    "plt.yticks(ticks, labels=[i for i in range(len(ticks))])\n",
    "\n",
    "# xtickslabls = [\"\" for i in range(4)] + [\"$\\\\theta^{max}_{1}$\", \"\"]\n",
    "# # Set ticks labels for x-axis\n",
    "# ax.set_xticklabels(xtickslabls)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "    if n != 1 and n != 9:\n",
    "        label.set_visible(False)\n",
    "\n",
    "for n, label in enumerate(ax.yaxis.get_ticklabels()):\n",
    "    if n != 1 and n != 9:\n",
    "        label.set_visible(False)\n",
    "        \n",
    "\n",
    "min_line_num = 1\n",
    "max_line_num = 8\n",
    "buffer_width = .5\n",
    "nbins = 10\n",
    "\n",
    "lower_bound = (min_line_num-buffer_width)/nbins * width\n",
    "upper_bound = (max_line_num+buffer_width)/nbins * width\n",
    "min_line = min_line_num/nbins * width\n",
    "max_line = max_line_num/nbins * width\n",
    "\n",
    "print(lower_bound, upper_bound, min_line, max_line)\n",
    "# line axvline is dashed\n",
    "plt.axvline(\n",
    "    x=max_line, ymin=lower_bound, ymax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_1 max\"\n",
    ")\n",
    "\n",
    "# line axvline is dashed\n",
    "plt.axvline(\n",
    "    x=min_line, ymin=lower_bound, ymax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_1 min\"\n",
    ")\n",
    "\n",
    "# line colour is white\n",
    "plt.axhline(y=max_line, xmin=lower_bound, xmax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_2 max\")\n",
    "\n",
    "plt.axhline(y=min_line, xmin=lower_bound, xmax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_2 max\")\n",
    "\n",
    "\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# make arrows\n",
    "# ax.plot((1), (0), ls=\"\", marker=\">\", ms=10, color=\"k\",\n",
    "#         transform=ax.get_yaxis_transform(), clip_on=False)\n",
    "# ax.plot((0), (1), ls=\"\", marker=\"^\", ms=10, color=\"k\",\n",
    "#         transform=ax.get_xaxis_transform(), clip_on=False)\n",
    "# place legend outside\n",
    "# plt.legend(bbox_to_anchor=(1.0, 1), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the limits for the plot\n",
    "theta1_min, theta1_max = 0, 10\n",
    "theta2_min, theta2_max = 0, 5\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Set the limits of the plot\n",
    "ax.set_xlim(theta1_min, theta1_max)\n",
    "ax.set_ylim(theta2_min, theta2_max)\n",
    "\n",
    "# Set the labels for the axes\n",
    "ax.set_xlabel(r'$\\theta_1$')\n",
    "ax.set_ylabel(r'$\\theta_2$')\n",
    "\n",
    "# Draw the grid lines\n",
    "ax.grid(True, which='both')\n",
    "\n",
    "# Draw horizontal and vertical lines (grid-like appearance)\n",
    "for y in np.linspace(theta2_min, theta2_max, 100):\n",
    "    ax.axhline(y, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "for x in np.linspace(theta1_min, theta1_max, 100):\n",
    "    ax.axvline(x, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Example coordinates for the irregular polygons\n",
    "polygon1 = np.array([[1, 2], [2, 3], [3, 2.5], [2.5, 1.5], [1.5, 1]])\n",
    "polygon2 = np.array([[6, 3], [7, 4], [8, 3.5], [7.5, 2.5], [6.5, 2]])\n",
    "polygon3 = np.array([[4, 1], [5, 2], [6, 1.5], [5.5, 0.5], [4.5, 0]])\n",
    "\n",
    "# Draw the polygons\n",
    "ax.plot(polygon1[:, 0], polygon1[:, 1], 'ko-')  # Black circles connected by lines\n",
    "ax.plot(polygon2[:, 0], polygon2[:, 1], 'ko-')\n",
    "ax.plot(polygon3[:, 0], polygon3[:, 1], 'ko-')\n",
    "\n",
    "# Draw filled areas (for illustration, using one filled area)\n",
    "polygon_fill = np.array([[4, 2], [5, 3], [6, 2.5], [5.5, 1.5], [4.5, 1]])\n",
    "ax.fill(polygon_fill[:, 0], polygon_fill[:, 1], 'gray', alpha=0.5)\n",
    "\n",
    "# Set the major ticks\n",
    "ax.set_xticks(np.arange(theta1_min, theta1_max + 1, 1))\n",
    "ax.set_yticks(np.arange(theta2_min, theta2_max + 1, 1))\n",
    "\n",
    "# Set the minor ticks\n",
    "ax.set_xticks(np.arange(theta1_min, theta1_max + 1, 0.2), minor=True)\n",
    "ax.set_yticks(np.arange(theta2_min, theta2_max + 1, 0.2), minor=True)\n",
    "\n",
    "\n",
    "# Adding arrow labels to the ends of the axes\n",
    "ax.annotate(r'$\\theta_1$', xy=(theta1_max, theta2_min), xytext=(theta1_max + 0.5, theta2_min - 0.5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            fontsize=12, ha='center')\n",
    "ax.annotate(r'$\\theta_2$', xy=(theta1_min, theta2_max), xytext=(theta1_min - 0.5, theta2_max + 0.5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            fontsize=12, ha='center')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "theta_min = 1.5\n",
    "theta_max = 8.5\n",
    "font_size = 14\n",
    "\n",
    "# Set up the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Set axis labels and limits\n",
    "# ax.set_xlabel(r'$\\theta_1$', fontsize=14)\n",
    "# ax.set_ylabel(r'$\\theta_2$', fontsize=14)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "# Remove tick marks and labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Add min and max labels\n",
    "ax.text(theta_min, -0.5, r'$\\theta_1^{min}$', fontsize=font_size)\n",
    "ax.text(theta_max, -0.5, r'$\\theta_1^{max}$', fontsize=font_size)\n",
    "ax.text(-0.5, theta_min, r'$\\theta_2^{min}$', fontsize=font_size)\n",
    "ax.text(-0.5, theta_max, r'$\\theta_2^{max}$', fontsize=font_size)\n",
    "\n",
    "# Draw the main curve\n",
    "t = np.linspace(0, 2*np.pi, 200)\n",
    "x = 3 + 1*np.cos(t) - .2*np.sin(t-.17) \n",
    "y = 6 + 1*np.sin(t) + .2*np.cos(t-.37) \n",
    "ax.plot(x, y, 'k-')\n",
    "\n",
    "# Draw the shaded circle\n",
    "circle = plt.Circle((6, 4), 1.5, fill=True, facecolor='lightgray', edgecolor='black')\n",
    "ax.add_artist(circle)\n",
    "\n",
    "ax.axvline(x=theta_min, color='k', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=theta_max, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.axhline(y=theta_min, color='k', linestyle='--', alpha=0.5)\n",
    "ax.axhline(y=theta_max, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.plot(1, 0, \">k\", transform=ax.get_yaxis_transform(), clip_on=False)  \n",
    "ax.plot(0, 1, \"^k\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
    "\n",
    "# Extend axis lines\n",
    "ax.spines['left'].set_bounds(0, 10)\n",
    "ax.spines['bottom'].set_bounds(0, 10)\n",
    "\n",
    "# Add axis labels at the ends\n",
    "ax.text(10.1, 0, r'$\\theta_1$', fontsize=font_size, ha='left', va='center')\n",
    "ax.text(0, 10.1, r'$\\theta_2$', fontsize=font_size, ha='center', va='bottom')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "randArr = np.random.rand(10, 1)\n",
    "sortArr = np.sort(randArr, axis=0)\n",
    "\n",
    "print(f\"Original array: \\n{randArr}\")\n",
    "print(f\"Sorted array: \\n{sortArr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
