{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import time\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from paik.solver import Solver\n",
    "from paik.settings import (\n",
    "    PANDA_NSF,\n",
    "    PANDA_PAIK,\n",
    "    FETCH_PAIK,\n",
    "    FETCH_ARM_PAIK,\n",
    "    IIWA7_PAIK,\n",
    ")\n",
    "import os\n",
    "from paik.file import save_pickle, load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorldModel::LoadRobot: /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "joint mimic: no multiplier, using default value of 1 \n",
      "joint mimic: no offset, using default value of 0 \n",
      "URDFParser: Link size: 17\n",
      "URDFParser: Joint size: 12\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link0.dae (59388 verts, 20478 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link1.dae (37309 verts, 12516 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link2.dae (37892 verts, 12716 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link3.dae (42512 verts, 14233 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link4.dae (43520 verts, 14620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link5.dae (54770 verts, 18327 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link6.dae (64086 verts, 21620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link7.dae (35829 verts, 12077 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/hand.dae (20896 verts, 7078 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "URDFParser: Done loading robot file /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "Initialized robot collision data structures in time 0.413765\n",
      "(\"[INFO] create new model with config: SolverConfig(robot_name='panda', n=7, \"\n",
      " \"m=7, r=1, subnet_num_layers=3, model_architecture='nsf', randperm=False, \"\n",
      " 'base_std=0.68, subnet_width=1024, num_transforms=8, num_bins=10, lr=0.00037, '\n",
      " 'lr_weight_decay=0.012, lr_amsgrad=False, lr_beta=(0.9, 0.999), '\n",
      " 'noise_esp=0.0025, noise_esp_decay=0.97, use_dimension_reduction=True, '\n",
      " 'gamma=0.086, batch_size=2048, num_epochs=15, shce_patience=2, '\n",
      " \"use_nsf_only=False, select_reference_posture_method='knn', \"\n",
      " \"ckpt_name='0126-1535', enable_load_model=True, device='cuda', N=5000000, \"\n",
      " \"data_dir='/home/luca/paik/data/panda', \"\n",
      " \"train_dir='/home/luca/paik/data/panda/train', \"\n",
      " \"weight_dir='/home/luca/paik/weights/panda', max_num_data_hnne=3000000, \"\n",
      " \"traj_dir='/home/luca/paik/data/panda/trajectory/', \"\n",
      " \"dir_paths=('/home/luca/paik/data/panda', '/home/luca/paik/weights/panda', \"\n",
      " \"'/home/luca/paik/data/panda/trajectory/', \"\n",
      " \"'/home/luca/paik/data/panda/train'))\")\n",
      "[WARNING] not load model yet.\n",
      "[WARNING] /home/luca/paik/weights/panda/top3_date.pth not found.. Load training data instead.\n",
      "[ERROR] /home/luca/paik/data/panda/train/F-5000000-7-7-1.npy: file not exist and return empty np array.\n",
      "[WARNING] F not found, generate and save in /home/luca/paik/data/panda/train/F-5000000-7-7-1.npy.\n",
      "[INFO] Use HNNE to cluster the posture features.\n",
      "Building h-NNE hierarchy using FINCH...\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Tue Aug  6 08:36:00 2024 Building RP forest with 32 trees\n",
      "Tue Aug  6 08:36:18 2024 NN descent for 22 iterations\n",
      "\t 1  /  22\n",
      "\t 2  /  22\n",
      "\t 3  /  22\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 0: 801256 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Tue Aug  6 08:39:44 2024 Building RP forest with 32 trees\n",
      "Tue Aug  6 08:39:47 2024 NN descent for 20 iterations\n",
      "\t 1  /  20\n",
      "\t 2  /  20\n",
      "\t 3  /  20\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 1: 201551 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Tue Aug  6 08:39:54 2024 Building RP forest with 26 trees\n",
      "Tue Aug  6 08:39:55 2024 NN descent for 18 iterations\n",
      "\t 1  /  18\n",
      "\t 2  /  18\n",
      "\t 3  /  18\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 2: 49522 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Tue Aug  6 08:39:58 2024 Building RP forest with 20 trees\n",
      "Tue Aug  6 08:39:58 2024 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 3: 11995 clusters\n",
      "Level 4: 2866 clusters\n",
      "Level 5: 706 clusters\n",
      "Level 6: 177 clusters\n",
      "Level 7: 45 clusters\n",
      "Level 8: 14 clusters\n",
      "Level 9: 5 clusters\n",
      "Level 10: 2 clusters\n",
      "Removing 1 levels from the top to start with a levelof size at least 3.\n",
      "Projecting to 1 dimensions...\n",
      "[801256, 201551, 49522, 11995, 2866, 706, 177, 45, 14, 5]\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Tue Aug  6 08:40:10 2024 Building RP forest with 20 trees\n",
      "Tue Aug  6 08:40:10 2024 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\t 4  /  16\n",
      "\t 5  /  16\n",
      "\tStopping threshold met -- exiting after 5 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Tue Aug  6 08:43:16 2024 Building RP forest with 26 trees\n",
      "Tue Aug  6 08:43:16 2024 NN descent for 18 iterations\n",
      "\t 1  /  18\n",
      "\t 2  /  18\n",
      "\t 3  /  18\n",
      "\t 4  /  18\n",
      "\t 5  /  18\n",
      "\tStopping threshold met -- exiting after 5 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Tue Aug  6 08:43:18 2024 Building RP forest with 32 trees\n",
      "Tue Aug  6 08:43:20 2024 NN descent for 20 iterations\n",
      "\t 1  /  20\n",
      "\t 2  /  20\n",
      "\t 3  /  20\n",
      "\t 4  /  20\n",
      "\t 5  /  20\n",
      "\tStopping threshold met -- exiting after 5 iterations\n",
      "[SUCCESS] F saved in /home/luca/paik/data/panda/train/F-5000000-7-7-1.npy.\n",
      "[SUCCESS] F load from /home/luca/paik/data/panda/train/F-5000000-7-7-1.npy\n",
      "[SUCCESS] P_knn load from /home/luca/paik/weights/panda/P_knn-5000000-7-7-1.pth.\n",
      "[SUCCESS] J_knn load from /home/luca/paik/weights/panda/J_knn-5000000-7-7-1.pth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 l2           ang\n",
      "count  10000.000000  10000.000000\n",
      "mean       0.838410    125.471287\n",
      "std        0.299264     37.982985\n",
      "min        0.026840      9.560889\n",
      "25%        0.635947     99.612997\n",
      "50%        0.859664    131.586782\n",
      "75%        1.049079    157.078318\n",
      "max        1.577518    179.996785\n",
      "  l2 (mm)    ang (deg)    inference_time (ms)\n",
      "---------  -----------  ---------------------\n",
      "   838.41       125.47                      9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8384103408388294, 2.189887072194179, 0.009, 0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = Solver(solver_param=PANDA_PAIK, load_date=\"best\", work_dir=\"/home/luca/paik\")\n",
    "solver.evaluate_ikp_iterative(num_poses=100, num_sols=100)\n",
    "# solver.generate_ik_solutions(P, F, std, latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 1338333 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 1: 338740 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 2: 83834 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 3: 20278 clusters\n",
      "Partition 4: 4902 clusters\n",
      "Partition 5: 1184 clusters\n",
      "Partition 6: 285 clusters\n",
      "Partition 7: 68 clusters\n",
      "Partition 8: 21 clusters\n",
      "Partition 9: 7 clusters\n",
      "Partition 10: 2 clusters\n"
     ]
    }
   ],
   "source": [
    "from finch import FINCH\n",
    "\n",
    "data = solver.J\n",
    "c, num_clust, req_c = FINCH(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1338323, 338814, 83823, 20447, 4869, 1118, 289, 65, 15, 5, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_idx_to_num_clusters_20 = np.argmin(np.abs(np.array(num_clust) - 20))\n",
    "closest_idx_to_num_clusters_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillate_latent(solver, latent, num_steps=100, step_size=0.1):\n",
    "    _, P = solver._robot.sample_joint_angles_and_poses(\n",
    "                n=1, return_torch=False\n",
    "            )\n",
    "    F = solver.select_reference_posture(P, \"knn\")\n",
    "    print(P.shape, F.shape)\n",
    "    J_hat = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "    assert J_hat.shape == (1, 1, solver.n) # (num_sols, num_poses, n)\n",
    "    J_hat = np.repeat(np.zeros_like(J_hat), num_steps*2, axis=0) # (num_steps*2, 1, n)\n",
    "    \n",
    "    curr_i = 0\n",
    "    for i in range(num_steps):\n",
    "        latent[0] += step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "        curr_i += 1\n",
    "        \n",
    "    for i in range(num_steps):\n",
    "        latent[0] -= step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "        curr_i += 1\n",
    "        \n",
    "    return J_hat.reshape(-1, solver.n)\n",
    "oscillate_latent(solver, np.zeros((7)), num_steps=100, step_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillate_feature(solver, num_steps=100, step_size=0.1):\n",
    "    _, P = solver._robot.sample_joint_angles_and_poses(\n",
    "                n=1, return_torch=False\n",
    "            )\n",
    "    F = solver.select_reference_posture(P, \"knn\")\n",
    "    J_hat = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "    assert J_hat.shape == (1, 1, solver.n) # (num_sols, num_poses, n)\n",
    "    J_hat = np.repeat(np.zeros_like(J_hat), num_steps*2, axis=0) # (num_steps*2, 1, n)\n",
    "    \n",
    "    curr_i = 0\n",
    "    for i in range(num_steps):\n",
    "        F += step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "        curr_i += 1\n",
    "        \n",
    "    for i in range(num_steps):\n",
    "        F -= step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "        curr_i += 1\n",
    "        \n",
    "    return J_hat.reshape(-1, solver.n)\n",
    "\n",
    "oscillate_feature(solver, num_steps=100, step_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.49it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.57it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.51it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.50it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.75it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.50it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.66it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.59it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.71it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       max_joint_changes\n",
      "count          10.000000\n",
      "mean            3.402328\n",
      "std             0.909429\n",
      "min             2.520334\n",
      "25%             2.705115\n",
      "50%             3.304000\n",
      "75%             3.573157\n",
      "max             5.466048\n",
      "(10, 10, 7) (10,)\n",
      "(\"[INFO] create new model with config: SolverConfig(robot_name='panda', n=7, \"\n",
      " \"m=7, r=1, subnet_num_layers=3, model_architecture='nsf', randperm=False, \"\n",
      " 'base_std=0.68, subnet_width=1024, num_transforms=8, num_bins=10, lr=0.00037, '\n",
      " 'lr_weight_decay=0.012, lr_amsgrad=False, lr_beta=(0.9, 0.999), '\n",
      " 'noise_esp=0.0025, noise_esp_decay=0.97, gamma=0.086, batch_size=2048, '\n",
      " 'num_epochs=15, shce_patience=2, use_nsf_only=True, '\n",
      " \"select_reference_posture_method='knn', ckpt_name='0115-0234', \"\n",
      " \"enable_load_model=True, device='cuda', N=5000000, \"\n",
      " \"data_dir='/home/luca/paik/data/panda', \"\n",
      " \"train_dir='/home/luca/paik/data/panda/train', \"\n",
      " \"weight_dir='/home/luca/paik/weights/panda', max_num_data_hnne=4000000, \"\n",
      " \"traj_dir='/home/luca/paik/data/panda/trajectory/', \"\n",
      " \"dir_paths=('/home/luca/paik/data/panda', '/home/luca/paik/weights/panda', \"\n",
      " \"'/home/luca/paik/data/panda/trajectory/', \"\n",
      " \"'/home/luca/paik/data/panda/train'))\")\n",
      "WorldModel::LoadRobot: /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "joint mimic: no multiplier, using default value of 1 \n",
      "joint mimic: no offset, using default value of 0 \n",
      "URDFParser: Link size: 17\n",
      "URDFParser: Joint size: 12\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link0.dae (59388 verts, 20478 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link1.dae (37309 verts, 12516 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link2.dae (37892 verts, 12716 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link3.dae (42512 verts, 14233 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link4.dae (43520 verts, 14620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link5.dae (54770 verts, 18327 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link6.dae (64086 verts, 21620 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/link7.dae (35829 verts, 12077 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/hand.dae (20896 verts, 7078 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "LoadAssimp: Loaded model /home/luca/miniconda3/lib/python3.9/site-packages/jrl/urdfs/panda/meshes/visual/finger.dae (1849 verts, 624 tris)\n",
      "URDFParser: Done loading robot file /home/luca/.cache/jrl/temp_urdfs/panda_arm_hand_formatted_link_filepaths_absolute.urdf\n",
      "[WARNING] not load model yet.\n",
      "(\"[INFO] create new model with config: SolverConfig(robot_name='panda', n=7, \"\n",
      " \"m=7, r=1, subnet_num_layers=3, model_architecture='nsf', randperm=False, \"\n",
      " 'base_std=0.68, subnet_width=1024, num_transforms=8, num_bins=10, lr=0.00037, '\n",
      " 'lr_weight_decay=0.012, lr_amsgrad=False, lr_beta=(0.9, 0.999), '\n",
      " 'noise_esp=0.0025, noise_esp_decay=0.97, gamma=0.086, batch_size=2048, '\n",
      " 'num_epochs=15, shce_patience=2, use_nsf_only=True, '\n",
      " \"select_reference_posture_method='knn', ckpt_name='0115-0234', \"\n",
      " \"enable_load_model=True, device='cuda', N=5000000, \"\n",
      " \"data_dir='/home/luca/miniconda3/lib/python3.9/site-packages/data/panda', \"\n",
      " \"train_dir='/home/luca/miniconda3/lib/python3.9/site-packages/data/panda/train', \"\n",
      " \"weight_dir='/home/luca/miniconda3/lib/python3.9/site-packages/weights/panda', \"\n",
      " 'max_num_data_hnne=4000000, '\n",
      " \"traj_dir='/home/luca/miniconda3/lib/python3.9/site-packages/data/panda/trajectory/', \"\n",
      " \"dir_paths=('/home/luca/miniconda3/lib/python3.9/site-packages/data/panda', \"\n",
      " \"'/home/luca/miniconda3/lib/python3.9/site-packages/weights/panda', \"\n",
      " \"'/home/luca/miniconda3/lib/python3.9/site-packages/data/panda/trajectory/', \"\n",
      " \"'/home/luca/miniconda3/lib/python3.9/site-packages/data/panda/train'))\")\n",
      "[WARNING] not load model yet.\n",
      "[SUCCESS] load model, J, P, F, J_knn, P_knn from /home/luca/paik/weights/panda/0115-0234\n",
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before remove posture feature (2000, 9)\n",
      "after remove posture feature (2000, 8)\n",
      "before remove posture feature (20000, 9)\n",
      "after remove posture feature (20000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       max_joint_changes\n",
      "count          10.000000\n",
      "mean            2.811235\n",
      "std             0.296058\n",
      "min             2.482743\n",
      "25%             2.602259\n",
      "50%             2.760053\n",
      "75%             2.922328\n",
      "max             3.513676\n",
      "(10, 10, 7) (10,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "def simple_path_planning(solver, P: np.ndarray, num_sols: int):\n",
    "    base_std = 0.1\n",
    "    assert len(P.shape) == 2\n",
    "    num_poses = P.shape[0]\n",
    "    \n",
    "    F = solver.select_reference_posture(P[0], \"knn\", num_sols=num_sols)\n",
    "    assert F.shape == (num_sols, solver.r)\n",
    "    P_tr = np.repeat(np.expand_dims(P[0], axis=0), num_sols, axis=0).reshape(-1, P.shape[-1])\n",
    "    assert P_tr.shape == (num_sols, solver.n)\n",
    "    J_fr = solver.generate_ik_solutions(P_tr, F, num_sols=1, std=base_std, latent=np.zeros((solver.n)))\n",
    "    assert J_fr.shape == (1, num_sols, solver.n)\n",
    "    J_fr = J_fr.reshape(num_sols, solver.n)\n",
    "    \n",
    "    if solver._use_nsf_only:\n",
    "        # feature from the first pose\n",
    "        F = solver.select_reference_posture(P[np.random.randint(0, num_poses)], \"knn\")\n",
    "        F = np.repeat(F, P.shape[0], axis=0)\n",
    "        J_hat = solver.generate_ik_solutions(P, F, num_sols=num_sols, std=base_std, latent=np.zeros((solver.n)))\n",
    "    else:\n",
    "        num_neighbors = 10\n",
    "        assert num_sols % num_neighbors == 0\n",
    "        F = solver.select_reference_posture(P, \"knn\", num_sols=num_neighbors)\n",
    "        assert F.shape == (num_neighbors*num_poses, solver.r)\n",
    "        F_tr = F.reshape(num_neighbors, num_poses, solver.r)\n",
    "        F_tr = np.repeat(np.expand_dims(F_tr, axis=0), num_sols//num_neighbors, axis=0).reshape(-1, solver.r)\n",
    "        assert F_tr.shape == (num_sols*num_poses, solver.r)\n",
    "        P_tr = np.repeat(np.expand_dims(P, axis=0), num_sols, axis=0).reshape(-1, P.shape[-1])\n",
    "        assert P_tr.shape == (num_sols*num_poses, solver.n)\n",
    "        J_hat = solver.generate_ik_solutions(P_tr, F_tr, num_sols=1, std=base_std, latent=np.zeros((solver.n)))\n",
    "        assert J_hat.shape == (1, num_sols*num_poses, solver.n)\n",
    "        J_hat = J_hat.reshape(num_sols, num_poses, solver.n)        \n",
    "    \n",
    "    # based on the generated solutions, we can now plan a path\n",
    "    # we will use the nearest neighbor to the solutions of the previous pose\n",
    "    # to determine the solution for the next pose\n",
    "    # we will use the first solution as the initial solution\n",
    "    def get_nearest_neighbor(next_q_set, curr_q):\n",
    "        neigh = NearestNeighbors(n_neighbors=1)\n",
    "        neigh.fit(next_q_set)\n",
    "        return neigh.kneighbors([curr_q], return_distance=False).flatten()\n",
    "    \n",
    "    \n",
    "    smooth_trajectory = np.zeros_like(J_hat[0])\n",
    "    \n",
    "    # random initialization\n",
    "    smooth_trajectory[0] = J_fr[np.random.randint(0, num_sols), 0]\n",
    "    \n",
    "    for i in range(1, num_poses):\n",
    "        idx = get_nearest_neighbor(J_hat[:, i], smooth_trajectory[i-1])\n",
    "        smooth_trajectory[i] = J_hat[idx, i]\n",
    "\n",
    "    # compute maximum joint changes for the smooth trajectory\n",
    "    max_joint_changes = np.max(np.abs(np.diff(smooth_trajectory, axis=0)))\n",
    "\n",
    "    return smooth_trajectory.reshape(1, num_poses, solver.n), max_joint_changes\n",
    "\n",
    "def plan_multiple_trajectories(solver, P, num_trajectories: int, num_samples_per_pose: int):\n",
    "    num_poses = P.shape[0]\n",
    "    trajectories = np.zeros((num_trajectories, num_poses, solver.n))\n",
    "    max_joint_changes = np.zeros(num_trajectories)\n",
    "    \n",
    "    for i in range(num_trajectories):\n",
    "        trajectories[i], max_joint_changes[i] = simple_path_planning(solver, P, num_sols=num_samples_per_pose)\n",
    "    df = pd.DataFrame(max_joint_changes, columns=[\"max_joint_changes\"])\n",
    "    print(df.describe())\n",
    "    \n",
    "    return trajectories, max_joint_changes\n",
    "    \n",
    "\n",
    "poses_function = lambda counter: np.array(\n",
    "        [0.4 * np.sin(counter / 50), 0.6, 0.75, 0.7071068, -0.7071068, 0.0, 0.0]\n",
    "    )\n",
    "\n",
    "num_poses = 10\n",
    "num_trajectories = 10\n",
    "num_samples_per_pose = 2000\n",
    "P = np.array([poses_function(i) for i in range(num_poses)])\n",
    "\n",
    "# solver = Solver(solver_param=PANDA_PAIK, load_date=\"0705-0305\", work_dir=\"/home/luca/paik\")\n",
    "trajectories, max_joint_changes = plan_multiple_trajectories(solver, P, num_trajectories=num_trajectories, num_samples_per_pose=num_samples_per_pose)\n",
    "print(trajectories.shape, max_joint_changes.shape)\n",
    "\n",
    "nsf = Solver(solver_param=PANDA_NSF, load_date=\"0115-0234\", work_dir=\"/home/luca/paik\")\n",
    "trajectories, max_joint_changes = plan_multiple_trajectories(nsf, P, num_trajectories=num_trajectories, num_samples_per_pose=num_samples_per_pose)\n",
    "print(trajectories.shape, max_joint_changes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zuko.distributions import DiagNormal\n",
    "from zuko.flows import Flow, Unconditional\n",
    "\n",
    "num_sols = 10\n",
    "c_rand = torch.ones((1, 9), device=solver._device)\n",
    "latent = torch.tensor([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], device=solver._device)\n",
    "\n",
    "model = Flow(transforms=solver._solver.transforms,  # type: ignore\n",
    "    base=Unconditional(\n",
    "        DiagNormal,\n",
    "        torch.zeros((solver._robot.n_dofs,), device=solver._device) + latent,\n",
    "        torch.zeros((solver._robot.n_dofs,),\n",
    "                    device=solver._device) * 0,\n",
    "        buffer=True,\n",
    "    ),  # type: ignore\n",
    ")\n",
    "model(c_rand).sample((num_sols,))\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(solver_param=PANDA_PAIK, load_date=\"0703-0717\", work_dir=\"/home/luca/paik\")\n",
    "solver.evaluate_ikp_iterative(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(solver_param=PANDA_NSF, load_date=\"0115-0234\", work_dir=\"/home/luca/paik\")\n",
    "solver.evaluate_ikp_iterative(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from paik.file import save_pickle, load_pickle\n",
    "\n",
    "def save_by_date(date: str):\n",
    "    with open(os.path.join('./', f\"{date}.pth\"), \"w\") as f:\n",
    "        f.write(date)\n",
    "    \n",
    "def remove_by_date(date: str):\n",
    "    os.remove(os.path.join('./', f\"{date}.pth\"))\n",
    "\n",
    "def save_if_top3(date: str, l2: float):\n",
    "    top3_date_path = os.path.join('./', \"top3_date.pth\")\n",
    "    if not os.path.exists(top3_date_path):\n",
    "        save_pickle(top3_date_path, {\"date\": [\"\", \"\", \"\"], \"l2\": [1000, 1000, 1000]})\n",
    "    top3_date = load_pickle(top3_date_path)\n",
    "    save_idx = -1\n",
    "    # # if the top3 date has the current date, then check if the current model is better, if so, replace it\n",
    "    if date in top3_date[\"date\"]:\n",
    "        if l2 < top3_date[\"l2\"][top3_date[\"date\"].index(date)]:\n",
    "            save_idx = top3_date[\"date\"].index(date)\n",
    "    elif l2 < max(top3_date[\"l2\"]):\n",
    "        save_idx = top3_date[\"l2\"].index(max(top3_date[\"l2\"]))\n",
    "    \n",
    "    if save_idx == -1:\n",
    "        print(f\"[INFO] current model is not better than the top3 model in {top3_date_path}\")\n",
    "    else:\n",
    "        if top3_date[\"date\"][save_idx] != \"\" and top3_date[\"date\"][save_idx] != date:\n",
    "            remove_by_date(top3_date[\"date\"][save_idx])\n",
    "        top3_date[\"date\"][save_idx] = date\n",
    "        top3_date[\"l2\"][save_idx] = l2\n",
    "        save_pickle(top3_date_path, top3_date)\n",
    "        save_by_date(date)\n",
    "        print(f\"[SUCCESS] save the date {date} with l2 {l2:.5f} in {top3_date_path}\")\n",
    "    print(f\"[INFO] top3 dates: {top3_date['date']}, top3 l2: {top3_date['l2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 1 sequnece\n",
    "save_if_top3(\"0702-1911\", 0.10001)\n",
    "save_if_top3(\"0702-1914\", 0.40004)\n",
    "save_if_top3(\"0702-1914\", 0.30004)\n",
    "save_if_top3(\"0702-1914\", 0.30006)\n",
    "save_if_top3(\"0702-1913\", 0.30003)\n",
    "save_if_top3(\"0702-1912\", 0.20002)\n",
    "\n",
    "save_if_top3(\"0702-1915\", 0.00005)\n",
    "save_if_top3(\"0702-1916\", 0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paik.file import save_pickle, load_pickle\n",
    "d = load_pickle(\"/home/luca/paik/weights/panda/top3_date.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['date'][1] = \"\"\n",
    "d['date'][2] = \"\"\n",
    "d['l2'][1] = 1000\n",
    "d['l2'][2] = 1000\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(\"/home/luca/paik/weights/panda/top3_date.pth\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pickle(\"/home/luca/paik/weights/panda/top3_date.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paik.model import get_robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = get_robot(solver_param.robot_name, solver_param.dir_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.n_dofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()  # an empty figure with no Axes\n",
    "fig, ax = plt.subplots()  # a figure with a single Axes\n",
    "\n",
    "width = 1\n",
    "ticks =np.linspace(0, width, 11)\n",
    "\n",
    "ax.set_xlabel(\"$\\\\theta_{1}$\")\n",
    "ax.set_ylabel(\"$\\\\theta_{2}$\")\n",
    "\n",
    "plt.xticks(ticks, labels=[i for i in range(len(ticks))])\n",
    "plt.yticks(ticks, labels=[i for i in range(len(ticks))])\n",
    "\n",
    "# xtickslabls = [\"\" for i in range(4)] + [\"$\\\\theta^{max}_{1}$\", \"\"]\n",
    "# # Set ticks labels for x-axis\n",
    "# ax.set_xticklabels(xtickslabls)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "    if n != 1 and n != 9:\n",
    "        label.set_visible(False)\n",
    "\n",
    "for n, label in enumerate(ax.yaxis.get_ticklabels()):\n",
    "    if n != 1 and n != 9:\n",
    "        label.set_visible(False)\n",
    "        \n",
    "\n",
    "min_line_num = 1\n",
    "max_line_num = 8\n",
    "buffer_width = .5\n",
    "nbins = 10\n",
    "\n",
    "lower_bound = (min_line_num-buffer_width)/nbins * width\n",
    "upper_bound = (max_line_num+buffer_width)/nbins * width\n",
    "min_line = min_line_num/nbins * width\n",
    "max_line = max_line_num/nbins * width\n",
    "\n",
    "print(lower_bound, upper_bound, min_line, max_line)\n",
    "# line axvline is dashed\n",
    "plt.axvline(\n",
    "    x=max_line, ymin=lower_bound, ymax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_1 max\"\n",
    ")\n",
    "\n",
    "# line axvline is dashed\n",
    "plt.axvline(\n",
    "    x=min_line, ymin=lower_bound, ymax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_1 min\"\n",
    ")\n",
    "\n",
    "# line colour is white\n",
    "plt.axhline(y=max_line, xmin=lower_bound, xmax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_2 max\")\n",
    "\n",
    "plt.axhline(y=min_line, xmin=lower_bound, xmax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_2 max\")\n",
    "\n",
    "\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# make arrows\n",
    "# ax.plot((1), (0), ls=\"\", marker=\">\", ms=10, color=\"k\",\n",
    "#         transform=ax.get_yaxis_transform(), clip_on=False)\n",
    "# ax.plot((0), (1), ls=\"\", marker=\"^\", ms=10, color=\"k\",\n",
    "#         transform=ax.get_xaxis_transform(), clip_on=False)\n",
    "# place legend outside\n",
    "# plt.legend(bbox_to_anchor=(1.0, 1), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the limits for the plot\n",
    "theta1_min, theta1_max = 0, 10\n",
    "theta2_min, theta2_max = 0, 5\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Set the limits of the plot\n",
    "ax.set_xlim(theta1_min, theta1_max)\n",
    "ax.set_ylim(theta2_min, theta2_max)\n",
    "\n",
    "# Set the labels for the axes\n",
    "ax.set_xlabel(r'$\\theta_1$')\n",
    "ax.set_ylabel(r'$\\theta_2$')\n",
    "\n",
    "# Draw the grid lines\n",
    "ax.grid(True, which='both')\n",
    "\n",
    "# Draw horizontal and vertical lines (grid-like appearance)\n",
    "for y in np.linspace(theta2_min, theta2_max, 100):\n",
    "    ax.axhline(y, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "for x in np.linspace(theta1_min, theta1_max, 100):\n",
    "    ax.axvline(x, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Example coordinates for the irregular polygons\n",
    "polygon1 = np.array([[1, 2], [2, 3], [3, 2.5], [2.5, 1.5], [1.5, 1]])\n",
    "polygon2 = np.array([[6, 3], [7, 4], [8, 3.5], [7.5, 2.5], [6.5, 2]])\n",
    "polygon3 = np.array([[4, 1], [5, 2], [6, 1.5], [5.5, 0.5], [4.5, 0]])\n",
    "\n",
    "# Draw the polygons\n",
    "ax.plot(polygon1[:, 0], polygon1[:, 1], 'ko-')  # Black circles connected by lines\n",
    "ax.plot(polygon2[:, 0], polygon2[:, 1], 'ko-')\n",
    "ax.plot(polygon3[:, 0], polygon3[:, 1], 'ko-')\n",
    "\n",
    "# Draw filled areas (for illustration, using one filled area)\n",
    "polygon_fill = np.array([[4, 2], [5, 3], [6, 2.5], [5.5, 1.5], [4.5, 1]])\n",
    "ax.fill(polygon_fill[:, 0], polygon_fill[:, 1], 'gray', alpha=0.5)\n",
    "\n",
    "# Set the major ticks\n",
    "ax.set_xticks(np.arange(theta1_min, theta1_max + 1, 1))\n",
    "ax.set_yticks(np.arange(theta2_min, theta2_max + 1, 1))\n",
    "\n",
    "# Set the minor ticks\n",
    "ax.set_xticks(np.arange(theta1_min, theta1_max + 1, 0.2), minor=True)\n",
    "ax.set_yticks(np.arange(theta2_min, theta2_max + 1, 0.2), minor=True)\n",
    "\n",
    "\n",
    "# Adding arrow labels to the ends of the axes\n",
    "ax.annotate(r'$\\theta_1$', xy=(theta1_max, theta2_min), xytext=(theta1_max + 0.5, theta2_min - 0.5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            fontsize=12, ha='center')\n",
    "ax.annotate(r'$\\theta_2$', xy=(theta1_min, theta2_max), xytext=(theta1_min - 0.5, theta2_max + 0.5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            fontsize=12, ha='center')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "theta_min = 1.5\n",
    "theta_max = 8.5\n",
    "font_size = 14\n",
    "\n",
    "# Set up the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Set axis labels and limits\n",
    "# ax.set_xlabel(r'$\\theta_1$', fontsize=14)\n",
    "# ax.set_ylabel(r'$\\theta_2$', fontsize=14)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "# Remove tick marks and labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Add min and max labels\n",
    "ax.text(theta_min, -0.5, r'$\\theta_1^{min}$', fontsize=font_size)\n",
    "ax.text(theta_max, -0.5, r'$\\theta_1^{max}$', fontsize=font_size)\n",
    "ax.text(-0.5, theta_min, r'$\\theta_2^{min}$', fontsize=font_size)\n",
    "ax.text(-0.5, theta_max, r'$\\theta_2^{max}$', fontsize=font_size)\n",
    "\n",
    "# Draw the main curve\n",
    "t = np.linspace(0, 2*np.pi, 200)\n",
    "x = 3 + 1*np.cos(t) - .2*np.sin(t-.17) \n",
    "y = 6 + 1*np.sin(t) + .2*np.cos(t-.37) \n",
    "ax.plot(x, y, 'k-')\n",
    "\n",
    "# Draw the shaded circle\n",
    "circle = plt.Circle((6, 4), 1.5, fill=True, facecolor='lightgray', edgecolor='black')\n",
    "ax.add_artist(circle)\n",
    "\n",
    "ax.axvline(x=theta_min, color='k', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=theta_max, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.axhline(y=theta_min, color='k', linestyle='--', alpha=0.5)\n",
    "ax.axhline(y=theta_max, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.plot(1, 0, \">k\", transform=ax.get_yaxis_transform(), clip_on=False)  \n",
    "ax.plot(0, 1, \"^k\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
    "\n",
    "# Extend axis lines\n",
    "ax.spines['left'].set_bounds(0, 10)\n",
    "ax.spines['bottom'].set_bounds(0, 10)\n",
    "\n",
    "# Add axis labels at the ends\n",
    "ax.text(10.1, 0, r'$\\theta_1$', fontsize=font_size, ha='left', va='center')\n",
    "ax.text(0, 10.1, r'$\\theta_2$', fontsize=font_size, ha='center', va='bottom')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: \n",
      "[[0.04550944]\n",
      " [0.28749008]\n",
      " [0.16790026]\n",
      " [0.1901927 ]\n",
      " [0.52840827]\n",
      " [0.17664453]\n",
      " [0.6656493 ]\n",
      " [0.50986014]\n",
      " [0.02397332]\n",
      " [0.38507165]]\n",
      "Sorted array: \n",
      "[[0.02397332]\n",
      " [0.04550944]\n",
      " [0.16790026]\n",
      " [0.17664453]\n",
      " [0.1901927 ]\n",
      " [0.28749008]\n",
      " [0.38507165]\n",
      " [0.50986014]\n",
      " [0.52840827]\n",
      " [0.6656493 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "randArr = np.random.rand(10, 1)\n",
    "sortArr = np.sort(randArr, axis=0)\n",
    "\n",
    "print(f\"Original array: \\n{randArr}\")\n",
    "print(f\"Sorted array: \\n{sortArr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
