{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorldModel::LoadRobot: /home/luca/Klampt-examples/data/robots/baxter.rob\n",
      "RobParser: Reading robot file /home/luca/Klampt-examples/data/robots/baxter.rob...\n",
      "RobParser:    Parsing robot file, 54 links read...\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/collision_head_link_1.off (482 verts, 960 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/collision_head_link_2.off (482 verts, 960 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/torso.off (39450 verts, 69139 tris)\n",
      "ManagedGeometry: loaded /home/luca/Klampt-examples/data/robots/baxter/torso.off in time 0.397249s\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/head.off (2643 verts, 5215 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/screen.off (1904 verts, 3486 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/display.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_upper_shoulder.off (20559 verts, 38337 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_lower_shoulder.off (3423 verts, 6574 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_upper_elbow.off (7111 verts, 13124 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_lower_elbow.off (6412 verts, 11996 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_upper_forearm.off (14126 verts, 26193 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_lower_forearm.off (7375 verts, 13750 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_wrist.off (5987 verts, 11316 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_gripper_base.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_gripper.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_hand_accelerometer.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_hand_camera.off (40 verts, 76 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/left_hand_range.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/pedestal.off (41323 verts, 74650 tris)\n",
      "ManagedGeometry: loaded /home/luca/Klampt-examples/data/robots/baxter/pedestal.off in time 0.430688s\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_upper_shoulder.off (20559 verts, 38337 tris)\n",
      "ManagedGeometry: loaded /home/luca/Klampt-examples/data/robots/baxter/right_upper_shoulder.off in time 0.204861s\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_lower_shoulder.off (3423 verts, 6574 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_upper_elbow.off (7111 verts, 13124 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_lower_elbow.off (6412 verts, 11996 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_upper_forearm.off (14126 verts, 26193 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_lower_forearm.off (7375 verts, 13750 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_wrist.off (5987 verts, 11316 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_gripper_base.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_gripper.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_hand_accelerometer.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_hand_camera.off (40 verts, 76 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/right_hand_range.off (8 verts, 12 tris)\n",
      "LoadAssimp: Loaded model /home/luca/Klampt-examples/data/robots/baxter/sonar_ring.off (40 verts, 76 tris)\n",
      "RobParser: Loaded geometries in time 2.05968s, 397326 total primitive elements\n",
      "RobParser: Done loading robot file /home/luca/Klampt-examples/data/robots/baxter.rob\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import time\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from paik.solver import Solver\n",
    "from paik.settings import (\n",
    "    PANDA_NSF,\n",
    "    PANDA_PAIK,\n",
    "    FETCH_PAIK,\n",
    "    FETCH_ARM_PAIK,\n",
    "    IIWA7_PAIK,\n",
    "    ATLAS_ARM_PAIK,\n",
    "    ATLAS_WAIST_ARM_PAIK,\n",
    "    BAXTER_ARM_PAIK,\n",
    "    PR2_PAIK\n",
    ")\n",
    "import os\n",
    "from paik.file import save_pickle, load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorldModel::LoadRobot: /home/luca/Klampt-examples/data/robots/baxter.rob\n",
      "(\"[INFO] create new model with config: SolverConfig(robot_name='baxter_arm', \"\n",
      " \"n=7, m=7, r=1, subnet_num_layers=3, model_architecture='nsf', \"\n",
      " 'randperm=False, base_std=0.68, subnet_width=1024, num_transforms=7, '\n",
      " 'num_bins=10, lr=0.00037, lr_weight_decay=0.012, lr_amsgrad=False, '\n",
      " 'lr_beta=(0.9, 0.999), noise_esp=0.0025, noise_esp_decay=0.97, '\n",
      " 'use_dimension_reduction=False, gamma=0.086, batch_size=2048, num_epochs=15, '\n",
      " \"shce_patience=2, use_nsf_only=False, select_reference_posture_method='knn', \"\n",
      " \"ckpt_name='1118-0317', enable_load_model=True, device='cuda', N=5000000, \"\n",
      " \"data_dir='/home/luca/paik/data/baxter_arm', \"\n",
      " \"train_dir='/home/luca/paik/data/baxter_arm/train', \"\n",
      " \"weight_dir='/home/luca/paik/weights/baxter_arm', max_num_data_hnne=3000000, \"\n",
      " \"traj_dir='/home/luca/paik/data/baxter_arm/trajectory/', \"\n",
      " \"dir_paths=('/home/luca/paik/data/baxter_arm', \"\n",
      " \"'/home/luca/paik/weights/baxter_arm', \"\n",
      " \"'/home/luca/paik/data/baxter_arm/trajectory/', \"\n",
      " \"'/home/luca/paik/data/baxter_arm/train'))\")\n",
      "RobParser: Reading robot file /home/luca/Klampt-examples/data/robots/baxter.rob...\n",
      "RobParser:    Parsing robot file, 54 links read...\n",
      "TriMeshTopology: mesh has 4 triangles with duplicate neighbors!\n",
      "  Triangle range 789 to 941\n",
      "  May see strange results for some triangle mesh operations\n",
      "ManagedGeometry: Initialized /home/luca/Klampt-examples/data/robots/baxter/torso.off collision data structures in time 0.202527s\n",
      "TriMeshTopology: mesh has 118 triangles with duplicate neighbors!\n",
      "  Triangle range 1716 to 8978\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 42 triangles with duplicate neighbors!\n",
      "  Triangle range 9539 to 20550\n",
      "  May see strange results for some triangle mesh operations\n",
      "ManagedGeometry: Initialized /home/luca/Klampt-examples/data/robots/baxter/pedestal.off collision data structures in time 0.214819s\n",
      "TriMeshTopology: mesh has 118 triangles with duplicate neighbors!\n",
      "  Triangle range 1716 to 8978\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 42 triangles with duplicate neighbors!\n",
      "  Triangle range 9539 to 20550\n",
      "  May see strange results for some triangle mesh operations\n",
      "RobParser: Loaded geometries in time 1.22287s, 397326 total primitive elements\n",
      "RobParser: Done loading robot file /home/luca/Klampt-examples/data/robots/baxter.rob\n",
      "[WARNING] not load model yet.\n",
      "[INFO] use_dimension_reduction is False, use clustering.\n",
      "[WARNING] /home/luca/paik/weights/baxter_arm/param.pth: file not exist and return None.. Load training data instead.\n",
      "[ERROR] /home/luca/paik/data/baxter_arm/train/F-5000000-7-7-1.npy: file not exist and return empty np array.\n",
      "[WARNING] F not found, generate and save in /home/luca/paik/data/baxter_arm/train/F-5000000-7-7-1.npy.\n",
      "Building h-NNE hierarchy using FINCH...\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Tue Aug 13 23:59:54 2024 Building RP forest with 32 trees\n",
      "Wed Aug 14 00:00:13 2024 NN descent for 22 iterations\n",
      "\t 1  /  22\n",
      "\t 2  /  22\n",
      "\t 3  /  22\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 0: 798205 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Wed Aug 14 00:03:48 2024 Building RP forest with 32 trees\n",
      "Wed Aug 14 00:03:51 2024 NN descent for 20 iterations\n",
      "\t 1  /  20\n",
      "\t 2  /  20\n",
      "\t 3  /  20\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 1: 199437 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Wed Aug 14 00:03:59 2024 Building RP forest with 26 trees\n",
      "Wed Aug 14 00:04:00 2024 NN descent for 18 iterations\n",
      "\t 1  /  18\n",
      "\t 2  /  18\n",
      "\t 3  /  18\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 2: 48424 clusters\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Wed Aug 14 00:04:03 2024 Building RP forest with 20 trees\n",
      "Wed Aug 14 00:04:03 2024 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 3: 11625 clusters\n",
      "Level 4: 2843 clusters\n",
      "Level 5: 688 clusters\n",
      "Level 6: 153 clusters\n",
      "Level 7: 35 clusters\n",
      "Level 8: 11 clusters\n",
      "Level 9: 4 clusters\n",
      "Overwriting the dimensions 2 to the new value 1.\n",
      "Projecting to 1 dimensions...\n",
      "[798205, 199437, 48424, 11625, 2843, 688, 153, 35, 11, 4]\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Wed Aug 14 00:04:15 2024 Building RP forest with 20 trees\n",
      "Wed Aug 14 00:04:15 2024 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\t 4  /  16\n",
      "\t 5  /  16\n",
      "\tStopping threshold met -- exiting after 5 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Wed Aug 14 00:07:31 2024 Building RP forest with 26 trees\n",
      "Wed Aug 14 00:07:32 2024 NN descent for 18 iterations\n",
      "\t 1  /  18\n",
      "\t 2  /  18\n",
      "\t 3  /  18\n",
      "\t 4  /  18\n",
      "\t 5  /  18\n",
      "\tStopping threshold met -- exiting after 5 iterations\n",
      "Using ann to approximate 1-nns of the projected points...\n",
      "Wed Aug 14 00:07:34 2024 Building RP forest with 32 trees\n",
      "Wed Aug 14 00:07:36 2024 NN descent for 20 iterations\n",
      "\t 1  /  20\n",
      "\t 2  /  20\n",
      "\t 3  /  20\n",
      "\t 4  /  20\n",
      "\t 5  /  20\n",
      "\tStopping threshold met -- exiting after 5 iterations\n",
      "[INFO] use_dimension_reduction is False, use clustering.\n",
      "[SUCCESS] F saved in /home/luca/paik/data/baxter_arm/train/F-5000000-7-7-1.npy.\n",
      "[SUCCESS] F load from /home/luca/paik/data/baxter_arm/train/F-5000000-7-7-1.npy\n",
      "                  0\n",
      "count  5.000000e+06\n",
      "mean   4.299432e+00\n",
      "std    2.895503e+00\n",
      "min    0.000000e+00\n",
      "25%    2.000000e+00\n",
      "50%    4.000000e+00\n",
      "75%    6.000000e+00\n",
      "max    1.000000e+01\n",
      "[WARNING] P_knn not found, generate and save in /home/luca/paik/weights/baxter_arm/P_knn-5000000-7-7-1.pth.\n",
      "[SUCCESS] P_knn load from /home/luca/paik/weights/baxter_arm/P_knn-5000000-7-7-1.pth.\n",
      "[WARNING] J_knn not found, generate and save in /home/luca/paik/weights/baxter_arm/J_knn-5000000-7-7-1.pth.\n",
      "[SUCCESS] J_knn load from /home/luca/paik/weights/baxter_arm/J_knn-5000000-7-7-1.pth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 l2           ang\n",
      "count  10000.000000  10000.000000\n",
      "mean       0.860220    129.849922\n",
      "std        0.313904     36.419479\n",
      "min        0.044440      8.890407\n",
      "25%        0.628855    106.612011\n",
      "50%        0.878798    136.926532\n",
      "75%        1.108208    159.469903\n",
      "max        1.663415    179.994933\n",
      "  l2 (mm)    ang (deg)    inference_time (ms)\n",
      "---------  -----------  ---------------------\n",
      "   860.22       129.85                      9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8602200439572629, 2.266308676389674, 0.009, 0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = BAXTER_ARM_PAIK\n",
    "param.use_dimension_reduction = False\n",
    "solver = Solver(solver_param=param, load_date=\"\", work_dir=\"/home/luca/paik\")\n",
    "solver.random_ikp(num_poses=100, num_sols=100)\n",
    "# solver.generate_ik_solutions(P, F, std, latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building h-NNE hierarchy using FINCH...\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Wed Aug  7 22:28:46 2024 Building RP forest with 23 trees\n",
      "Wed Aug  7 22:28:47 2024 NN descent for 17 iterations\n",
      "\t 1  /  17\n",
      "\t 2  /  17\n",
      "\t 3  /  17\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Step PyNNDescent done ...\n",
      "Level 0: 26136 clusters\n",
      "Level 1: 6342 clusters\n",
      "Level 2: 1528 clusters\n",
      "Level 3: 359 clusters\n",
      "Level 4: 87 clusters\n",
      "Level 5: 25 clusters\n",
      "Level 6: 8 clusters\n",
      "Level 7: 2 clusters\n",
      "Removing 1 levels from the top to start with a levelof size at least 3.\n",
      "Overwriting the dimensions 2 to the new value 1.\n",
      "Projecting to 1 dimensions...\n",
      "[26136, 6342, 1528, 359, 87, 25, 8]\n",
      "[INFO] use_dimension_reduction is False, use clustering.\n"
     ]
    }
   ],
   "source": [
    "from hnne import HNNE\n",
    "J = solver.J\n",
    "num_data = 10_0000\n",
    "\n",
    "hnne = HNNE()\n",
    "Fr = hnne.fit_transform(X=J[:num_data], dim=solver.r, verbose=True)\n",
    "\n",
    "print(f\"[INFO] use_dimension_reduction is False, use clustering.\")\n",
    "partitions = hnne.hierarchy_parameters.partitions\n",
    "num_clusters = hnne.hierarchy_parameters.partition_sizes\n",
    "closest_idx_to_num_clusters_20 = np.argmin(\n",
    "    np.abs(np.array(num_clusters) - 20)\n",
    ")\n",
    "Fp = partitions[:, closest_idx_to_num_clusters_20].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fp = Fp.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "num_total_data = num_data * 2\n",
    "J = J[:num_total_data]\n",
    "# query nearest neighbors for the rest of J\n",
    "if len(F) != len(J):\n",
    "    knn = NearestNeighbors(n_neighbors=1).fit(J[:num_data])\n",
    "    F = np.row_stack(\n",
    "        (\n",
    "            F,\n",
    "            F[\n",
    "                knn.kneighbors(\n",
    "                    J[num_data:], n_neighbors=1, return_distance=False\n",
    "                ).flatten()  # type: ignore\n",
    "            ],\n",
    "        )\n",
    "    )  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finch import FINCH\n",
    "J = solver.J\n",
    "\n",
    "num_data = min(solver.param.max_num_data_hnne, len(J))\n",
    "\n",
    "print(f\"[INFO] Use FINCH to cluster the posture features.\")\n",
    "cluster_labels_all_partitions, num_clusters, required_clusters = FINCH(\n",
    "    J[:num_data]\n",
    ")\n",
    "closest_idx_to_num_clusters_20 = np.argmin(\n",
    "    np.abs(np.array(num_clusters) - 20)\n",
    ")\n",
    "F = cluster_labels_all_partitions[:, closest_idx_to_num_clusters_20]\n",
    "\n",
    "df = pd.DataFrame(F)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hnne import HNNE\n",
    "J = solver.J\n",
    "num_data = min(solver.param.max_num_data_hnne, len(J))\n",
    "\n",
    "hnne = HNNE(dim=solver.r)\n",
    "projection = hnne.fit_transform(J[:num_data], verbose=True)\n",
    "\n",
    "partitions = hnne.hierarchy_parameters.partitions\n",
    "partition_sizes = hnne.hierarchy_parameters.partition_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(projection)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions[:, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_idx_to_num_clusters_20 = np.argmin(np.abs(np.array(num_clust) - 20))\n",
    "closest_idx_to_num_clusters_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillate_latent(solver, latent, num_steps=100, step_size=0.1):\n",
    "    _, P = solver._robot.sample_joint_angles_and_poses(\n",
    "                n=1, return_torch=False\n",
    "            )\n",
    "    F = solver.select_reference_posture(P, \"knn\")\n",
    "    print(P.shape, F.shape)\n",
    "    J_hat = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "    assert J_hat.shape == (1, 1, solver.n) # (num_sols, num_poses, n)\n",
    "    J_hat = np.repeat(np.zeros_like(J_hat), num_steps*2, axis=0) # (num_steps*2, 1, n)\n",
    "    \n",
    "    curr_i = 0\n",
    "    for i in range(num_steps):\n",
    "        latent[0] += step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "        curr_i += 1\n",
    "        \n",
    "    for i in range(num_steps):\n",
    "        latent[0] -= step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=latent)\n",
    "        curr_i += 1\n",
    "        \n",
    "    return J_hat.reshape(-1, solver.n)\n",
    "oscillate_latent(solver, np.zeros((7)), num_steps=100, step_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillate_feature(solver, num_steps=100, step_size=0.1):\n",
    "    _, P = solver._robot.sample_joint_angles_and_poses(\n",
    "                n=1, return_torch=False\n",
    "            )\n",
    "    F = solver.select_reference_posture(P, \"knn\")\n",
    "    J_hat = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "    assert J_hat.shape == (1, 1, solver.n) # (num_sols, num_poses, n)\n",
    "    J_hat = np.repeat(np.zeros_like(J_hat), num_steps*2, axis=0) # (num_steps*2, 1, n)\n",
    "    \n",
    "    curr_i = 0\n",
    "    for i in range(num_steps):\n",
    "        F += step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "        curr_i += 1\n",
    "        \n",
    "    for i in range(num_steps):\n",
    "        F -= step_size\n",
    "        J_hat[curr_i] = solver.generate_ik_solutions(P, F, num_sols=1, std=0.0, latent=np.zeros((7)))\n",
    "        curr_i += 1\n",
    "        \n",
    "    return J_hat.reshape(-1, solver.n)\n",
    "\n",
    "oscillate_feature(solver, num_steps=100, step_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "def simple_path_planning(solver, P: np.ndarray, num_sols: int):\n",
    "    base_std = 0.1\n",
    "    assert len(P.shape) == 2\n",
    "    num_poses = P.shape[0]\n",
    "    \n",
    "    F = solver.select_reference_posture(P[0], \"knn\", num_sols=num_sols)\n",
    "    assert F.shape == (num_sols, solver.r)\n",
    "    P_tr = np.repeat(np.expand_dims(P[0], axis=0), num_sols, axis=0).reshape(-1, P.shape[-1])\n",
    "    assert P_tr.shape == (num_sols, solver.n)\n",
    "    J_fr = solver.generate_ik_solutions(P_tr, F, num_sols=1, std=base_std, latent=np.zeros((solver.n)))\n",
    "    assert J_fr.shape == (1, num_sols, solver.n)\n",
    "    J_fr = J_fr.reshape(num_sols, solver.n)\n",
    "    \n",
    "    if solver._use_nsf_only:\n",
    "        # feature from the first pose\n",
    "        F = solver.select_reference_posture(P[np.random.randint(0, num_poses)], \"knn\")\n",
    "        F = np.repeat(F, P.shape[0], axis=0)\n",
    "        J_hat = solver.generate_ik_solutions(P, F, num_sols=num_sols, std=base_std, latent=np.zeros((solver.n)))\n",
    "    else:\n",
    "        num_neighbors = 10\n",
    "        assert num_sols % num_neighbors == 0\n",
    "        F = solver.select_reference_posture(P, \"knn\", num_sols=num_neighbors)\n",
    "        assert F.shape == (num_neighbors*num_poses, solver.r)\n",
    "        F_tr = F.reshape(num_neighbors, num_poses, solver.r)\n",
    "        F_tr = np.repeat(np.expand_dims(F_tr, axis=0), num_sols//num_neighbors, axis=0).reshape(-1, solver.r)\n",
    "        assert F_tr.shape == (num_sols*num_poses, solver.r)\n",
    "        P_tr = np.repeat(np.expand_dims(P, axis=0), num_sols, axis=0).reshape(-1, P.shape[-1])\n",
    "        assert P_tr.shape == (num_sols*num_poses, solver.n)\n",
    "        J_hat = solver.generate_ik_solutions(P_tr, F_tr, num_sols=1, std=base_std, latent=np.zeros((solver.n)))\n",
    "        assert J_hat.shape == (1, num_sols*num_poses, solver.n)\n",
    "        J_hat = J_hat.reshape(num_sols, num_poses, solver.n)        \n",
    "    \n",
    "    # based on the generated solutions, we can now plan a path\n",
    "    # we will use the nearest neighbor to the solutions of the previous pose\n",
    "    # to determine the solution for the next pose\n",
    "    # we will use the first solution as the initial solution\n",
    "    def get_nearest_neighbor(next_q_set, curr_q):\n",
    "        neigh = NearestNeighbors(n_neighbors=1)\n",
    "        neigh.fit(next_q_set)\n",
    "        return neigh.kneighbors([curr_q], return_distance=False).flatten()\n",
    "    \n",
    "    \n",
    "    smooth_trajectory = np.zeros_like(J_hat[0])\n",
    "    \n",
    "    # random initialization\n",
    "    smooth_trajectory[0] = J_fr[np.random.randint(0, num_sols), 0]\n",
    "    \n",
    "    for i in range(1, num_poses):\n",
    "        idx = get_nearest_neighbor(J_hat[:, i], smooth_trajectory[i-1])\n",
    "        smooth_trajectory[i] = J_hat[idx, i]\n",
    "\n",
    "    # compute maximum joint changes for the smooth trajectory\n",
    "    max_joint_changes = np.max(np.abs(np.diff(smooth_trajectory, axis=0)))\n",
    "\n",
    "    return smooth_trajectory.reshape(1, num_poses, solver.n), max_joint_changes\n",
    "\n",
    "def plan_multiple_trajectories(solver, P, num_trajectories: int, num_samples_per_pose: int):\n",
    "    num_poses = P.shape[0]\n",
    "    trajectories = np.zeros((num_trajectories, num_poses, solver.n))\n",
    "    max_joint_changes = np.zeros(num_trajectories)\n",
    "    \n",
    "    for i in range(num_trajectories):\n",
    "        trajectories[i], max_joint_changes[i] = simple_path_planning(solver, P, num_sols=num_samples_per_pose)\n",
    "    df = pd.DataFrame(max_joint_changes, columns=[\"max_joint_changes\"])\n",
    "    print(df.describe())\n",
    "    \n",
    "    return trajectories, max_joint_changes\n",
    "    \n",
    "\n",
    "poses_function = lambda counter: np.array(\n",
    "        [0.4 * np.sin(counter / 50), 0.6, 0.75, 0.7071068, -0.7071068, 0.0, 0.0]\n",
    "    )\n",
    "\n",
    "num_poses = 10\n",
    "num_trajectories = 10\n",
    "num_samples_per_pose = 2000\n",
    "P = np.array([poses_function(i) for i in range(num_poses)])\n",
    "\n",
    "# solver = Solver(solver_param=PANDA_PAIK, load_date=\"0705-0305\", work_dir=\"/home/luca/paik\")\n",
    "trajectories, max_joint_changes = plan_multiple_trajectories(solver, P, num_trajectories=num_trajectories, num_samples_per_pose=num_samples_per_pose)\n",
    "print(trajectories.shape, max_joint_changes.shape)\n",
    "\n",
    "nsf = Solver(solver_param=PANDA_NSF, load_date=\"0115-0234\", work_dir=\"/home/luca/paik\")\n",
    "trajectories, max_joint_changes = plan_multiple_trajectories(nsf, P, num_trajectories=num_trajectories, num_samples_per_pose=num_samples_per_pose)\n",
    "print(trajectories.shape, max_joint_changes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zuko.distributions import DiagNormal\n",
    "from zuko.flows import Flow, Unconditional\n",
    "\n",
    "num_sols = 10\n",
    "c_rand = torch.ones((1, 9), device=solver._device)\n",
    "latent = torch.tensor([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], device=solver._device)\n",
    "\n",
    "model = Flow(transforms=solver._solver.transforms,  # type: ignore\n",
    "    base=Unconditional(\n",
    "        DiagNormal,\n",
    "        torch.zeros((solver._robot.n_dofs,), device=solver._device) + latent,\n",
    "        torch.zeros((solver._robot.n_dofs,),\n",
    "                    device=solver._device) * 0,\n",
    "        buffer=True,\n",
    "    ),  # type: ignore\n",
    ")\n",
    "model(c_rand).sample((num_sols,))\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(solver_param=PANDA_PAIK, load_date=\"0703-0717\", work_dir=\"/home/luca/paik\")\n",
    "solver.random_ikp(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(solver_param=PANDA_NSF, load_date=\"0115-0234\", work_dir=\"/home/luca/paik\")\n",
    "solver.random_ikp(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from paik.file import save_pickle, load_pickle\n",
    "\n",
    "def save_by_date(date: str):\n",
    "    with open(os.path.join('./', f\"{date}.pth\"), \"w\") as f:\n",
    "        f.write(date)\n",
    "    \n",
    "def remove_by_date(date: str):\n",
    "    os.remove(os.path.join('./', f\"{date}.pth\"))\n",
    "\n",
    "def save_if_top3(date: str, l2: float):\n",
    "    top3_date_path = os.path.join('./', \"top3_date.pth\")\n",
    "    if not os.path.exists(top3_date_path):\n",
    "        save_pickle(top3_date_path, {\"date\": [\"\", \"\", \"\"], \"l2\": [1000, 1000, 1000]})\n",
    "    top3_date = load_pickle(top3_date_path)\n",
    "    save_idx = -1\n",
    "    # # if the top3 date has the current date, then check if the current model is better, if so, replace it\n",
    "    if date in top3_date[\"date\"]:\n",
    "        if l2 < top3_date[\"l2\"][top3_date[\"date\"].index(date)]:\n",
    "            save_idx = top3_date[\"date\"].index(date)\n",
    "    elif l2 < max(top3_date[\"l2\"]):\n",
    "        save_idx = top3_date[\"l2\"].index(max(top3_date[\"l2\"]))\n",
    "    \n",
    "    if save_idx == -1:\n",
    "        print(f\"[INFO] current model is not better than the top3 model in {top3_date_path}\")\n",
    "    else:\n",
    "        if top3_date[\"date\"][save_idx] != \"\" and top3_date[\"date\"][save_idx] != date:\n",
    "            remove_by_date(top3_date[\"date\"][save_idx])\n",
    "        top3_date[\"date\"][save_idx] = date\n",
    "        top3_date[\"l2\"][save_idx] = l2\n",
    "        save_pickle(top3_date_path, top3_date)\n",
    "        save_by_date(date)\n",
    "        print(f\"[SUCCESS] save the date {date} with l2 {l2:.5f} in {top3_date_path}\")\n",
    "    print(f\"[INFO] top3 dates: {top3_date['date']}, top3 l2: {top3_date['l2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 1 sequnece\n",
    "save_if_top3(\"0702-1911\", 0.10001)\n",
    "save_if_top3(\"0702-1914\", 0.40004)\n",
    "save_if_top3(\"0702-1914\", 0.30004)\n",
    "save_if_top3(\"0702-1914\", 0.30006)\n",
    "save_if_top3(\"0702-1913\", 0.30003)\n",
    "save_if_top3(\"0702-1912\", 0.20002)\n",
    "\n",
    "save_if_top3(\"0702-1915\", 0.00005)\n",
    "save_if_top3(\"0702-1916\", 0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paik.file import save_pickle, load_pickle\n",
    "d = load_pickle(\"/home/luca/paik/weights/panda/top3_date.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['date'][1] = \"\"\n",
    "d['date'][2] = \"\"\n",
    "d['l2'][1] = 1000\n",
    "d['l2'][2] = 1000\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(\"/home/luca/paik/weights/panda/top3_date.pth\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pickle(\"/home/luca/paik/weights/panda/top3_date.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paik.model import get_robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = get_robot(solver_param.robot_name, solver_param.dir_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.n_dofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()  # an empty figure with no Axes\n",
    "fig, ax = plt.subplots()  # a figure with a single Axes\n",
    "\n",
    "width = 1\n",
    "ticks =np.linspace(0, width, 11)\n",
    "\n",
    "ax.set_xlabel(\"$\\\\theta_{1}$\")\n",
    "ax.set_ylabel(\"$\\\\theta_{2}$\")\n",
    "\n",
    "plt.xticks(ticks, labels=[i for i in range(len(ticks))])\n",
    "plt.yticks(ticks, labels=[i for i in range(len(ticks))])\n",
    "\n",
    "# xtickslabls = [\"\" for i in range(4)] + [\"$\\\\theta^{max}_{1}$\", \"\"]\n",
    "# # Set ticks labels for x-axis\n",
    "# ax.set_xticklabels(xtickslabls)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "    if n != 1 and n != 9:\n",
    "        label.set_visible(False)\n",
    "\n",
    "for n, label in enumerate(ax.yaxis.get_ticklabels()):\n",
    "    if n != 1 and n != 9:\n",
    "        label.set_visible(False)\n",
    "        \n",
    "\n",
    "min_line_num = 1\n",
    "max_line_num = 8\n",
    "buffer_width = .5\n",
    "nbins = 10\n",
    "\n",
    "lower_bound = (min_line_num-buffer_width)/nbins * width\n",
    "upper_bound = (max_line_num+buffer_width)/nbins * width\n",
    "min_line = min_line_num/nbins * width\n",
    "max_line = max_line_num/nbins * width\n",
    "\n",
    "print(lower_bound, upper_bound, min_line, max_line)\n",
    "# line axvline is dashed\n",
    "plt.axvline(\n",
    "    x=max_line, ymin=lower_bound, ymax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_1 max\"\n",
    ")\n",
    "\n",
    "# line axvline is dashed\n",
    "plt.axvline(\n",
    "    x=min_line, ymin=lower_bound, ymax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_1 min\"\n",
    ")\n",
    "\n",
    "# line colour is white\n",
    "plt.axhline(y=max_line, xmin=lower_bound, xmax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_2 max\")\n",
    "\n",
    "plt.axhline(y=min_line, xmin=lower_bound, xmax=upper_bound, color=\"black\", linestyle=\"--\", label=\"theta_2 max\")\n",
    "\n",
    "\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# make arrows\n",
    "# ax.plot((1), (0), ls=\"\", marker=\">\", ms=10, color=\"k\",\n",
    "#         transform=ax.get_yaxis_transform(), clip_on=False)\n",
    "# ax.plot((0), (1), ls=\"\", marker=\"^\", ms=10, color=\"k\",\n",
    "#         transform=ax.get_xaxis_transform(), clip_on=False)\n",
    "# place legend outside\n",
    "# plt.legend(bbox_to_anchor=(1.0, 1), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the limits for the plot\n",
    "theta1_min, theta1_max = 0, 10\n",
    "theta2_min, theta2_max = 0, 5\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Set the limits of the plot\n",
    "ax.set_xlim(theta1_min, theta1_max)\n",
    "ax.set_ylim(theta2_min, theta2_max)\n",
    "\n",
    "# Set the labels for the axes\n",
    "ax.set_xlabel(r'$\\theta_1$')\n",
    "ax.set_ylabel(r'$\\theta_2$')\n",
    "\n",
    "# Draw the grid lines\n",
    "ax.grid(True, which='both')\n",
    "\n",
    "# Draw horizontal and vertical lines (grid-like appearance)\n",
    "for y in np.linspace(theta2_min, theta2_max, 100):\n",
    "    ax.axhline(y, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "for x in np.linspace(theta1_min, theta1_max, 100):\n",
    "    ax.axvline(x, color='gray', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Example coordinates for the irregular polygons\n",
    "polygon1 = np.array([[1, 2], [2, 3], [3, 2.5], [2.5, 1.5], [1.5, 1]])\n",
    "polygon2 = np.array([[6, 3], [7, 4], [8, 3.5], [7.5, 2.5], [6.5, 2]])\n",
    "polygon3 = np.array([[4, 1], [5, 2], [6, 1.5], [5.5, 0.5], [4.5, 0]])\n",
    "\n",
    "# Draw the polygons\n",
    "ax.plot(polygon1[:, 0], polygon1[:, 1], 'ko-')  # Black circles connected by lines\n",
    "ax.plot(polygon2[:, 0], polygon2[:, 1], 'ko-')\n",
    "ax.plot(polygon3[:, 0], polygon3[:, 1], 'ko-')\n",
    "\n",
    "# Draw filled areas (for illustration, using one filled area)\n",
    "polygon_fill = np.array([[4, 2], [5, 3], [6, 2.5], [5.5, 1.5], [4.5, 1]])\n",
    "ax.fill(polygon_fill[:, 0], polygon_fill[:, 1], 'gray', alpha=0.5)\n",
    "\n",
    "# Set the major ticks\n",
    "ax.set_xticks(np.arange(theta1_min, theta1_max + 1, 1))\n",
    "ax.set_yticks(np.arange(theta2_min, theta2_max + 1, 1))\n",
    "\n",
    "# Set the minor ticks\n",
    "ax.set_xticks(np.arange(theta1_min, theta1_max + 1, 0.2), minor=True)\n",
    "ax.set_yticks(np.arange(theta2_min, theta2_max + 1, 0.2), minor=True)\n",
    "\n",
    "\n",
    "# Adding arrow labels to the ends of the axes\n",
    "ax.annotate(r'$\\theta_1$', xy=(theta1_max, theta2_min), xytext=(theta1_max + 0.5, theta2_min - 0.5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            fontsize=12, ha='center')\n",
    "ax.annotate(r'$\\theta_2$', xy=(theta1_min, theta2_max), xytext=(theta1_min - 0.5, theta2_max + 0.5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "            fontsize=12, ha='center')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "theta_min = 1.5\n",
    "theta_max = 8.5\n",
    "font_size = 14\n",
    "\n",
    "# Set up the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Set axis labels and limits\n",
    "# ax.set_xlabel(r'$\\theta_1$', fontsize=14)\n",
    "# ax.set_ylabel(r'$\\theta_2$', fontsize=14)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "# Remove tick marks and labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Add min and max labels\n",
    "ax.text(theta_min, -0.5, r'$\\theta_1^{min}$', fontsize=font_size)\n",
    "ax.text(theta_max, -0.5, r'$\\theta_1^{max}$', fontsize=font_size)\n",
    "ax.text(-0.5, theta_min, r'$\\theta_2^{min}$', fontsize=font_size)\n",
    "ax.text(-0.5, theta_max, r'$\\theta_2^{max}$', fontsize=font_size)\n",
    "\n",
    "# Draw the main curve\n",
    "t = np.linspace(0, 2*np.pi, 200)\n",
    "x = 3 + 1*np.cos(t) - .2*np.sin(t-.17) \n",
    "y = 6 + 1*np.sin(t) + .2*np.cos(t-.37) \n",
    "ax.plot(x, y, 'k-')\n",
    "\n",
    "# Draw the shaded circle\n",
    "circle = plt.Circle((6, 4), 1.5, fill=True, facecolor='lightgray', edgecolor='black')\n",
    "ax.add_artist(circle)\n",
    "\n",
    "ax.axvline(x=theta_min, color='k', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=theta_max, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.axhline(y=theta_min, color='k', linestyle='--', alpha=0.5)\n",
    "ax.axhline(y=theta_max, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.plot(1, 0, \">k\", transform=ax.get_yaxis_transform(), clip_on=False)  \n",
    "ax.plot(0, 1, \"^k\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
    "\n",
    "# Extend axis lines\n",
    "ax.spines['left'].set_bounds(0, 10)\n",
    "ax.spines['bottom'].set_bounds(0, 10)\n",
    "\n",
    "# Add axis labels at the ends\n",
    "ax.text(10.1, 0, r'$\\theta_1$', fontsize=font_size, ha='left', va='center')\n",
    "ax.text(0, 10.1, r'$\\theta_2$', fontsize=font_size, ha='center', va='bottom')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "randArr = np.random.rand(10, 1)\n",
    "sortArr = np.sort(randArr, axis=0)\n",
    "\n",
    "print(f\"Original array: \\n{randArr}\")\n",
    "print(f\"Sorted array: \\n{sortArr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
